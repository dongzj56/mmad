{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device         : cuda:1\n",
      "label_file     : C:/Users/dongzj/Desktop/Multimodal_AD/adni_dataset/ADNI_902.csv\n",
      "mri_dir        : C:/Users/dongzj/Desktop/Multimodal_AD/adni_dataset/MRI\n",
      "task           : ADCN\n",
      "augment        : False\n",
      "split_ratio_test: 0.2\n",
      "seed           : 42\n",
      "num_epochs     : 100\n",
      "batch_size     : 8\n",
      "lr             : 1e-06\n",
      "weight_decay   : 0.0001\n",
      "fp16           : True\n",
      "checkpoint_dir : checkpoints-adcn-mri\n",
      "nb_class       : 2\n",
      "n_splits       : 5\n",
      "dropout_rate   : 0.5\n",
      "in_channels    : 1\n",
      "seg_task       : False\n",
      "\n",
      "[ADNI Dataset: ADCN] 样本分布：\n",
      "  CN (0): 204\n",
      "  AD (1): 219\n",
      "\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "训练集样本数: 295  (69.7%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 85  (20.1%)\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "训练集样本数: 295  (69.7%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 85  (20.1%)\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "训练集样本数: 295  (69.7%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 85  (20.1%)\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "训练集样本数: 296  (70.0%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 84  (19.9%)\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "训练集样本数: 296  (70.0%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 84  (19.9%)\n",
      "✅ fold indices saved to checkpoints-adcn-mri\\fold_indices.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, csv, numpy as np\n",
    "from collections import Counter\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets.ADNI import ADNI, ADNI_transform\n",
    "from monai.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, matthews_corrcoef,\n",
    "                             confusion_matrix, roc_curve, auc)\n",
    "\n",
    "# -------------------- 配置 --------------------\n",
    "config_path = rf\"C:\\Users\\dongzj\\Desktop\\mmad\\unet3d_single\\config\\config_unet3d_single_model.json\"\n",
    "def load_cfg(path=config_path):\n",
    "    with open(path) as f: return json.load(f)\n",
    "\n",
    "class Cfg:\n",
    "    def __init__(self, d):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        for k, v in d.items(): \n",
    "            setattr(self, k, v)\n",
    "\n",
    "# ----------------- 指标函数 -------------------\n",
    "def calculate_metrics(y_true, y_pred, y_score):\n",
    "    if len(y_true) == 0:\n",
    "        raise ValueError(\"No samples to evaluate. Please check your test_loader / data split.\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    spe = tn / (tn + fp + 1e-8)\n",
    "    return {\n",
    "        'ACC': accuracy_score(y_true, y_pred),\n",
    "        'PRE': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'SEN': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'SPE': spe,\n",
    "        'F1' : f1_score(y_true, y_pred, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_true, y_score),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "        'cm' : np.array([[tn, fp], [fn, tp]])\n",
    "    }\n",
    "cfg = Cfg(load_cfg())\n",
    "for name, val in vars(cfg).items():\n",
    "    print(f\"{name:15s}: {val}\")\n",
    "writer = SummaryWriter(cfg.checkpoint_dir)\n",
    "\n",
    "# ----------------- 创建模型 -------------------\n",
    "def generate_model(cfg):\n",
    "    \"\"\"\n",
    "    按 cfg 创建模型与训练组件。\n",
    "    \n",
    "    返回\n",
    "    -------\n",
    "    model, optimizer, scheduler, scaler, criterion\n",
    "    \"\"\"\n",
    "    from models.unet3d import UNet3DClassifier\n",
    "    model = UNet3DClassifier(\n",
    "        in_channels=cfg.in_channels,\n",
    "        num_classes=cfg.nb_class\n",
    "    ).to(cfg.device)\n",
    "\n",
    "    # 参数统计\n",
    "    total_params     = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    bytes_per_param  = 2 if cfg.fp16 else 4\n",
    "    print(\"--------------------model------------------\")\n",
    "    print(f\"Total params(M)    : {total_params:,}\")\n",
    "    print(f\"Trainable params(M): {trainable_params:,}\")\n",
    "    print(f\"Approx. size    : {total_params*bytes_per_param/1024**2:.2f} MB\")\n",
    "    print(\"model type:\", type(model).__name__)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ----------------- 测试创建模型 -------------------\n",
    "\n",
    "# model = generate_model(cfg)\n",
    "\n",
    "# dummy = torch.randn(1, cfg.in_channels, 96, 112, 96, device=cfg.device)\n",
    "# with torch.no_grad():\n",
    "#     out = model(dummy)\n",
    "# print(\"Dummy output shape:\", out.shape)\n",
    "\n",
    "# ----------------- 加载数据 -------------------\n",
    "from collections import defaultdict\n",
    "\n",
    "fold_loaders = []                  # ⬅️ 所有折的 DataLoader 都收集到这里\n",
    "fold_indices = defaultdict(dict)   # 可选：若想保存索引，方便调试\n",
    "\n",
    "full_ds = ADNI(cfg.label_file, cfg.mri_dir, cfg.task, cfg.augment).data_dict\n",
    "labels  = [d['label'] for d in full_ds]\n",
    "\n",
    "outer_cv = StratifiedKFold(\n",
    "    n_splits=cfg.n_splits,     # 5 折\n",
    "    shuffle=True,\n",
    "    random_state=cfg.seed\n",
    ")\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(outer_cv.split(full_ds, labels), start=1):\n",
    "    train_val_ds = [full_ds[i] for i in train_val_idx]\n",
    "    test_ds      = [full_ds[i] for i in test_idx]\n",
    "\n",
    "    # —— 内层 90/10 分出验证集 —— #\n",
    "    labels_train_val = [d['label'] for d in train_val_ds]\n",
    "    idxs = np.arange(len(train_val_ds))\n",
    "    train_idx_, val_idx_ = train_test_split(\n",
    "        idxs, test_size=0.125, stratify=labels_train_val, random_state=cfg.seed\n",
    "    )\n",
    "    train_ds = [train_val_ds[i] for i in train_idx_]\n",
    "    val_ds   = [train_val_ds[i] for i in val_idx_]\n",
    "\n",
    "    print(f\"\\n=== Fold {fold}/{cfg.n_splits} ===\")\n",
    "    print(f\"训练集样本数: {len(train_ds)}  ({len(train_ds)/len(full_ds):.1%})\")\n",
    "    print(f\"验证集样本数: {len(val_ds)}  ({len(val_ds)/len(full_ds):.1%})\")\n",
    "    print(f\"测试集样本数: {len(test_ds)}  ({len(test_ds)/len(full_ds):.1%})\")\n",
    "\n",
    "    # —— 构造 DataLoader —— #\n",
    "    tr_tf, vl_tf = ADNI_transform(augment=cfg.augment)\n",
    "    te_tf        = vl_tf      # 测试不做增强\n",
    "\n",
    "    tr_loader = DataLoader(\n",
    "        Dataset(train_ds, tr_tf),\n",
    "        batch_size=cfg.batch_size, shuffle=True,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    vl_loader = DataLoader(\n",
    "        Dataset(val_ds, vl_tf),\n",
    "        batch_size=cfg.batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        Dataset(test_ds, te_tf),\n",
    "        batch_size=cfg.batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # —— 保存到列表 —— #\n",
    "    fold_loaders.append({\n",
    "        \"fold\"        : fold,\n",
    "        \"train_loader\": tr_loader,\n",
    "        \"val_loader\"  : vl_loader,\n",
    "        \"test_loader\" : test_loader\n",
    "    })\n",
    "\n",
    "    # （可选）保存索引，便于日后溯源\n",
    "    fold_indices[fold][\"train_idx\"] = train_idx_\n",
    "    fold_indices[fold][\"val_idx\"]   = val_idx_\n",
    "    fold_indices[fold][\"test_idx\"]  = test_idx\n",
    "\n",
    "# 现在 fold_loaders[0] ~ fold_loaders[4] 就是 5 组 train/val/test DataLoader\n",
    "# 例如：fold_loaders[0]['train_loader'] 取第一折的训练集加载器\n",
    "\n",
    "# 假设 fold_indices 是 {1:{\"train_idx\": [...], \"val_idx\":[...], \"test_idx\":[...]}, 2: {...}, ...}\n",
    "save_path = os.path.join(cfg.checkpoint_dir, \"fold_indices.json\")\n",
    "with open(save_path, \"w\") as f:\n",
    "    # 先把 numpy 数组转成 list\n",
    "    serializable = {\n",
    "        str(fold): {\n",
    "            \"train_idx\": v[\"train_idx\"].tolist(),\n",
    "            \"val_idx\"  : v[\"val_idx\"].tolist(),\n",
    "            \"test_idx\" : v[\"test_idx\"].tolist(),\n",
    "        }\n",
    "        for fold, v in fold_indices.items()\n",
    "    }\n",
    "    json.dump(serializable, f, indent=2)\n",
    "print(f\"✅ fold indices saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------- 五折交叉验证训练 -----------------\n",
    "os.makedirs(cfg.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for fold_idx in range(cfg.n_splits):              # cfg.n_splits == 5\n",
    "    fold = fold_idx + 1\n",
    "    print(f\"\\n=== Fold {fold}/{cfg.n_splits} ===\")\n",
    "\n",
    "    # —— 每折都重新实例化模型与训练组件 —— #\n",
    "    model     = generate_model(cfg)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.lr,\n",
    "        weight_decay=getattr(cfg, 'weight_decay', 0)\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.num_epochs)\n",
    "    scaler    = GradScaler(enabled=cfg.fp16)\n",
    "\n",
    "    # —— 获取该折的 DataLoader —— #\n",
    "    tr_loader = fold_loaders[fold_idx]['train_loader']\n",
    "    vl_loader = fold_loaders[fold_idx]['val_loader']\n",
    "\n",
    "    # —— 计算该折训练集中各类别样本权重 —— #\n",
    "    all_labels = []\n",
    "    for batch in tr_loader:\n",
    "        all_labels.extend(batch['label'].cpu().tolist())\n",
    "    counts = Counter(all_labels)\n",
    "    class_counts = [counts.get(i, 0) for i in range(cfg.nb_class)]\n",
    "    total_count = sum(class_counts)\n",
    "    weights = [\n",
    "        total_count / (cfg.nb_class * c) if c > 0 else 0.0\n",
    "        for c in class_counts\n",
    "    ]\n",
    "    weights = torch.tensor(weights, dtype=torch.float, device=cfg.device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    # —— 为该折创建专属 CSV —— #\n",
    "    csv_path = os.path.join(cfg.checkpoint_dir, f\"metrics_fold{fold}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_Loss\",\"train_ACC\",\"train_PRE\",\"train_SEN\",\"train_SPE\",\"train_F1\",\"train_AUC\",\"train_MCC\",\n",
    "            \"val_Loss\",\"val_ACC\"  ,\"val_PRE\"  ,\"val_SEN\"  ,\"val_SPE\"  ,\"val_F1\"  ,\"val_AUC\"  ,\"val_MCC\",\n",
    "        ])\n",
    "\n",
    "    best_auc = -np.inf\n",
    "\n",
    "    # —— Epoch 循环 —— #\n",
    "    for epoch in range(1, cfg.num_epochs + 1):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # -------- Train --------\n",
    "        model.train()\n",
    "        tr_loss_sum = 0.0\n",
    "        tr_batches  = 0\n",
    "        yt, yp, ys = [], [], []\n",
    "        for batch in tr_loader:\n",
    "            x = batch['MRI'].to(cfg.device)\n",
    "            y = batch['label'].to(cfg.device).long().view(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda', enabled=cfg.fp16):\n",
    "                out  = model(x)\n",
    "                loss = criterion(out, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tr_loss_sum += loss.item()\n",
    "            tr_batches  += 1\n",
    "\n",
    "            prob = torch.softmax(out, dim=1)[:, 1].detach().cpu().numpy()\n",
    "            pred = out.argmax(1).detach().cpu().numpy()\n",
    "            yt.extend(y.cpu().numpy())\n",
    "            yp.extend(pred)\n",
    "            ys.extend(prob)\n",
    "\n",
    "        tr_met  = calculate_metrics(yt, yp, ys)\n",
    "        tr_loss = tr_loss_sum / tr_batches\n",
    "\n",
    "        # -------- Validation --------\n",
    "        model.eval()\n",
    "        vl_loss_sum = 0.0\n",
    "        vl_batches  = 0\n",
    "        yt, yp, ys = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in vl_loader:\n",
    "                print(\"------------------------------------------\")\n",
    "                print(batch['MRI'].shape)\n",
    "                print(\"------------------------------------------\")\n",
    "                \n",
    "                x = batch['MRI'].to(cfg.device)\n",
    "                y = batch['label'].to(cfg.device).long().view(-1)\n",
    "\n",
    "                with autocast(device_type='cuda', enabled=cfg.fp16):\n",
    "                    out  = model(x)\n",
    "                    loss = criterion(out, y)\n",
    "\n",
    "                vl_loss_sum += loss.item()\n",
    "                vl_batches  += 1\n",
    "\n",
    "                prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "                pred = out.argmax(1).cpu().numpy()\n",
    "                yt.extend(y.cpu().numpy())\n",
    "                yp.extend(pred)\n",
    "                ys.extend(prob)\n",
    "\n",
    "        vl_met  = calculate_metrics(yt, yp, ys)\n",
    "        vl_loss = vl_loss_sum / vl_batches\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Fold {fold} | Epoch {epoch:03d} | \"\n",
    "              f\"Train Loss={tr_loss:.4f} | Val Loss={vl_loss:.4f} | \"\n",
    "              f\"Train ACC={tr_met['ACC']:.4f} | Val ACC={vl_met['ACC']:.4f} | \"\n",
    "              f\"Train AUC={tr_met['AUC']:.4f} | Val AUC={vl_met['AUC']:.4f} | \"\n",
    "              f\"time={time.time()-t0:.1f}s\")\n",
    "\n",
    "        # —— 保存当前折最佳模型 —— #\n",
    "        if vl_met['AUC'] > best_auc:\n",
    "            best_auc = vl_met['AUC']\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(cfg.checkpoint_dir, f\"best_model_fold{fold}.pth\")\n",
    "            )\n",
    "            print(\"✅ Fold\", fold, \"saved best model (AUC={:.4f})\".format(best_auc))\n",
    "\n",
    "        # —— 追加写入 CSV —— #\n",
    "        with open(csv_path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                f\"{tr_loss:.4f}\", f\"{tr_met['ACC']:.4f}\", f\"{tr_met['PRE']:.4f}\",\n",
    "                f\"{tr_met['SEN']:.4f}\", f\"{tr_met['SPE']:.4f}\", f\"{tr_met['F1']:.4f}\", f\"{tr_met['AUC']:.4f}\", f\"{tr_met['MCC']:.4f}\",\n",
    "                f\"{vl_loss:.4f}\", f\"{vl_met['ACC']:.4f}\", f\"{vl_met['PRE']:.4f}\",\n",
    "                f\"{vl_met['SEN']:.4f}\", f\"{vl_met['SPE']:.4f}\", f\"{vl_met['F1']:.4f}\", f\"{vl_met['AUC']:.4f}\", f\"{vl_met['MCC']:.4f}\",\n",
    "            ])\n",
    "\n",
    "    print(f\"=== Fold {fold} 完成，Best AUC={best_auc:.4f} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_test_data(cfg, fold):\n",
    "    # 读取整个数据集\n",
    "    full_ds = ADNI(\n",
    "        cfg.label_file,\n",
    "        cfg.pet_dir,\n",
    "        cfg.task,\n",
    "        cfg.augment\n",
    "    ).data_dict\n",
    "\n",
    "    #  从 JSON 中加载各折的下标\n",
    "    idx_path = os.path.join(cfg.checkpoint_dir, \"fold_indices.json\")\n",
    "    with open(idx_path, \"r\") as f:\n",
    "        all_indices = json.load(f)\n",
    "\n",
    "    # 取出指定 fold 的 test_idx\n",
    "    test_idx = all_indices[str(fold)][\"test_idx\"]\n",
    "\n",
    "    # 重建测试集\n",
    "    test_data = [ full_ds[i] for i in test_idx ]\n",
    "    return test_data\n",
    "\n",
    "def test_models(checkpoint_dir, test_data, fold):\n",
    "    cfg = Cfg(load_cfg(config_path))\n",
    "    device = cfg.device\n",
    "\n",
    "    # 构建 DataLoader\n",
    "    _, test_tf = ADNI_transform(augment=False)\n",
    "    ds = Dataset(data=test_data, transform=test_tf)\n",
    "    loader = DataLoader(ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "                        num_workers=2, pin_memory=True)\n",
    "\n",
    "    # 加载模型\n",
    "    model = generate_model(cfg)\n",
    "    ckpt = os.path.join(checkpoint_dir, f\"best_model_fold{fold}.pth\")\n",
    "    model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    print(f\"✅ Loaded {ckpt}\")\n",
    "\n",
    "    # 推理\n",
    "    y_true, y_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch['MRI'].to(device)\n",
    "            out = model(x)\n",
    "            probs = torch.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "            labels = batch['label'].long().view(-1).cpu().numpy()\n",
    "            y_prob.extend(probs)\n",
    "            y_true.extend(labels)\n",
    "\n",
    "    # 计算指标\n",
    "    y_pred  = (np.array(y_prob) > 0.5).astype(int)\n",
    "    metrics = calculate_metrics(y_true, y_pred, y_prob)\n",
    "\n",
    "    # ——— 画并保存该折的 ROC 曲线 ———\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, lw=2)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(f'ROC Fold {fold} (AUC={metrics[\"AUC\"]:.2f})')\n",
    "    roc_path = os.path.join(checkpoint_dir, f\"roc_fold{fold}.png\")\n",
    "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ ROC curve for fold {fold} saved to {roc_path}\")\n",
    "\n",
    "    return metrics, y_prob, y_true\n",
    "\n",
    "\n",
    "all_metrics = []\n",
    "all_probs   = []\n",
    "all_labels  = []\n",
    "\n",
    "results_txt = os.path.join(cfg.checkpoint_dir, \"test_results.txt\")\n",
    "with open(results_txt, \"w\") as f:\n",
    "    f.write(\"Fold\\tACC\\tPRE\\tSEN\\tSPE\\tF1\\tAUC\\tMCC\\n\")\n",
    "\n",
    "for fold in range(1, cfg.n_splits+1):\n",
    "    print(f\"\\n=== Testing Fold {fold}/{cfg.n_splits} ===\")\n",
    "    test_data = load_test_data(cfg, fold)\n",
    "    metrics, probs, labels = test_models(cfg.checkpoint_dir, test_data, fold)\n",
    "\n",
    "    # ——— 追加写入 TXT ———\n",
    "    with open(results_txt, \"a\") as f:\n",
    "        f.write(\n",
    "            f\"{fold}\\t\"\n",
    "            f\"{metrics['ACC']:.4f}\\t{metrics['PRE']:.4f}\\t\"\n",
    "            f\"{metrics['SEN']:.4f}\\t{metrics['SPE']:.4f}\\t\"\n",
    "            f\"{metrics['F1']:.4f}\\t{metrics['AUC']:.4f}\\t\"\n",
    "            f\"{metrics['MCC']:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "    all_metrics.append(metrics)\n",
    "    all_probs.extend(probs)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "\n",
    "# 画平均 ROC\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "plt.plot(mean_fpr, interp_tpr, 'b-', lw=2,\n",
    "         label=f'Mean ROC (AUC={roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(cfg.checkpoint_dir, 'mean_test_roc.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 汇总指标：均值 ± 标准差\n",
    "print(\"\\n=== Final Test Results (mean ± std) ===\")\n",
    "for k in ['ACC','PRE','SEN','SPE','F1','AUC','MCC']:\n",
    "    vals = [m[k] for m in all_metrics]\n",
    "    print(f\"{k}: {np.mean(vals):.4f} ± {np.std(vals):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
