{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T21:23:45.825310Z",
     "start_time": "2025-07-13T21:23:34.149968Z"
    }
   },
   "source": [
    "import os, json, time, csv, numpy as np, pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets.ADNI import ADNI, ADNI_transform\n",
    "from monai.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from utils.metrics import calculate_metrics\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\.conda\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:23:45.933842Z",
     "start_time": "2025-07-13T21:23:45.849202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------- 配置 --------------------\n",
    "def load_cfg(path):\n",
    "    with open(path) as f: \n",
    "        return json.load(f)\n",
    "\n",
    "class Cfg:\n",
    "    def __init__(self, d):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        for k, v in d.items(): \n",
    "            setattr(self, k, v)\n",
    "# ----------------- 加载配置 -------------------\n",
    "config_path = \"config/config2.json\"\n",
    "cfg = Cfg(load_cfg(config_path))\n",
    "for name, val in vars(cfg).items():\n",
    "    print(f\"{name:15s}: {val}\")\n",
    "writer = SummaryWriter(cfg.checkpoint_dir)"
   ],
   "id": "d6109517638733bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device         : cuda:0\n",
      "label_file     : adni_dataset/ADNI_902.csv\n",
      "mri_dir        : adni_dataset/MRI\n",
      "pet_dir        : adni_dataset/PET\n",
      "table_dir      : adni_dataset/ADNI_Tabel.csv\n",
      "tabular_emb    : models/tabular_emb.csv\n",
      "table_startcol : 4\n",
      "task           : ADCN\n",
      "augment        : False\n",
      "split_ratio_test: 0.2\n",
      "seed           : 42\n",
      "num_epochs     : 100\n",
      "batch_size     : 6\n",
      "lr             : 1e-06\n",
      "weight_decay   : 1e-05\n",
      "fp16           : True\n",
      "checkpoint_dir : checkpoints_mmad-adcn\n",
      "nb_class       : 2\n",
      "n_splits       : 5\n",
      "dropout_rate   : 0.5\n",
      "in_channels    : 2\n",
      "seg_task       : False\n",
      "img_dim        : 512\n",
      "tab_dim        : 192\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:23:46.336020Z",
     "start_time": "2025-07-13T21:23:46.277177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "full_dataset = ADNI(cfg.label_file, cfg.mri_dir, cfg.pet_dir, cfg.task, cfg.augment)\n",
    "full_ds      = full_dataset.data_dict         # list[dict]\n",
    "labels       = [d[\"label\"] for d in full_ds]\n",
    "\n",
    "# -------------------- 划分 --------------------\n",
    "\n",
    "fold_indices = defaultdict(dict)\n",
    "outer_cv = StratifiedKFold(\n",
    "    n_splits=cfg.n_splits, shuffle=True, random_state=cfg.seed\n",
    ")\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(outer_cv.split(full_ds, labels), start=1):\n",
    "    # ——— 内层 90/10 再分验证集 ———\n",
    "    train_val_labels = [labels[i] for i in train_val_idx]\n",
    "    idxs_inner       = np.arange(len(train_val_idx))\n",
    "    train_idx_in, val_idx_in = train_test_split(\n",
    "        idxs_inner, test_size=0.125, stratify=train_val_labels, random_state=cfg.seed\n",
    "    )\n",
    "\n",
    "    # ——— 映射回 full_ds 的绝对索引 ———\n",
    "    train_idx = np.array(train_val_idx)[train_idx_in]\n",
    "    val_idx   = np.array(train_val_idx)[val_idx_in]\n",
    "\n",
    "    fold_indices[fold][\"train_idx\"] = train_idx.tolist()\n",
    "    fold_indices[fold][\"val_idx\"]   = val_idx.tolist()\n",
    "    fold_indices[fold][\"test_idx\"]  = test_idx.tolist()\n",
    "\n",
    "    print(f\"Fold {fold}: train {len(train_idx)}, val {len(val_idx)}, test {len(test_idx)}\")\n",
    "\n",
    "# -------------------- 保存 JSON --------------------\n",
    "\n",
    "os.makedirs(cfg.checkpoint_dir, exist_ok=True)\n",
    "json_path = os.path.join(cfg.checkpoint_dir, \"fold_indices.json\")\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in fold_indices.items()}, f, indent=2)\n",
    "print(f\"Fold indices saved to {json_path}\")"
   ],
   "id": "6328bbec6694dae2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ADNI Dataset: ADCN] 样本分布：\n",
      "  CN (0): 204\n",
      "  AD (1): 219\n",
      "\n",
      "Fold 1: train 295, val 43, test 85\n",
      "Fold 2: train 295, val 43, test 85\n",
      "Fold 3: train 295, val 43, test 85\n",
      "Fold 4: train 296, val 43, test 84\n",
      "Fold 5: train 296, val 43, test 84\n",
      "Fold indices saved to checkpoints_mmad-adcn\\fold_indices.json\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:23:46.674741Z",
     "start_time": "2025-07-13T21:23:46.387744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 full_ds = ADNI(...).data_dict，cfg 已定义\n",
    "json_path = os.path.join(cfg.checkpoint_dir, \"fold_indices.json\")\n",
    "csv_path  = os.path.join(cfg.table_dir)  # 请替换为你的实际文件名\n",
    "\n",
    "# 读取完整表格\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 读取 fold 索引\n",
    "with open(json_path, 'r') as f:\n",
    "    fold_indices = json.load(f)\n",
    "\n",
    "# 提取 full_ds 中的 Subject_ID 列表\n",
    "all_subjects = [entry['Subject'] for entry in full_ds]\n",
    "\n",
    "for fold_str, idxs in fold_indices.items():\n",
    "    fold = int(fold_str)\n",
    "    train_idx = idxs['train_idx']\n",
    "    val_idx   = idxs['val_idx']\n",
    "    test_idx  = idxs['test_idx']\n",
    "\n",
    "    # 根据索引得到本折的 Subject_ID 列表\n",
    "    train_subs = [ all_subjects[i] for i in train_idx ]\n",
    "    val_subs   = [ all_subjects[i] for i in val_idx   ]\n",
    "    test_subs  = [ all_subjects[i] for i in test_idx  ]\n",
    "\n",
    "    # 在原始 df 中筛出对应行\n",
    "    df_train = df[df['Subject_ID'].isin(train_subs)].reset_index(drop=True)\n",
    "    df_val   = df[df['Subject_ID'].isin(val_subs)]  .reset_index(drop=True)\n",
    "    df_test  = df[df['Subject_ID'].isin(test_subs)] .reset_index(drop=True)\n",
    "\n",
    "    # 重排列顺序：第一列 Subject_ID，第二列 Group，后面是所有其他列\n",
    "    def reorder(df_split):\n",
    "        cols = df_split.columns.tolist()\n",
    "        cols.remove('Subject_ID')\n",
    "        if 'Group' not in cols:\n",
    "            raise KeyError(\"'Group' 列未找到，请确认表格中有此列\")\n",
    "        cols.remove('Group')\n",
    "        return df_split[['Subject_ID', 'Group'] + cols]\n",
    "\n",
    "    df_train = reorder(df_train)\n",
    "    df_val   = reorder(df_val)\n",
    "    df_test  = reorder(df_test)\n",
    "\n",
    "    # 保存到各自目录\n",
    "    out_dir = os.path.join(cfg.checkpoint_dir, f\"fold{fold}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df_train.to_csv(os.path.join(out_dir, \"train.csv\"), index=False)\n",
    "    df_val  .to_csv(os.path.join(out_dir, \"val.csv\"),   index=False)\n",
    "    df_test .to_csv(os.path.join(out_dir, \"test.csv\"),  index=False)\n",
    "\n",
    "    print(f\"Fold {fold} saved:\")\n",
    "    print(f\"  train → {os.path.join(out_dir, 'train.csv')}\")\n",
    "    print(f\"  val   → {os.path.join(out_dir, 'val.csv')}\")\n",
    "    print(f\"  test  → {os.path.join(out_dir, 'test.csv')}\")\n"
   ],
   "id": "496d0f740e77f37c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 saved:\n",
      "  train → checkpoints_mmad-adcn\\fold1\\train.csv\n",
      "  val   → checkpoints_mmad-adcn\\fold1\\val.csv\n",
      "  test  → checkpoints_mmad-adcn\\fold1\\test.csv\n",
      "Fold 2 saved:\n",
      "  train → checkpoints_mmad-adcn\\fold2\\train.csv\n",
      "  val   → checkpoints_mmad-adcn\\fold2\\val.csv\n",
      "  test  → checkpoints_mmad-adcn\\fold2\\test.csv\n",
      "Fold 3 saved:\n",
      "  train → checkpoints_mmad-adcn\\fold3\\train.csv\n",
      "  val   → checkpoints_mmad-adcn\\fold3\\val.csv\n",
      "  test  → checkpoints_mmad-adcn\\fold3\\test.csv\n",
      "Fold 4 saved:\n",
      "  train → checkpoints_mmad-adcn\\fold4\\train.csv\n",
      "  val   → checkpoints_mmad-adcn\\fold4\\val.csv\n",
      "  test  → checkpoints_mmad-adcn\\fold4\\test.csv\n",
      "Fold 5 saved:\n",
      "  train → checkpoints_mmad-adcn\\fold5\\train.csv\n",
      "  val   → checkpoints_mmad-adcn\\fold5\\val.csv\n",
      "  test  → checkpoints_mmad-adcn\\fold5\\test.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:24:52.222742Z",
     "start_time": "2025-07-13T21:23:46.803398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.tabular_encoder import tabular_encoder_fold\n",
    "\n",
    "for fold in range(1, cfg.n_splits+1):\n",
    "    fold_dir = os.path.join(cfg.checkpoint_dir, f\"fold{fold}\")\n",
    "    if cfg.task == \"ADCN\":\n",
    "        classes = [\"CN\", \"AD\"]\n",
    "    elif cfg.task == \"SMCIPMCI\":\n",
    "        classes = [\"SMCI\", \"PMCI\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task: {cfg.task}\")\n",
    "    tabular_encoder_fold(\n",
    "        fold_dir    = fold_dir,\n",
    "        label_col   = \"Group\",\n",
    "        classes     = classes,\n",
    "        start_col   = 3,\n",
    "        device      = cfg.device,\n",
    "        n_fold      = 5,\n",
    "        dropna      = False\n",
    "    )\n",
    "    \n",
    "\n"
   ],
   "id": "24322c3dbde3a27a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Using device: cuda:0\n",
      "✓ Saved train_emb.csv ((295, 194))\n",
      "✓ Saved val_emb.csv ((43, 194))\n",
      "✓ Saved test_emb.csv ((85, 194))\n",
      "✓ Saved train_emb.csv ((295, 194))\n",
      "✓ Saved val_emb.csv ((43, 194))\n",
      "✓ Saved test_emb.csv ((85, 194))\n",
      "✓ Saved train_emb.csv ((295, 194))\n",
      "✓ Saved val_emb.csv ((43, 194))\n",
      "✓ Saved test_emb.csv ((85, 194))\n",
      "✓ Saved train_emb.csv ((296, 194))\n",
      "✓ Saved val_emb.csv ((43, 194))\n",
      "✓ Saved test_emb.csv ((84, 194))\n",
      "✓ Saved train_emb.csv ((296, 194))\n",
      "✓ Saved val_emb.csv ((43, 194))\n",
      "✓ Saved test_emb.csv ((84, 194))\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:24:52.719200Z",
     "start_time": "2025-07-13T21:24:52.335246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------------------------\n",
    "# 1. 建立 Subject ➜ 影像样本字典，便于快速对齐\n",
    "# -------------------------------------------------\n",
    "subject_map = {d[\"Subject\"]: d for d in full_ds}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. 为五折构造 train/val/test DataLoader\n",
    "# -------------------------------------------------\n",
    "import pandas as pd\n",
    "from monai.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_emb_csv(path):\n",
    "    \"\"\"CSV -> {sid: (label:int, emb:numpy[192])}\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    sid   = df.iloc[:, 0].astype(str).tolist()\n",
    "    label = df.iloc[:, 1].astype(int).tolist()\n",
    "    emb   = df.iloc[:, 2:].astype(\"float32\").values\n",
    "    return {s: (l, e) for s, l, e in zip(sid, label, emb)}\n",
    "\n",
    "tr_tf, vl_tf = ADNI_transform(augment=cfg.augment)\n",
    "te_tf        = vl_tf\n",
    "\n",
    "fold_loaders = []\n",
    "\n",
    "for fold in range(1, cfg.n_splits + 1):\n",
    "    fold_dir  = os.path.join(cfg.checkpoint_dir, f\"fold{fold}\")\n",
    "    paths     = {sp: os.path.join(fold_dir, f\"{sp}_emb.csv\")\n",
    "                 for sp in [\"train\", \"val\", \"test\"]}\n",
    "\n",
    "    # 解析 CSV\n",
    "    emb_maps  = {sp: load_emb_csv(p) for sp, p in paths.items()}\n",
    "\n",
    "    split_ds  = {}\n",
    "    for sp, emb_map in emb_maps.items():\n",
    "        samples = []\n",
    "        for sid, (lbl, emb) in emb_map.items():\n",
    "            if sid not in subject_map:\n",
    "                raise KeyError(f\"{sid} not found in ADNI dataset\")\n",
    "            s = subject_map[sid].copy()     # MRI / PET / label / Subject\n",
    "            s[\"label\"] = lbl                # 以 CSV 为准\n",
    "            s[\"table\"] = emb                # 192‑d numpy\n",
    "            samples.append(s)\n",
    "        split_ds[sp] = samples\n",
    "\n",
    "    # DataLoader\n",
    "    dl_kw = dict(batch_size=cfg.batch_size, pin_memory=True)\n",
    "    fold_loaders.append({\n",
    "        \"fold\": fold,\n",
    "        \"train_loader\": DataLoader(Dataset(split_ds[\"train\"], tr_tf),\n",
    "                                   shuffle=True,  num_workers=4, **dl_kw),\n",
    "        \"val_loader\":   DataLoader(Dataset(split_ds[\"val\"],   vl_tf),\n",
    "                                   shuffle=False, num_workers=2, **dl_kw),\n",
    "        \"test_loader\":  DataLoader(Dataset(split_ds[\"test\"],  te_tf),\n",
    "                                   shuffle=False, num_workers=2, **dl_kw),\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {fold}  ➜  train {len(split_ds['train'])} | \"\n",
    "          f\"val {len(split_ds['val'])} | test {len(split_ds['test'])}\")\n",
    "\n",
    "# 现在 fold_loaders 就和之前影像-only 版本一模一样可直接用于训练：\n",
    "# for fold_dict in fold_loaders:\n",
    "#     tr_loader = fold_dict[\"train_loader\"]\n",
    "#     ...\n"
   ],
   "id": "376d3ed5f64e73ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1  ➜  train 295 | val 43 | test 85\n",
      "Fold 2  ➜  train 295 | val 43 | test 85\n",
      "Fold 3  ➜  train 295 | val 43 | test 85\n",
      "Fold 4  ➜  train 296 | val 43 | test 84\n",
      "Fold 5  ➜  train 296 | val 43 | test 84\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:28:44.663167Z",
     "start_time": "2025-07-13T21:24:52.861629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inspect_fold_loaders(fold_loaders):\n",
    "    for fd in fold_loaders:\n",
    "        fold = fd[\"fold\"]\n",
    "        tl, vl, te = fd[\"train_loader\"], fd[\"val_loader\"], fd[\"test_loader\"]\n",
    "\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "        print(f\"  ▸ train_loader ─ {len(tl.dataset):4d} samples \"\n",
    "              f\"· {len(tl):3d} batches (batch={tl.batch_size})\")\n",
    "        print(f\"  ▸ val_loader   ─ {len(vl.dataset):4d} samples \"\n",
    "              f\"· {len(vl):3d} batches\")\n",
    "        print(f\"  ▸ test_loader  ─ {len(te.dataset):4d} samples \"\n",
    "              f\"· {len(te):3d} batches\")\n",
    "\n",
    "        # -------- 取一个 batch 测 shape --------\n",
    "        batch = next(iter(tl))\n",
    "        keys  = list(batch.keys())\n",
    "        print(\"  --> keys:\", keys)\n",
    "\n",
    "        mri, pet, tab, y = (batch[\"MRI\"], batch[\"PET\"],\n",
    "                            batch[\"table\"], batch[\"label\"])\n",
    "        print(f\"      MRI   : {tuple(mri.shape)}  {mri.dtype}\")\n",
    "        print(f\"      PET   : {tuple(pet.shape)}  {pet.dtype}\")\n",
    "        print(f\"      table : {tuple(tab.shape)} {tab.dtype}  \"\n",
    "              f\"(should be [B, 192])\")\n",
    "        print(f\"      label : {tuple(y.shape)}   {y.dtype}\")\n",
    "\n",
    "        # -------- 快速看标签分布 --------\n",
    "        uniq, cnt = torch.unique(y, return_counts=True)\n",
    "        dist = {int(k): int(v) for k, v in zip(uniq, cnt)}\n",
    "        print(\"      label counts:\", dist)\n",
    "\n",
    "# 调用\n",
    "inspect_fold_loaders(fold_loaders)"
   ],
   "id": "1f134b7df0745589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "  ▸ train_loader ─  295 samples ·  50 batches (batch=6)\n",
      "  ▸ val_loader   ─   43 samples ·   8 batches\n",
      "  ▸ test_loader  ─   85 samples ·  15 batches\n",
      "  --> keys: ['MRI', 'PET', 'label', 'Subject', 'table']\n",
      "      MRI   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      PET   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      table : (6, 192) torch.float32  (should be [B, 192])\n",
      "      label : (6,)   torch.int64\n",
      "      label counts: {0: 3, 1: 3}\n",
      "\n",
      "=== Fold 2 ===\n",
      "  ▸ train_loader ─  295 samples ·  50 batches (batch=6)\n",
      "  ▸ val_loader   ─   43 samples ·   8 batches\n",
      "  ▸ test_loader  ─   85 samples ·  15 batches\n",
      "  --> keys: ['MRI', 'PET', 'label', 'Subject', 'table']\n",
      "      MRI   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      PET   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      table : (6, 192) torch.float32  (should be [B, 192])\n",
      "      label : (6,)   torch.int64\n",
      "      label counts: {0: 3, 1: 3}\n",
      "\n",
      "=== Fold 3 ===\n",
      "  ▸ train_loader ─  295 samples ·  50 batches (batch=6)\n",
      "  ▸ val_loader   ─   43 samples ·   8 batches\n",
      "  ▸ test_loader  ─   85 samples ·  15 batches\n",
      "  --> keys: ['MRI', 'PET', 'label', 'Subject', 'table']\n",
      "      MRI   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      PET   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      table : (6, 192) torch.float32  (should be [B, 192])\n",
      "      label : (6,)   torch.int64\n",
      "      label counts: {0: 5, 1: 1}\n",
      "\n",
      "=== Fold 4 ===\n",
      "  ▸ train_loader ─  296 samples ·  50 batches (batch=6)\n",
      "  ▸ val_loader   ─   43 samples ·   8 batches\n",
      "  ▸ test_loader  ─   84 samples ·  14 batches\n",
      "  --> keys: ['MRI', 'PET', 'label', 'Subject', 'table']\n",
      "      MRI   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      PET   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      table : (6, 192) torch.float32  (should be [B, 192])\n",
      "      label : (6,)   torch.int64\n",
      "      label counts: {0: 3, 1: 3}\n",
      "\n",
      "=== Fold 5 ===\n",
      "  ▸ train_loader ─  296 samples ·  50 batches (batch=6)\n",
      "  ▸ val_loader   ─   43 samples ·   8 batches\n",
      "  ▸ test_loader  ─   84 samples ·  14 batches\n",
      "  --> keys: ['MRI', 'PET', 'label', 'Subject', 'table']\n",
      "      MRI   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      PET   : (6, 1, 91, 109, 91)  torch.float32\n",
      "      table : (6, 192) torch.float32  (should be [B, 192])\n",
      "      label : (6,)   torch.int64\n",
      "      label counts: {0: 4, 1: 2}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T21:28:45.021235Z",
     "start_time": "2025-07-13T21:28:44.805741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------- 创建模型 -------------------\n",
    "from models.mmad_encoder import ImageEncoder, ImageEncoder_CEN  # 根据你的命名调整\n",
    "from models.mmad_encoder import MultiModalClassifier\n",
    "def generate_image_model(cfg):\n",
    "    # 使用 CEN 版本的编码器 + 分类头\n",
    "    model = ImageEncoder_CEN(\n",
    "        in_ch_modality   = 1,\n",
    "        level_channels   = [64, 128, 256],\n",
    "        bottleneck_ch    = 512,\n",
    "        share_layers     = 2,\n",
    "        cen_ratios       = (0.20, 0.10),\n",
    "    ).to(cfg.device)\n",
    "\n",
    "    # 参数统计\n",
    "    total_params     = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    bytes_per_param  = 2 if getattr(cfg, 'fp16', False) else 4\n",
    "\n",
    "    print(\"-------------------- model --------------------\")\n",
    "    print(f\"Total params(M)    : {total_params:,}\")\n",
    "    print(f\"Trainable params(M): {trainable_params:,}\")\n",
    "    print(f\"Approx. size       : {total_params * bytes_per_param / 1024**2:.2f} MB\")\n",
    "    print(\"Model type:\", type(model).__name__)\n",
    "\n",
    "    return model\n",
    "\n",
    "def generate_mm_classifier(cfg):\n",
    "    model = MultiModalClassifier(\n",
    "        img_dim=1024,\n",
    "        tab_dim=192,\n",
    "        num_classes=2\n",
    "    ).to(cfg.device)\n",
    "    # 参数统计\n",
    "    total_params     = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    bytes_per_param  = 2 if getattr(cfg, 'fp16', False) else 4\n",
    "\n",
    "    print(\"-------------------- model --------------------\")\n",
    "    print(f\"Total params(M)    : {total_params:,}\")\n",
    "    print(f\"Trainable params(M): {trainable_params:,}\")\n",
    "    print(f\"Approx. size       : {total_params * bytes_per_param / 1024**2:.2f} MB\")\n",
    "    print(\"Model type:\", type(model).__name__)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = generate_image_model(cfg)\n",
    "model = generate_mm_classifier(cfg)\n",
    "print(model)"
   ],
   "id": "bf62256aa672099f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- model --------------------\n",
      "Total params(M)    : 13,667,328\n",
      "Trainable params(M): 13,667,328\n",
      "Approx. size       : 26.07 MB\n",
      "Model type: ImageEncoder_CEN\n",
      "-------------------- model --------------------\n",
      "Total params(M)    : 312,066\n",
      "Trainable params(M): 312,066\n",
      "Approx. size       : 0.60 MB\n",
      "Model type: MultiModalClassifier\n",
      "MultiModalClassifier(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1216, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-13T21:28:45.135085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------- 五折训练主循环 -----------------\n",
    "os.makedirs(cfg.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for fold_idx in range(cfg.n_splits):\n",
    "    fold = fold_idx + 1\n",
    "    print(f\"\\n=== Fold {fold}/{cfg.n_splits} ===\")\n",
    "\n",
    "    # ---- 模型：影像编码器 + 多模态分类器 ---- #\n",
    "    img_encoder = generate_image_model(cfg).to(cfg.device)\n",
    "    clf_model   = generate_mm_classifier(cfg).to(cfg.device)\n",
    "\n",
    "    params = list(img_encoder.parameters()) + list(clf_model.parameters())\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params, lr=cfg.lr, weight_decay=getattr(cfg, 'weight_decay', 0)\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.num_epochs)\n",
    "    scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n",
    "\n",
    "    # ---- DataLoader ---- #\n",
    "    tr_loader = fold_loaders[fold_idx]['train_loader']\n",
    "    vl_loader = fold_loaders[fold_idx]['val_loader']\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- CSV ---- #\n",
    "    csv_path = os.path.join(cfg.checkpoint_dir, f\"metrics_fold{fold}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\", \"train_Loss\",\"train_ACC\",\"train_PRE\",\"train_SEN\",\"train_SPE\",\"train_F1\",\"train_AUC\",\"train_MCC\",\n",
    "            \"val_Loss\",\"val_ACC\",\"val_PRE\",\"val_SEN\",\"val_SPE\",\"val_F1\",\"val_AUC\",\"val_MCC\",\n",
    "        ])\n",
    "\n",
    "    best_auc = -np.inf\n",
    "\n",
    "    # -------------- Epoch 循环 --------------\n",
    "    for epoch in range(1, cfg.num_epochs + 1):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # -------- Train --------\n",
    "        img_encoder.train(); clf_model.train()\n",
    "        tr_loss_sum, tr_batches = 0.0, 0\n",
    "        yt, yp, ys = [], [], []\n",
    "\n",
    "        for batch in tr_loader:\n",
    "            mri   = batch['MRI'].to(cfg.device)\n",
    "            pet   = batch['PET'].to(cfg.device)\n",
    "            table = batch['table'].to(cfg.device).float()\n",
    "            y     = batch['label'].to(cfg.device).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda', enabled=getattr(cfg, 'fp16', False)):\n",
    "                img_feat = img_encoder(mri, pet)          # [B, img_dim]\n",
    "                out      = clf_model(img_feat, table)     # [B, num_cls]\n",
    "                loss     = criterion(out, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tr_loss_sum += loss.item(); tr_batches += 1\n",
    "            prob = torch.softmax(out, dim=1)[:, 1].detach().cpu().numpy()\n",
    "            pred = out.argmax(1).detach().cpu().numpy()\n",
    "            yt.extend(y.cpu().numpy()); yp.extend(pred); ys.extend(prob)\n",
    "\n",
    "        tr_met  = calculate_metrics(yt, yp, ys)\n",
    "        tr_loss = tr_loss_sum / tr_batches\n",
    "\n",
    "        # -------- Validation --------\n",
    "        img_encoder.eval(); clf_model.eval()\n",
    "        vl_loss_sum, vl_batches = 0.0, 0\n",
    "        yt, yp, ys = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in vl_loader:\n",
    "                mri   = batch['MRI'].to(cfg.device)\n",
    "                pet   = batch['PET'].to(cfg.device)\n",
    "                table = batch['table'].to(cfg.device).float()\n",
    "                y     = batch['label'].to(cfg.device).long()\n",
    "\n",
    "                with autocast(device_type='cuda', enabled=getattr(cfg, 'fp16', False)):\n",
    "                    img_feat = img_encoder(mri, pet)\n",
    "                    out      = clf_model(img_feat, table)\n",
    "                    loss     = criterion(out, y)\n",
    "\n",
    "                vl_loss_sum += loss.item(); vl_batches += 1\n",
    "                prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "                pred = out.argmax(1).cpu().numpy()\n",
    "                yt.extend(y.cpu().numpy()); yp.extend(pred); ys.extend(prob)\n",
    "\n",
    "        vl_met  = calculate_metrics(yt, yp, ys)\n",
    "        vl_loss = vl_loss_sum / vl_batches\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Fold {fold} | Epoch {epoch:03d} | Train Loss={tr_loss:.4f} | Val Loss={vl_loss:.4f} | \"\n",
    "              f\"Train ACC={tr_met['ACC']:.4f} | Val ACC={vl_met['ACC']:.4f} | Train AUC={tr_met['AUC']:.4f} | Val AUC={vl_met['AUC']:.4f} | \"\n",
    "              f\"time={time.time()-t0:.1f}s\")\n",
    "\n",
    "        # -------- Save best model --------\n",
    "        if vl_met['AUC'] > best_auc:\n",
    "            best_auc = vl_met['AUC']\n",
    "            torch.save({\n",
    "                'img_encoder': img_encoder.state_dict(),\n",
    "                'clf_model'  : clf_model.state_dict()\n",
    "            }, os.path.join(cfg.checkpoint_dir, f\"best_model_fold{fold}.pth\"))\n",
    "            print(f\"✅ Fold {fold} saved best model (AUC={best_auc:.4f})\")\n",
    "\n",
    "        # -------- CSV log --------\n",
    "        with open(csv_path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                f\"{tr_loss:.4f}\", f\"{tr_met['ACC']:.4f}\", f\"{tr_met['PRE']:.4f}\",\n",
    "                f\"{tr_met['SEN']:.4f}\", f\"{tr_met['SPE']:.4f}\", f\"{tr_met['F1']:.4f}\", f\"{tr_met['AUC']:.4f}\", f\"{tr_met['MCC']:.4f}\",\n",
    "                f\"{vl_loss:.4f}\", f\"{vl_met['ACC']:.4f}\", f\"{vl_met['PRE']:.4f}\",\n",
    "                f\"{vl_met['SEN']:.4f}\", f\"{vl_met['SPE']:.4f}\", f\"{vl_met['F1']:.4f}\", f\"{vl_met['AUC']:.4f}\", f\"{vl_met['MCC']:.4f}\",\n",
    "            ])\n",
    "\n",
    "    print(f\"=== Fold {fold} 完成，Best AUC={best_auc:.4f} ===\")\n"
   ],
   "id": "9c33d130d251000d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "-------------------- model --------------------\n",
      "Total params(M)    : 13,667,328\n",
      "Trainable params(M): 13,667,328\n",
      "Approx. size       : 26.07 MB\n",
      "Model type: ImageEncoder_CEN\n",
      "-------------------- model --------------------\n",
      "Total params(M)    : 312,066\n",
      "Trainable params(M): 312,066\n",
      "Approx. size       : 0.60 MB\n",
      "Model type: MultiModalClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_31988\\146870631.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epoch 001 | Train Loss=0.6713 | Val Loss=0.6568 | Train ACC=0.5525 | Val ACC=0.4884 | Train AUC=0.7932 | Val AUC=1.0000 | time=205.9s\n",
      "✅ Fold 1 saved best model (AUC=1.0000)\n",
      "Fold 1 | Epoch 002 | Train Loss=0.6524 | Val Loss=0.6181 | Train ACC=0.6068 | Val ACC=0.6744 | Train AUC=0.9025 | Val AUC=1.0000 | time=205.8s\n",
      "Fold 1 | Epoch 003 | Train Loss=0.6229 | Val Loss=0.5910 | Train ACC=0.7831 | Val ACC=0.9070 | Train AUC=0.9641 | Val AUC=1.0000 | time=206.6s\n",
      "Fold 1 | Epoch 004 | Train Loss=0.6058 | Val Loss=0.5662 | Train ACC=0.8339 | Val ACC=1.0000 | Train AUC=0.9612 | Val AUC=1.0000 | time=202.4s\n",
      "Fold 1 | Epoch 005 | Train Loss=0.5789 | Val Loss=0.5408 | Train ACC=0.8949 | Val ACC=0.9535 | Train AUC=0.9754 | Val AUC=0.9978 | time=201.3s\n",
      "Fold 1 | Epoch 006 | Train Loss=0.5590 | Val Loss=0.5125 | Train ACC=0.8881 | Val ACC=0.9535 | Train AUC=0.9622 | Val AUC=0.9957 | time=201.7s\n",
      "Fold 1 | Epoch 007 | Train Loss=0.5512 | Val Loss=0.4950 | Train ACC=0.8712 | Val ACC=0.9535 | Train AUC=0.9385 | Val AUC=0.9957 | time=201.5s\n",
      "Fold 1 | Epoch 008 | Train Loss=0.5345 | Val Loss=0.4814 | Train ACC=0.8746 | Val ACC=0.9535 | Train AUC=0.9445 | Val AUC=0.9957 | time=201.2s\n",
      "Fold 1 | Epoch 009 | Train Loss=0.5114 | Val Loss=0.4627 | Train ACC=0.8814 | Val ACC=0.9535 | Train AUC=0.9599 | Val AUC=0.9935 | time=201.0s\n",
      "Fold 1 | Epoch 010 | Train Loss=0.5009 | Val Loss=0.4486 | Train ACC=0.8881 | Val ACC=0.9767 | Train AUC=0.9508 | Val AUC=0.9935 | time=201.2s\n",
      "Fold 1 | Epoch 011 | Train Loss=0.4976 | Val Loss=0.4298 | Train ACC=0.8678 | Val ACC=0.9535 | Train AUC=0.9377 | Val AUC=0.9935 | time=203.9s\n",
      "Fold 1 | Epoch 012 | Train Loss=0.4872 | Val Loss=0.4209 | Train ACC=0.8644 | Val ACC=0.9535 | Train AUC=0.9461 | Val AUC=0.9935 | time=203.6s\n",
      "Fold 1 | Epoch 013 | Train Loss=0.4712 | Val Loss=0.4048 | Train ACC=0.9017 | Val ACC=0.9535 | Train AUC=0.9537 | Val AUC=0.9935 | time=204.1s\n",
      "Fold 1 | Epoch 014 | Train Loss=0.4695 | Val Loss=0.3954 | Train ACC=0.8780 | Val ACC=0.9535 | Train AUC=0.9442 | Val AUC=0.9935 | time=202.9s\n",
      "Fold 1 | Epoch 015 | Train Loss=0.4504 | Val Loss=0.3866 | Train ACC=0.9085 | Val ACC=0.9535 | Train AUC=0.9575 | Val AUC=0.9935 | time=200.9s\n",
      "Fold 1 | Epoch 016 | Train Loss=0.4411 | Val Loss=0.3711 | Train ACC=0.8949 | Val ACC=0.9535 | Train AUC=0.9618 | Val AUC=0.9935 | time=200.8s\n",
      "Fold 1 | Epoch 017 | Train Loss=0.4415 | Val Loss=0.3633 | Train ACC=0.9119 | Val ACC=0.9767 | Train AUC=0.9594 | Val AUC=0.9935 | time=202.0s\n",
      "Fold 1 | Epoch 018 | Train Loss=0.4232 | Val Loss=0.3578 | Train ACC=0.8915 | Val ACC=0.9767 | Train AUC=0.9694 | Val AUC=0.9935 | time=203.3s\n",
      "Fold 1 | Epoch 019 | Train Loss=0.4334 | Val Loss=0.3560 | Train ACC=0.8746 | Val ACC=0.9767 | Train AUC=0.9497 | Val AUC=1.0000 | time=203.4s\n",
      "Fold 1 | Epoch 020 | Train Loss=0.4116 | Val Loss=0.3383 | Train ACC=0.9119 | Val ACC=0.9767 | Train AUC=0.9717 | Val AUC=0.9957 | time=202.8s\n",
      "Fold 1 | Epoch 021 | Train Loss=0.4056 | Val Loss=0.3388 | Train ACC=0.9051 | Val ACC=0.9767 | Train AUC=0.9760 | Val AUC=1.0000 | time=204.1s\n",
      "Fold 1 | Epoch 022 | Train Loss=0.4044 | Val Loss=0.3228 | Train ACC=0.9017 | Val ACC=0.9767 | Train AUC=0.9671 | Val AUC=1.0000 | time=203.1s\n",
      "Fold 1 | Epoch 023 | Train Loss=0.4033 | Val Loss=0.3235 | Train ACC=0.9254 | Val ACC=0.9767 | Train AUC=0.9704 | Val AUC=1.0000 | time=203.4s\n",
      "Fold 1 | Epoch 024 | Train Loss=0.3977 | Val Loss=0.3439 | Train ACC=0.9254 | Val ACC=0.9767 | Train AUC=0.9731 | Val AUC=1.0000 | time=204.1s\n",
      "Fold 1 | Epoch 025 | Train Loss=0.3698 | Val Loss=0.3042 | Train ACC=0.9322 | Val ACC=0.9767 | Train AUC=0.9791 | Val AUC=1.0000 | time=206.5s\n",
      "Fold 1 | Epoch 026 | Train Loss=0.3616 | Val Loss=0.2904 | Train ACC=0.9322 | Val ACC=0.9767 | Train AUC=0.9850 | Val AUC=1.0000 | time=201.7s\n",
      "Fold 1 | Epoch 027 | Train Loss=0.3787 | Val Loss=0.2845 | Train ACC=0.9119 | Val ACC=1.0000 | Train AUC=0.9751 | Val AUC=1.0000 | time=202.6s\n",
      "Fold 1 | Epoch 028 | Train Loss=0.3607 | Val Loss=0.2798 | Train ACC=0.9254 | Val ACC=1.0000 | Train AUC=0.9840 | Val AUC=1.0000 | time=203.8s\n",
      "Fold 1 | Epoch 029 | Train Loss=0.3461 | Val Loss=0.2828 | Train ACC=0.9356 | Val ACC=0.9767 | Train AUC=0.9872 | Val AUC=1.0000 | time=203.0s\n",
      "Fold 1 | Epoch 030 | Train Loss=0.3500 | Val Loss=0.2713 | Train ACC=0.9390 | Val ACC=1.0000 | Train AUC=0.9855 | Val AUC=1.0000 | time=203.3s\n",
      "Fold 1 | Epoch 031 | Train Loss=0.3519 | Val Loss=0.2725 | Train ACC=0.9390 | Val ACC=0.9767 | Train AUC=0.9866 | Val AUC=1.0000 | time=203.4s\n",
      "Fold 1 | Epoch 032 | Train Loss=0.3276 | Val Loss=0.2522 | Train ACC=0.9458 | Val ACC=1.0000 | Train AUC=0.9885 | Val AUC=1.0000 | time=203.1s\n",
      "Fold 1 | Epoch 033 | Train Loss=0.3385 | Val Loss=0.2606 | Train ACC=0.9288 | Val ACC=0.9767 | Train AUC=0.9851 | Val AUC=1.0000 | time=202.3s\n",
      "Fold 1 | Epoch 034 | Train Loss=0.3218 | Val Loss=0.2357 | Train ACC=0.9559 | Val ACC=1.0000 | Train AUC=0.9926 | Val AUC=1.0000 | time=203.3s\n",
      "Fold 1 | Epoch 035 | Train Loss=0.3166 | Val Loss=0.2362 | Train ACC=0.9390 | Val ACC=1.0000 | Train AUC=0.9892 | Val AUC=1.0000 | time=204.0s\n",
      "Fold 1 | Epoch 036 | Train Loss=0.3175 | Val Loss=0.2335 | Train ACC=0.9661 | Val ACC=0.9767 | Train AUC=0.9912 | Val AUC=1.0000 | time=203.3s\n",
      "Fold 1 | Epoch 037 | Train Loss=0.3075 | Val Loss=0.2340 | Train ACC=0.9492 | Val ACC=1.0000 | Train AUC=0.9879 | Val AUC=1.0000 | time=201.6s\n",
      "Fold 1 | Epoch 038 | Train Loss=0.2970 | Val Loss=0.2249 | Train ACC=0.9593 | Val ACC=1.0000 | Train AUC=0.9937 | Val AUC=1.0000 | time=201.2s\n",
      "Fold 1 | Epoch 039 | Train Loss=0.2824 | Val Loss=0.2194 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9914 | Val AUC=1.0000 | time=201.1s\n",
      "Fold 1 | Epoch 040 | Train Loss=0.3026 | Val Loss=0.2173 | Train ACC=0.9458 | Val ACC=1.0000 | Train AUC=0.9866 | Val AUC=1.0000 | time=201.6s\n",
      "Fold 1 | Epoch 041 | Train Loss=0.2822 | Val Loss=0.2363 | Train ACC=0.9627 | Val ACC=1.0000 | Train AUC=0.9947 | Val AUC=1.0000 | time=201.8s\n",
      "Fold 1 | Epoch 042 | Train Loss=0.2903 | Val Loss=0.2331 | Train ACC=0.9559 | Val ACC=1.0000 | Train AUC=0.9909 | Val AUC=1.0000 | time=200.5s\n",
      "Fold 1 | Epoch 043 | Train Loss=0.2858 | Val Loss=0.2249 | Train ACC=0.9559 | Val ACC=1.0000 | Train AUC=0.9909 | Val AUC=1.0000 | time=201.0s\n",
      "Fold 1 | Epoch 044 | Train Loss=0.2916 | Val Loss=0.2114 | Train ACC=0.9627 | Val ACC=1.0000 | Train AUC=0.9914 | Val AUC=1.0000 | time=203.8s\n",
      "Fold 1 | Epoch 045 | Train Loss=0.2843 | Val Loss=0.2018 | Train ACC=0.9458 | Val ACC=0.9767 | Train AUC=0.9905 | Val AUC=1.0000 | time=202.8s\n",
      "Fold 1 | Epoch 046 | Train Loss=0.2779 | Val Loss=0.2708 | Train ACC=0.9525 | Val ACC=0.9767 | Train AUC=0.9939 | Val AUC=1.0000 | time=203.4s\n",
      "Fold 1 | Epoch 047 | Train Loss=0.2532 | Val Loss=0.1926 | Train ACC=0.9729 | Val ACC=0.9767 | Train AUC=0.9949 | Val AUC=1.0000 | time=202.2s\n",
      "Fold 1 | Epoch 048 | Train Loss=0.2686 | Val Loss=0.1916 | Train ACC=0.9559 | Val ACC=1.0000 | Train AUC=0.9907 | Val AUC=1.0000 | time=201.5s\n",
      "Fold 1 | Epoch 049 | Train Loss=0.2626 | Val Loss=0.2092 | Train ACC=0.9695 | Val ACC=1.0000 | Train AUC=0.9929 | Val AUC=1.0000 | time=201.1s\n",
      "Fold 1 | Epoch 050 | Train Loss=0.2639 | Val Loss=0.1900 | Train ACC=0.9729 | Val ACC=0.9767 | Train AUC=0.9894 | Val AUC=1.0000 | time=200.9s\n",
      "Fold 1 | Epoch 051 | Train Loss=0.2498 | Val Loss=0.1834 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9962 | Val AUC=1.0000 | time=200.9s\n",
      "Fold 1 | Epoch 052 | Train Loss=0.2648 | Val Loss=0.2056 | Train ACC=0.9525 | Val ACC=1.0000 | Train AUC=0.9913 | Val AUC=1.0000 | time=200.3s\n",
      "Fold 1 | Epoch 053 | Train Loss=0.2555 | Val Loss=0.1841 | Train ACC=0.9593 | Val ACC=1.0000 | Train AUC=0.9928 | Val AUC=1.0000 | time=202.3s\n",
      "Fold 1 | Epoch 054 | Train Loss=0.2407 | Val Loss=0.1752 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9950 | Val AUC=1.0000 | time=203.0s\n",
      "Fold 1 | Epoch 055 | Train Loss=0.2377 | Val Loss=0.1721 | Train ACC=0.9492 | Val ACC=1.0000 | Train AUC=0.9954 | Val AUC=1.0000 | time=203.4s\n",
      "Fold 1 | Epoch 056 | Train Loss=0.2609 | Val Loss=0.1934 | Train ACC=0.9559 | Val ACC=1.0000 | Train AUC=0.9930 | Val AUC=1.0000 | time=203.9s\n",
      "Fold 1 | Epoch 057 | Train Loss=0.2526 | Val Loss=0.1703 | Train ACC=0.9559 | Val ACC=1.0000 | Train AUC=0.9926 | Val AUC=1.0000 | time=203.2s\n",
      "Fold 1 | Epoch 058 | Train Loss=0.2547 | Val Loss=0.1762 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9956 | Val AUC=1.0000 | time=201.1s\n",
      "Fold 1 | Epoch 059 | Train Loss=0.2560 | Val Loss=0.1722 | Train ACC=0.9525 | Val ACC=1.0000 | Train AUC=0.9945 | Val AUC=1.0000 | time=201.2s\n",
      "Fold 1 | Epoch 060 | Train Loss=0.2440 | Val Loss=0.1719 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9953 | Val AUC=1.0000 | time=201.2s\n",
      "Fold 1 | Epoch 061 | Train Loss=0.2355 | Val Loss=0.1707 | Train ACC=0.9695 | Val ACC=0.9535 | Train AUC=0.9963 | Val AUC=1.0000 | time=201.1s\n",
      "Fold 1 | Epoch 062 | Train Loss=0.2437 | Val Loss=0.1693 | Train ACC=0.9525 | Val ACC=1.0000 | Train AUC=0.9967 | Val AUC=1.0000 | time=200.6s\n",
      "Fold 1 | Epoch 063 | Train Loss=0.2263 | Val Loss=0.1668 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9971 | Val AUC=1.0000 | time=200.8s\n",
      "Fold 1 | Epoch 064 | Train Loss=0.2223 | Val Loss=0.1790 | Train ACC=0.9627 | Val ACC=0.9767 | Train AUC=0.9957 | Val AUC=1.0000 | time=202.5s\n",
      "Fold 1 | Epoch 065 | Train Loss=0.2495 | Val Loss=0.1625 | Train ACC=0.9525 | Val ACC=1.0000 | Train AUC=0.9951 | Val AUC=1.0000 | time=203.2s\n",
      "Fold 1 | Epoch 066 | Train Loss=0.2394 | Val Loss=0.1610 | Train ACC=0.9695 | Val ACC=1.0000 | Train AUC=0.9955 | Val AUC=1.0000 | time=203.6s\n",
      "Fold 1 | Epoch 067 | Train Loss=0.2290 | Val Loss=0.1606 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9932 | Val AUC=1.0000 | time=203.3s\n",
      "Fold 1 | Epoch 068 | Train Loss=0.2301 | Val Loss=0.1535 | Train ACC=0.9797 | Val ACC=1.0000 | Train AUC=0.9965 | Val AUC=1.0000 | time=201.7s\n",
      "Fold 1 | Epoch 069 | Train Loss=0.2227 | Val Loss=0.1555 | Train ACC=0.9695 | Val ACC=1.0000 | Train AUC=0.9965 | Val AUC=1.0000 | time=201.2s\n",
      "Fold 1 | Epoch 070 | Train Loss=0.2435 | Val Loss=0.1571 | Train ACC=0.9627 | Val ACC=1.0000 | Train AUC=0.9933 | Val AUC=1.0000 | time=201.0s\n",
      "Fold 1 | Epoch 071 | Train Loss=0.2337 | Val Loss=0.1681 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9942 | Val AUC=1.0000 | time=201.8s\n",
      "Fold 1 | Epoch 072 | Train Loss=0.2324 | Val Loss=0.1597 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9937 | Val AUC=1.0000 | time=203.5s\n",
      "Fold 1 | Epoch 073 | Train Loss=0.2323 | Val Loss=0.1523 | Train ACC=0.9593 | Val ACC=1.0000 | Train AUC=0.9955 | Val AUC=1.0000 | time=202.6s\n",
      "Fold 1 | Epoch 074 | Train Loss=0.2183 | Val Loss=0.1553 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9973 | Val AUC=1.0000 | time=202.2s\n",
      "Fold 1 | Epoch 075 | Train Loss=0.2217 | Val Loss=0.1691 | Train ACC=0.9831 | Val ACC=1.0000 | Train AUC=0.9960 | Val AUC=1.0000 | time=203.7s\n",
      "Fold 1 | Epoch 076 | Train Loss=0.2160 | Val Loss=0.1587 | Train ACC=0.9695 | Val ACC=1.0000 | Train AUC=0.9971 | Val AUC=1.0000 | time=204.1s\n",
      "Fold 1 | Epoch 077 | Train Loss=0.2240 | Val Loss=0.1628 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9963 | Val AUC=1.0000 | time=204.5s\n",
      "Fold 1 | Epoch 078 | Train Loss=0.2194 | Val Loss=0.1508 | Train ACC=0.9729 | Val ACC=1.0000 | Train AUC=0.9953 | Val AUC=1.0000 | time=203.2s\n",
      "Fold 1 | Epoch 079 | Train Loss=0.2284 | Val Loss=0.1525 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9954 | Val AUC=1.0000 | time=201.1s\n",
      "Fold 1 | Epoch 080 | Train Loss=0.2254 | Val Loss=0.1532 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9986 | Val AUC=1.0000 | time=202.3s\n",
      "Fold 1 | Epoch 081 | Train Loss=0.2277 | Val Loss=0.1513 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9965 | Val AUC=1.0000 | time=202.4s\n",
      "Fold 1 | Epoch 082 | Train Loss=0.2139 | Val Loss=0.1633 | Train ACC=0.9729 | Val ACC=1.0000 | Train AUC=0.9958 | Val AUC=1.0000 | time=204.2s\n",
      "Fold 1 | Epoch 083 | Train Loss=0.2196 | Val Loss=0.1498 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9966 | Val AUC=1.0000 | time=202.6s\n",
      "Fold 1 | Epoch 084 | Train Loss=0.2316 | Val Loss=0.1586 | Train ACC=0.9627 | Val ACC=1.0000 | Train AUC=0.9937 | Val AUC=1.0000 | time=201.4s\n",
      "Fold 1 | Epoch 085 | Train Loss=0.2189 | Val Loss=0.1480 | Train ACC=0.9661 | Val ACC=1.0000 | Train AUC=0.9977 | Val AUC=1.0000 | time=202.5s\n",
      "Fold 1 | Epoch 086 | Train Loss=0.2077 | Val Loss=0.1546 | Train ACC=0.9831 | Val ACC=1.0000 | Train AUC=0.9980 | Val AUC=1.0000 | time=203.1s\n",
      "Fold 1 | Epoch 087 | Train Loss=0.2349 | Val Loss=0.1558 | Train ACC=0.9492 | Val ACC=1.0000 | Train AUC=0.9918 | Val AUC=1.0000 | time=204.7s\n",
      "Fold 1 | Epoch 088 | Train Loss=0.2078 | Val Loss=0.1487 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9982 | Val AUC=1.0000 | time=203.4s\n",
      "Fold 1 | Epoch 089 | Train Loss=0.2153 | Val Loss=0.1731 | Train ACC=0.9729 | Val ACC=0.9767 | Train AUC=0.9944 | Val AUC=1.0000 | time=204.4s\n",
      "Fold 1 | Epoch 090 | Train Loss=0.2109 | Val Loss=0.1577 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9983 | Val AUC=1.0000 | time=204.0s\n",
      "Fold 1 | Epoch 091 | Train Loss=0.2139 | Val Loss=0.1510 | Train ACC=0.9729 | Val ACC=1.0000 | Train AUC=0.9964 | Val AUC=1.0000 | time=204.1s\n",
      "Fold 1 | Epoch 092 | Train Loss=0.2145 | Val Loss=0.1523 | Train ACC=0.9627 | Val ACC=1.0000 | Train AUC=0.9966 | Val AUC=1.0000 | time=203.0s\n",
      "Fold 1 | Epoch 093 | Train Loss=0.2032 | Val Loss=0.1472 | Train ACC=0.9797 | Val ACC=1.0000 | Train AUC=0.9976 | Val AUC=1.0000 | time=204.2s\n",
      "Fold 1 | Epoch 094 | Train Loss=0.2233 | Val Loss=0.1510 | Train ACC=0.9593 | Val ACC=1.0000 | Train AUC=0.9912 | Val AUC=1.0000 | time=202.7s\n",
      "Fold 1 | Epoch 095 | Train Loss=0.2077 | Val Loss=0.1553 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9980 | Val AUC=1.0000 | time=202.3s\n",
      "Fold 1 | Epoch 096 | Train Loss=0.2187 | Val Loss=0.1478 | Train ACC=0.9729 | Val ACC=1.0000 | Train AUC=0.9960 | Val AUC=1.0000 | time=202.5s\n",
      "Fold 1 | Epoch 097 | Train Loss=0.2434 | Val Loss=0.1733 | Train ACC=0.9492 | Val ACC=0.9767 | Train AUC=0.9910 | Val AUC=1.0000 | time=203.3s\n",
      "Fold 1 | Epoch 098 | Train Loss=0.2118 | Val Loss=0.1587 | Train ACC=0.9729 | Val ACC=1.0000 | Train AUC=0.9968 | Val AUC=1.0000 | time=204.9s\n",
      "Fold 1 | Epoch 099 | Train Loss=0.1991 | Val Loss=0.1499 | Train ACC=0.9763 | Val ACC=1.0000 | Train AUC=0.9965 | Val AUC=1.0000 | time=203.5s\n",
      "Fold 1 | Epoch 100 | Train Loss=0.2272 | Val Loss=0.1553 | Train ACC=0.9627 | Val ACC=1.0000 | Train AUC=0.9962 | Val AUC=1.0000 | time=202.4s\n",
      "=== Fold 1 完成，Best AUC=1.0000 ===\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "-------------------- model --------------------\n",
      "Total params(M)    : 13,667,328\n",
      "Trainable params(M): 13,667,328\n",
      "Approx. size       : 26.07 MB\n",
      "Model type: ImageEncoder_CEN\n",
      "-------------------- model --------------------\n",
      "Total params(M)    : 312,066\n",
      "Trainable params(M): 312,066\n",
      "Approx. size       : 0.60 MB\n",
      "Model type: MultiModalClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_31988\\146870631.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 | Epoch 001 | Train Loss=0.6866 | Val Loss=0.6643 | Train ACC=0.5119 | Val ACC=0.4884 | Train AUC=0.6860 | Val AUC=1.0000 | time=201.3s\n",
      "✅ Fold 2 saved best model (AUC=1.0000)\n",
      "Fold 2 | Epoch 002 | Train Loss=0.6666 | Val Loss=0.6443 | Train ACC=0.5932 | Val ACC=0.6512 | Train AUC=0.8443 | Val AUC=1.0000 | time=200.6s\n",
      "Fold 2 | Epoch 003 | Train Loss=0.6470 | Val Loss=0.6239 | Train ACC=0.7085 | Val ACC=0.8605 | Train AUC=0.9314 | Val AUC=1.0000 | time=200.9s\n",
      "Fold 2 | Epoch 004 | Train Loss=0.6271 | Val Loss=0.6046 | Train ACC=0.8068 | Val ACC=0.9070 | Train AUC=0.9685 | Val AUC=1.0000 | time=201.8s\n",
      "Fold 2 | Epoch 005 | Train Loss=0.6125 | Val Loss=0.5822 | Train ACC=0.8102 | Val ACC=0.9302 | Train AUC=0.9628 | Val AUC=0.9946 | time=201.3s\n",
      "Fold 2 | Epoch 006 | Train Loss=0.5842 | Val Loss=0.5628 | Train ACC=0.8814 | Val ACC=0.9070 | Train AUC=0.9655 | Val AUC=0.9784 | time=202.1s\n",
      "Fold 2 | Epoch 007 | Train Loss=0.5675 | Val Loss=0.5405 | Train ACC=0.8712 | Val ACC=0.8372 | Train AUC=0.9397 | Val AUC=0.9632 | time=204.1s\n",
      "Fold 2 | Epoch 008 | Train Loss=0.5429 | Val Loss=0.5368 | Train ACC=0.8542 | Val ACC=0.8605 | Train AUC=0.9515 | Val AUC=0.9610 | time=205.0s\n",
      "Fold 2 | Epoch 009 | Train Loss=0.5310 | Val Loss=0.5119 | Train ACC=0.8475 | Val ACC=0.8372 | Train AUC=0.9371 | Val AUC=0.9459 | time=203.5s\n",
      "Fold 2 | Epoch 010 | Train Loss=0.5142 | Val Loss=0.4987 | Train ACC=0.8373 | Val ACC=0.8140 | Train AUC=0.9299 | Val AUC=0.9459 | time=202.3s\n",
      "Fold 2 | Epoch 011 | Train Loss=0.5039 | Val Loss=0.4838 | Train ACC=0.8542 | Val ACC=0.8140 | Train AUC=0.9352 | Val AUC=0.9394 | time=201.1s\n",
      "Fold 2 | Epoch 012 | Train Loss=0.4827 | Val Loss=0.4791 | Train ACC=0.8644 | Val ACC=0.8140 | Train AUC=0.9459 | Val AUC=0.9502 | time=202.8s\n",
      "Fold 2 | Epoch 013 | Train Loss=0.4720 | Val Loss=0.4621 | Train ACC=0.8780 | Val ACC=0.8372 | Train AUC=0.9509 | Val AUC=0.9394 | time=201.9s\n",
      "Fold 2 | Epoch 014 | Train Loss=0.4806 | Val Loss=0.4593 | Train ACC=0.8271 | Val ACC=0.8372 | Train AUC=0.9282 | Val AUC=0.9535 | time=202.2s\n",
      "Fold 2 | Epoch 015 | Train Loss=0.4629 | Val Loss=0.4464 | Train ACC=0.8610 | Val ACC=0.8372 | Train AUC=0.9435 | Val AUC=0.9459 | time=200.7s\n",
      "Fold 2 | Epoch 016 | Train Loss=0.4471 | Val Loss=0.4594 | Train ACC=0.8746 | Val ACC=0.8605 | Train AUC=0.9534 | Val AUC=0.9675 | time=202.7s\n",
      "Fold 2 | Epoch 017 | Train Loss=0.4500 | Val Loss=0.4369 | Train ACC=0.8746 | Val ACC=0.8605 | Train AUC=0.9523 | Val AUC=0.9675 | time=202.6s\n",
      "Fold 2 | Epoch 018 | Train Loss=0.4395 | Val Loss=0.4173 | Train ACC=0.8780 | Val ACC=0.9302 | Train AUC=0.9548 | Val AUC=0.9719 | time=203.7s\n",
      "Fold 2 | Epoch 019 | Train Loss=0.4298 | Val Loss=0.4144 | Train ACC=0.8847 | Val ACC=0.8605 | Train AUC=0.9576 | Val AUC=0.9719 | time=206.4s\n",
      "Fold 2 | Epoch 020 | Train Loss=0.4229 | Val Loss=0.4137 | Train ACC=0.8915 | Val ACC=0.8837 | Train AUC=0.9639 | Val AUC=0.9719 | time=221.4s\n",
      "Fold 2 | Epoch 021 | Train Loss=0.4165 | Val Loss=0.3968 | Train ACC=0.8915 | Val ACC=0.9070 | Train AUC=0.9644 | Val AUC=0.9708 | time=221.4s\n",
      "Fold 2 | Epoch 022 | Train Loss=0.4049 | Val Loss=0.4054 | Train ACC=0.8983 | Val ACC=0.8837 | Train AUC=0.9728 | Val AUC=0.9816 | time=217.9s\n",
      "Fold 2 | Epoch 023 | Train Loss=0.4069 | Val Loss=0.3918 | Train ACC=0.8915 | Val ACC=0.8837 | Train AUC=0.9688 | Val AUC=0.9827 | time=219.4s\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# -------------------- 测试 -----------------------------\n",
   "id": "18d7ee81fb5ed447"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
