{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:10:54.746035Z",
     "start_time": "2025-07-11T14:10:43.059908Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, json, time, csv, numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets.ADNI import ADNI, ADNI_transform\n",
    "from monai.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, matthews_corrcoef,\n",
    "                             confusion_matrix, roc_curve, auc)\n",
    "from models.unet3d import UNet3DClassifier, UNet3D, DualStreamUNet3DClassifier\n",
    "from utils.metrics import calculate_metrics\n",
    "from torch.multiprocessing import freeze_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:10:55.824738Z",
     "start_time": "2025-07-11T14:10:55.810748Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------- 配置 --------------------\n",
    "def load_cfg(path):\n",
    "    with open(path) as f: \n",
    "        return json.load(f)\n",
    "\n",
    "class Cfg:\n",
    "    def __init__(self, d):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        for k, v in d.items(): \n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:10:57.200864Z",
     "start_time": "2025-07-11T14:10:57.179955Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------- 创建模型 -------------------\n",
    "def generate_model(cfg):\n",
    "    model = DualStreamUNet3DClassifier(\n",
    "        in_channels_per_modality=1,    # MRI/PET 各 1 个通道\n",
    "        num_classes=cfg.nb_class,      # e.g. 2 (AD vs CN)\n",
    "        level_channels=[64, 128, 256], # 与单流 UNet3D 保持一致\n",
    "        bottleneck_channel=512\n",
    "    ).to(cfg.device)\n",
    "\n",
    "    # 参数统计\n",
    "    total_params     = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    bytes_per_param  = 2 if getattr(cfg, 'fp16', False) else 4\n",
    "    print(\"--------------------model------------------\")\n",
    "    print(f\"Total params(M)    : {total_params:,}\")\n",
    "    print(f\"Trainable params(M): {trainable_params:,}\")\n",
    "    print(f\"Approx. size       : {total_params*bytes_per_param/1024**2:.2f} MB\")\n",
    "    print(\"model type:\", type(model).__name__)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:10:58.582337Z",
     "start_time": "2025-07-11T14:10:58.528572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device         : cuda:0\n",
      "label_file     : C:/Users/dongzj/Desktop/Multimodal_AD/adni_dataset/ADNI_902.csv\n",
      "mri_dir        : C:/Users/dongzj/Desktop/Multimodal_AD/adni_dataset/MRI\n",
      "pet_dir        : C:/Users/dongzj/Desktop/Multimodal_AD/adni_dataset/PET\n",
      "task           : ADCN\n",
      "augment        : False\n",
      "split_ratio_test: 0.2\n",
      "seed           : 42\n",
      "num_epochs     : 100\n",
      "batch_size     : 8\n",
      "lr             : 1e-06\n",
      "weight_decay   : 1e-05\n",
      "fp16           : True\n",
      "checkpoint_dir : C:/Users/dongzj/Desktop/ex_result/Ablation_unet3d_2stream/checkpoints_two_encoder-adcn\n",
      "nb_class       : 2\n",
      "n_splits       : 5\n",
      "dropout_rate   : 0.5\n",
      "in_channels    : 2\n",
      "seg_task       : False\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 加载配置 -------------------\n",
    "config_path = rf\"C:\\Users\\dongzj\\Desktop\\mmad\\unet3d_multi\\config\\config_unet3d_2stream.json\"\n",
    "cfg = Cfg(load_cfg(config_path))\n",
    "for name, val in vars(cfg).items():\n",
    "    print(f\"{name:15s}: {val}\")\n",
    "writer = SummaryWriter(cfg.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T14:11:00.027505Z",
     "start_time": "2025-07-11T14:10:59.930931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ADNI Dataset: ADCN] 样本分布：\n",
      "  CN (0): 204\n",
      "  AD (1): 219\n",
      "\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "训练集样本数: 295  (69.7%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 85  (20.1%)\n",
      "fold indices saved to checkpoints_two_encoder\\fold_indices.json\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "训练集样本数: 295  (69.7%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 85  (20.1%)\n",
      "fold indices saved to checkpoints_two_encoder\\fold_indices.json\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "训练集样本数: 295  (69.7%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 85  (20.1%)\n",
      "fold indices saved to checkpoints_two_encoder\\fold_indices.json\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "训练集样本数: 296  (70.0%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 84  (19.9%)\n",
      "fold indices saved to checkpoints_two_encoder\\fold_indices.json\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "训练集样本数: 296  (70.0%)\n",
      "验证集样本数: 43  (10.2%)\n",
      "测试集样本数: 84  (19.9%)\n",
      "fold indices saved to checkpoints_two_encoder\\fold_indices.json\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 划分数据 -------------------\n",
    "fold_loaders = []                  # ⬅️ 所有折的 DataLoader 都收集到这里\n",
    "fold_indices = defaultdict(dict)   # 可选：若想保存索引，方便调试\n",
    "\n",
    "full_ds = ADNI(cfg.label_file, cfg.mri_dir, cfg.pet_dir,cfg.task, cfg.augment).data_dict\n",
    "labels  = [d['label'] for d in full_ds]\n",
    "\n",
    "outer_cv = StratifiedKFold(\n",
    "    n_splits=cfg.n_splits,     # 5 折\n",
    "    shuffle=True,\n",
    "    random_state=cfg.seed\n",
    ")\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(outer_cv.split(full_ds, labels), start=1):\n",
    "    train_val_ds = [full_ds[i] for i in train_val_idx]\n",
    "    test_ds      = [full_ds[i] for i in test_idx]\n",
    "\n",
    "    # —— 内层 90/10 分出验证集 —— #\n",
    "    labels_train_val = [d['label'] for d in train_val_ds]\n",
    "    idxs = np.arange(len(train_val_ds))\n",
    "    train_idx_, val_idx_ = train_test_split(\n",
    "        idxs, test_size=0.125, stratify=labels_train_val, random_state=cfg.seed\n",
    "    )\n",
    "    train_ds = [train_val_ds[i] for i in train_idx_]\n",
    "    val_ds   = [train_val_ds[i] for i in val_idx_]\n",
    "\n",
    "    print(f\"\\n=== Fold {fold}/{cfg.n_splits} ===\")\n",
    "    print(f\"训练集样本数: {len(train_ds)}  ({len(train_ds)/len(full_ds):.1%})\")\n",
    "    print(f\"验证集样本数: {len(val_ds)}  ({len(val_ds)/len(full_ds):.1%})\")\n",
    "    print(f\"测试集样本数: {len(test_ds)}  ({len(test_ds)/len(full_ds):.1%})\")\n",
    "    # —— 构造 DataLoader —— #\n",
    "    tr_tf, vl_tf = ADNI_transform(augment=cfg.augment)\n",
    "    te_tf        = vl_tf      # 测试不做增强\n",
    "    \n",
    "    tr_loader = DataLoader(\n",
    "        Dataset(train_ds, tr_tf),\n",
    "        batch_size=cfg.batch_size, shuffle=True,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    vl_loader = DataLoader(\n",
    "        Dataset(val_ds, vl_tf),\n",
    "        batch_size=cfg.batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        Dataset(test_ds, te_tf),\n",
    "        batch_size=cfg.batch_size, shuffle=False,\n",
    "        num_workers=2, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # —— 保存到列表 —— #\n",
    "    fold_loaders.append({\n",
    "        \"fold\"        : fold,\n",
    "        \"train_loader\": tr_loader,\n",
    "        \"val_loader\"  : vl_loader,\n",
    "        \"test_loader\" : test_loader\n",
    "    })\n",
    "    \n",
    "    # （可选）保存索引，便于日后溯源\n",
    "    fold_indices[fold][\"train_idx\"] = train_idx_\n",
    "    fold_indices[fold][\"val_idx\"]   = val_idx_\n",
    "    fold_indices[fold][\"test_idx\"]  = test_idx\n",
    "    \n",
    "    # 现在 fold_loaders[0] ~ fold_loaders[4] 就是 5 组 train/val/test DataLoader\n",
    "    \n",
    "    save_path = os.path.join(cfg.checkpoint_dir, \"fold_indices.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        serializable = {\n",
    "            str(fold): {\n",
    "                \"train_idx\": v[\"train_idx\"].tolist(),\n",
    "                \"val_idx\"  : v[\"val_idx\"].tolist(),\n",
    "                \"test_idx\" : v[\"test_idx\"].tolist(),\n",
    "            }\n",
    "            for fold, v in fold_indices.items()\n",
    "        }\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    print(f\"fold indices saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T05:32:57.048893Z",
     "start_time": "2025-07-11T14:11:02.033653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "--------------------model------------------\n",
      "Total params(M)    : 14,057,602\n",
      "Trainable params(M): 14,057,602\n",
      "Approx. size       : 26.81 MB\n",
      "model type: DualStreamUNet3DClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_24072\\1643430249.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | Epoch 001 | Train Loss=0.7074 | Val Loss=0.6854 | Train ACC=0.5186 | Val ACC=0.5116 | Train AUC=0.6535 | Val AUC=0.8247 | time=168.8s\n",
      "✅ Fold 1 saved best model (AUC=0.8247)\n",
      "Fold 1 | Epoch 002 | Train Loss=0.6836 | Val Loss=0.6278 | Train ACC=0.5186 | Val ACC=0.6279 | Train AUC=0.7134 | Val AUC=0.8766 | time=172.3s\n",
      "✅ Fold 1 saved best model (AUC=0.8766)\n",
      "Fold 1 | Epoch 003 | Train Loss=0.6615 | Val Loss=0.5886 | Train ACC=0.5525 | Val ACC=0.6512 | Train AUC=0.7224 | Val AUC=0.8864 | time=176.8s\n",
      "✅ Fold 1 saved best model (AUC=0.8864)\n",
      "Fold 1 | Epoch 004 | Train Loss=0.6459 | Val Loss=0.5590 | Train ACC=0.6373 | Val ACC=0.8140 | Train AUC=0.7226 | Val AUC=0.8929 | time=176.9s\n",
      "✅ Fold 1 saved best model (AUC=0.8929)\n",
      "Fold 1 | Epoch 005 | Train Loss=0.6299 | Val Loss=0.5342 | Train ACC=0.6542 | Val ACC=0.7674 | Train AUC=0.7335 | Val AUC=0.8983 | time=174.8s\n",
      "✅ Fold 1 saved best model (AUC=0.8983)\n",
      "Fold 1 | Epoch 006 | Train Loss=0.6184 | Val Loss=0.5114 | Train ACC=0.6542 | Val ACC=0.8140 | Train AUC=0.7372 | Val AUC=0.9048 | time=169.9s\n",
      "✅ Fold 1 saved best model (AUC=0.9048)\n",
      "Fold 1 | Epoch 007 | Train Loss=0.6092 | Val Loss=0.4968 | Train ACC=0.6915 | Val ACC=0.8140 | Train AUC=0.7431 | Val AUC=0.9113 | time=170.6s\n",
      "✅ Fold 1 saved best model (AUC=0.9113)\n",
      "Fold 1 | Epoch 008 | Train Loss=0.6113 | Val Loss=0.4982 | Train ACC=0.6610 | Val ACC=0.8140 | Train AUC=0.7337 | Val AUC=0.9134 | time=172.1s\n",
      "✅ Fold 1 saved best model (AUC=0.9134)\n",
      "Fold 1 | Epoch 009 | Train Loss=0.5934 | Val Loss=0.4821 | Train ACC=0.6983 | Val ACC=0.8372 | Train AUC=0.7633 | Val AUC=0.9177 | time=171.5s\n",
      "✅ Fold 1 saved best model (AUC=0.9177)\n",
      "Fold 1 | Epoch 010 | Train Loss=0.5726 | Val Loss=0.4638 | Train ACC=0.7220 | Val ACC=0.8605 | Train AUC=0.7868 | Val AUC=0.9221 | time=172.0s\n",
      "✅ Fold 1 saved best model (AUC=0.9221)\n",
      "Fold 1 | Epoch 011 | Train Loss=0.5768 | Val Loss=0.4526 | Train ACC=0.7390 | Val ACC=0.8372 | Train AUC=0.7778 | Val AUC=0.9286 | time=173.6s\n",
      "✅ Fold 1 saved best model (AUC=0.9286)\n",
      "Fold 1 | Epoch 012 | Train Loss=0.5682 | Val Loss=0.4509 | Train ACC=0.7153 | Val ACC=0.8837 | Train AUC=0.7838 | Val AUC=0.9481 | time=173.8s\n",
      "✅ Fold 1 saved best model (AUC=0.9481)\n",
      "Fold 1 | Epoch 013 | Train Loss=0.5623 | Val Loss=0.4482 | Train ACC=0.7288 | Val ACC=0.8837 | Train AUC=0.7954 | Val AUC=0.9524 | time=180.0s\n",
      "✅ Fold 1 saved best model (AUC=0.9524)\n",
      "Fold 1 | Epoch 014 | Train Loss=0.5469 | Val Loss=0.4277 | Train ACC=0.7424 | Val ACC=0.9070 | Train AUC=0.8116 | Val AUC=0.9567 | time=186.6s\n",
      "✅ Fold 1 saved best model (AUC=0.9567)\n",
      "Fold 1 | Epoch 015 | Train Loss=0.5610 | Val Loss=0.4264 | Train ACC=0.7220 | Val ACC=0.9302 | Train AUC=0.7905 | Val AUC=0.9632 | time=201.0s\n",
      "✅ Fold 1 saved best model (AUC=0.9632)\n",
      "Fold 1 | Epoch 016 | Train Loss=0.5350 | Val Loss=0.4068 | Train ACC=0.7559 | Val ACC=0.9535 | Train AUC=0.8288 | Val AUC=0.9740 | time=191.0s\n",
      "✅ Fold 1 saved best model (AUC=0.9740)\n",
      "Fold 1 | Epoch 017 | Train Loss=0.5138 | Val Loss=0.4199 | Train ACC=0.7729 | Val ACC=0.8372 | Train AUC=0.8468 | Val AUC=0.9675 | time=199.1s\n",
      "Fold 1 | Epoch 018 | Train Loss=0.5295 | Val Loss=0.4126 | Train ACC=0.7458 | Val ACC=0.9070 | Train AUC=0.8317 | Val AUC=0.9719 | time=188.7s\n",
      "Fold 1 | Epoch 019 | Train Loss=0.4893 | Val Loss=0.3729 | Train ACC=0.8000 | Val ACC=0.8605 | Train AUC=0.8631 | Val AUC=0.9740 | time=167.9s\n",
      "Fold 1 | Epoch 020 | Train Loss=0.4906 | Val Loss=0.4008 | Train ACC=0.7898 | Val ACC=0.8837 | Train AUC=0.8610 | Val AUC=0.9762 | time=153.1s\n",
      "✅ Fold 1 saved best model (AUC=0.9762)\n",
      "Fold 1 | Epoch 021 | Train Loss=0.4612 | Val Loss=0.3527 | Train ACC=0.8102 | Val ACC=0.9535 | Train AUC=0.8878 | Val AUC=0.9784 | time=153.2s\n",
      "✅ Fold 1 saved best model (AUC=0.9784)\n",
      "Fold 1 | Epoch 022 | Train Loss=0.4496 | Val Loss=0.3634 | Train ACC=0.7898 | Val ACC=0.9302 | Train AUC=0.8978 | Val AUC=0.9784 | time=153.3s\n",
      "Fold 1 | Epoch 023 | Train Loss=0.4528 | Val Loss=0.3619 | Train ACC=0.8237 | Val ACC=0.9070 | Train AUC=0.8857 | Val AUC=0.9784 | time=153.1s\n",
      "Fold 1 | Epoch 024 | Train Loss=0.4472 | Val Loss=0.3294 | Train ACC=0.8271 | Val ACC=0.8605 | Train AUC=0.8874 | Val AUC=0.9784 | time=154.0s\n",
      "Fold 1 | Epoch 025 | Train Loss=0.4176 | Val Loss=0.3060 | Train ACC=0.8508 | Val ACC=0.9302 | Train AUC=0.9120 | Val AUC=0.9805 | time=152.8s\n",
      "✅ Fold 1 saved best model (AUC=0.9805)\n",
      "Fold 1 | Epoch 026 | Train Loss=0.4276 | Val Loss=0.3120 | Train ACC=0.8237 | Val ACC=0.8605 | Train AUC=0.8999 | Val AUC=0.9784 | time=153.4s\n",
      "Fold 1 | Epoch 027 | Train Loss=0.4258 | Val Loss=0.2934 | Train ACC=0.8407 | Val ACC=0.9302 | Train AUC=0.9053 | Val AUC=0.9805 | time=154.3s\n",
      "✅ Fold 1 saved best model (AUC=0.9805)\n",
      "Fold 1 | Epoch 028 | Train Loss=0.4168 | Val Loss=0.6141 | Train ACC=0.8169 | Val ACC=0.5116 | Train AUC=0.9013 | Val AUC=0.9827 | time=153.3s\n",
      "✅ Fold 1 saved best model (AUC=0.9827)\n",
      "Fold 1 | Epoch 029 | Train Loss=0.3980 | Val Loss=0.3148 | Train ACC=0.8373 | Val ACC=0.8837 | Train AUC=0.9139 | Val AUC=0.9762 | time=152.8s\n",
      "Fold 1 | Epoch 030 | Train Loss=0.3772 | Val Loss=0.3051 | Train ACC=0.8508 | Val ACC=0.9535 | Train AUC=0.9261 | Val AUC=0.9740 | time=152.9s\n",
      "Fold 1 | Epoch 031 | Train Loss=0.3884 | Val Loss=0.2687 | Train ACC=0.8407 | Val ACC=0.9070 | Train AUC=0.9255 | Val AUC=0.9784 | time=153.4s\n",
      "Fold 1 | Epoch 032 | Train Loss=0.3772 | Val Loss=0.2887 | Train ACC=0.8508 | Val ACC=0.8837 | Train AUC=0.9259 | Val AUC=0.9805 | time=153.1s\n",
      "Fold 1 | Epoch 033 | Train Loss=0.3669 | Val Loss=0.2613 | Train ACC=0.8407 | Val ACC=0.9302 | Train AUC=0.9296 | Val AUC=0.9784 | time=153.4s\n",
      "Fold 1 | Epoch 034 | Train Loss=0.3819 | Val Loss=0.2712 | Train ACC=0.8373 | Val ACC=0.9070 | Train AUC=0.9210 | Val AUC=0.9697 | time=153.0s\n",
      "Fold 1 | Epoch 035 | Train Loss=0.3808 | Val Loss=0.2736 | Train ACC=0.8475 | Val ACC=0.9302 | Train AUC=0.9187 | Val AUC=0.9762 | time=153.2s\n",
      "Fold 1 | Epoch 036 | Train Loss=0.3542 | Val Loss=0.2518 | Train ACC=0.8644 | Val ACC=0.9302 | Train AUC=0.9356 | Val AUC=0.9784 | time=153.7s\n",
      "Fold 1 | Epoch 037 | Train Loss=0.3395 | Val Loss=0.3359 | Train ACC=0.8576 | Val ACC=0.9070 | Train AUC=0.9409 | Val AUC=0.9784 | time=153.3s\n",
      "Fold 1 | Epoch 038 | Train Loss=0.3648 | Val Loss=0.2472 | Train ACC=0.8712 | Val ACC=0.9302 | Train AUC=0.9287 | Val AUC=0.9784 | time=152.9s\n",
      "Fold 1 | Epoch 039 | Train Loss=0.3316 | Val Loss=0.2569 | Train ACC=0.8610 | Val ACC=0.9302 | Train AUC=0.9452 | Val AUC=0.9740 | time=152.9s\n",
      "Fold 1 | Epoch 040 | Train Loss=0.3244 | Val Loss=0.2327 | Train ACC=0.8814 | Val ACC=0.9302 | Train AUC=0.9540 | Val AUC=0.9762 | time=154.1s\n",
      "Fold 1 | Epoch 041 | Train Loss=0.3051 | Val Loss=0.2785 | Train ACC=0.8949 | Val ACC=0.9070 | Train AUC=0.9551 | Val AUC=0.9784 | time=153.7s\n",
      "Fold 1 | Epoch 042 | Train Loss=0.3332 | Val Loss=0.3620 | Train ACC=0.8441 | Val ACC=0.7907 | Train AUC=0.9418 | Val AUC=0.9827 | time=153.1s\n",
      "Fold 1 | Epoch 043 | Train Loss=0.3073 | Val Loss=0.2642 | Train ACC=0.9085 | Val ACC=0.9070 | Train AUC=0.9552 | Val AUC=0.9762 | time=153.3s\n",
      "Fold 1 | Epoch 044 | Train Loss=0.3326 | Val Loss=0.2456 | Train ACC=0.8678 | Val ACC=0.9302 | Train AUC=0.9388 | Val AUC=0.9729 | time=153.5s\n",
      "Fold 1 | Epoch 045 | Train Loss=0.2855 | Val Loss=0.2687 | Train ACC=0.9085 | Val ACC=0.9070 | Train AUC=0.9615 | Val AUC=0.9719 | time=153.3s\n",
      "Fold 1 | Epoch 046 | Train Loss=0.2907 | Val Loss=0.2972 | Train ACC=0.8983 | Val ACC=0.9070 | Train AUC=0.9629 | Val AUC=0.9719 | time=152.7s\n",
      "Fold 1 | Epoch 047 | Train Loss=0.2979 | Val Loss=0.2775 | Train ACC=0.8814 | Val ACC=0.9070 | Train AUC=0.9563 | Val AUC=0.9762 | time=153.1s\n",
      "Fold 1 | Epoch 048 | Train Loss=0.2612 | Val Loss=0.2842 | Train ACC=0.9186 | Val ACC=0.8837 | Train AUC=0.9777 | Val AUC=0.9740 | time=153.2s\n",
      "Fold 1 | Epoch 049 | Train Loss=0.2557 | Val Loss=0.2245 | Train ACC=0.9220 | Val ACC=0.9302 | Train AUC=0.9720 | Val AUC=0.9762 | time=153.4s\n",
      "Fold 1 | Epoch 050 | Train Loss=0.2746 | Val Loss=0.4261 | Train ACC=0.9085 | Val ACC=0.7442 | Train AUC=0.9633 | Val AUC=0.9762 | time=153.8s\n",
      "Fold 1 | Epoch 051 | Train Loss=0.2602 | Val Loss=0.2488 | Train ACC=0.9153 | Val ACC=0.9070 | Train AUC=0.9717 | Val AUC=0.9740 | time=153.1s\n",
      "Fold 1 | Epoch 052 | Train Loss=0.2411 | Val Loss=0.2348 | Train ACC=0.9186 | Val ACC=0.9302 | Train AUC=0.9734 | Val AUC=0.9740 | time=152.8s\n",
      "Fold 1 | Epoch 053 | Train Loss=0.2812 | Val Loss=0.2193 | Train ACC=0.8814 | Val ACC=0.9302 | Train AUC=0.9637 | Val AUC=0.9740 | time=152.9s\n",
      "Fold 1 | Epoch 054 | Train Loss=0.2546 | Val Loss=0.2084 | Train ACC=0.9288 | Val ACC=0.9302 | Train AUC=0.9762 | Val AUC=0.9762 | time=152.7s\n",
      "Fold 1 | Epoch 055 | Train Loss=0.2459 | Val Loss=0.2248 | Train ACC=0.9119 | Val ACC=0.9302 | Train AUC=0.9737 | Val AUC=0.9740 | time=152.5s\n",
      "Fold 1 | Epoch 056 | Train Loss=0.2358 | Val Loss=0.2078 | Train ACC=0.9186 | Val ACC=0.9535 | Train AUC=0.9757 | Val AUC=0.9794 | time=153.3s\n",
      "Fold 1 | Epoch 057 | Train Loss=0.3166 | Val Loss=0.2601 | Train ACC=0.8780 | Val ACC=0.9070 | Train AUC=0.9473 | Val AUC=0.9762 | time=153.4s\n",
      "Fold 1 | Epoch 058 | Train Loss=0.2434 | Val Loss=0.2215 | Train ACC=0.9254 | Val ACC=0.9535 | Train AUC=0.9735 | Val AUC=0.9784 | time=153.4s\n",
      "Fold 1 | Epoch 059 | Train Loss=0.2051 | Val Loss=0.2120 | Train ACC=0.9525 | Val ACC=0.9302 | Train AUC=0.9910 | Val AUC=0.9740 | time=153.6s\n",
      "Fold 1 | Epoch 060 | Train Loss=0.2348 | Val Loss=0.2110 | Train ACC=0.9288 | Val ACC=0.9535 | Train AUC=0.9786 | Val AUC=0.9784 | time=152.8s\n",
      "Fold 1 | Epoch 061 | Train Loss=0.2372 | Val Loss=0.2071 | Train ACC=0.9390 | Val ACC=0.9302 | Train AUC=0.9715 | Val AUC=0.9784 | time=153.2s\n",
      "Fold 1 | Epoch 062 | Train Loss=0.2169 | Val Loss=0.2276 | Train ACC=0.9458 | Val ACC=0.9302 | Train AUC=0.9808 | Val AUC=0.9762 | time=152.9s\n",
      "Fold 1 | Epoch 063 | Train Loss=0.2339 | Val Loss=0.2323 | Train ACC=0.9153 | Val ACC=0.9070 | Train AUC=0.9805 | Val AUC=0.9805 | time=158.3s\n",
      "Fold 1 | Epoch 064 | Train Loss=0.2169 | Val Loss=0.1958 | Train ACC=0.9424 | Val ACC=0.9535 | Train AUC=0.9773 | Val AUC=0.9827 | time=189.6s\n",
      "✅ Fold 1 saved best model (AUC=0.9827)\n",
      "Fold 1 | Epoch 065 | Train Loss=0.2236 | Val Loss=0.2008 | Train ACC=0.9220 | Val ACC=0.9302 | Train AUC=0.9783 | Val AUC=0.9805 | time=198.8s\n",
      "Fold 1 | Epoch 066 | Train Loss=0.2182 | Val Loss=0.2386 | Train ACC=0.9254 | Val ACC=0.9070 | Train AUC=0.9838 | Val AUC=0.9794 | time=198.8s\n",
      "Fold 1 | Epoch 067 | Train Loss=0.1877 | Val Loss=0.2065 | Train ACC=0.9525 | Val ACC=0.9302 | Train AUC=0.9856 | Val AUC=0.9805 | time=198.1s\n",
      "Fold 1 | Epoch 068 | Train Loss=0.2077 | Val Loss=0.2073 | Train ACC=0.9424 | Val ACC=0.9535 | Train AUC=0.9852 | Val AUC=0.9805 | time=201.6s\n",
      "Fold 1 | Epoch 069 | Train Loss=0.2356 | Val Loss=0.2052 | Train ACC=0.9288 | Val ACC=0.9535 | Train AUC=0.9782 | Val AUC=0.9784 | time=198.6s\n",
      "Fold 1 | Epoch 070 | Train Loss=0.1792 | Val Loss=0.1994 | Train ACC=0.9661 | Val ACC=0.9535 | Train AUC=0.9937 | Val AUC=0.9762 | time=200.4s\n",
      "Fold 1 | Epoch 071 | Train Loss=0.2188 | Val Loss=0.1965 | Train ACC=0.9356 | Val ACC=0.9302 | Train AUC=0.9807 | Val AUC=0.9805 | time=196.9s\n",
      "Fold 1 | Epoch 072 | Train Loss=0.2170 | Val Loss=0.1996 | Train ACC=0.9288 | Val ACC=0.9535 | Train AUC=0.9801 | Val AUC=0.9762 | time=200.4s\n",
      "Fold 1 | Epoch 073 | Train Loss=0.2279 | Val Loss=0.1979 | Train ACC=0.9322 | Val ACC=0.9302 | Train AUC=0.9782 | Val AUC=0.9762 | time=198.5s\n",
      "Fold 1 | Epoch 074 | Train Loss=0.1794 | Val Loss=0.1979 | Train ACC=0.9593 | Val ACC=0.9535 | Train AUC=0.9936 | Val AUC=0.9784 | time=200.1s\n",
      "Fold 1 | Epoch 075 | Train Loss=0.2180 | Val Loss=0.1988 | Train ACC=0.9390 | Val ACC=0.9535 | Train AUC=0.9812 | Val AUC=0.9762 | time=197.3s\n",
      "Fold 1 | Epoch 076 | Train Loss=0.1627 | Val Loss=0.1908 | Train ACC=0.9492 | Val ACC=0.9535 | Train AUC=0.9939 | Val AUC=0.9805 | time=200.9s\n",
      "Fold 1 | Epoch 077 | Train Loss=0.2152 | Val Loss=0.1961 | Train ACC=0.9220 | Val ACC=0.9535 | Train AUC=0.9818 | Val AUC=0.9762 | time=197.6s\n",
      "Fold 1 | Epoch 078 | Train Loss=0.2004 | Val Loss=0.2038 | Train ACC=0.9322 | Val ACC=0.9535 | Train AUC=0.9862 | Val AUC=0.9762 | time=199.4s\n",
      "Fold 1 | Epoch 079 | Train Loss=0.1983 | Val Loss=0.1946 | Train ACC=0.9458 | Val ACC=0.9302 | Train AUC=0.9848 | Val AUC=0.9784 | time=198.1s\n",
      "Fold 1 | Epoch 080 | Train Loss=0.1987 | Val Loss=0.1909 | Train ACC=0.9356 | Val ACC=0.9535 | Train AUC=0.9848 | Val AUC=0.9784 | time=199.5s\n",
      "Fold 1 | Epoch 081 | Train Loss=0.2049 | Val Loss=0.1945 | Train ACC=0.9288 | Val ACC=0.9535 | Train AUC=0.9836 | Val AUC=0.9784 | time=199.7s\n",
      "Fold 1 | Epoch 082 | Train Loss=0.2018 | Val Loss=0.1920 | Train ACC=0.9525 | Val ACC=0.9302 | Train AUC=0.9852 | Val AUC=0.9784 | time=198.8s\n",
      "Fold 1 | Epoch 083 | Train Loss=0.1736 | Val Loss=0.1942 | Train ACC=0.9492 | Val ACC=0.9535 | Train AUC=0.9923 | Val AUC=0.9784 | time=200.6s\n",
      "Fold 1 | Epoch 084 | Train Loss=0.1873 | Val Loss=0.1922 | Train ACC=0.9559 | Val ACC=0.9535 | Train AUC=0.9900 | Val AUC=0.9784 | time=198.6s\n",
      "Fold 1 | Epoch 085 | Train Loss=0.1786 | Val Loss=0.1908 | Train ACC=0.9559 | Val ACC=0.9535 | Train AUC=0.9895 | Val AUC=0.9784 | time=201.4s\n",
      "Fold 1 | Epoch 086 | Train Loss=0.1672 | Val Loss=0.1940 | Train ACC=0.9627 | Val ACC=0.9535 | Train AUC=0.9914 | Val AUC=0.9762 | time=198.1s\n",
      "Fold 1 | Epoch 087 | Train Loss=0.1808 | Val Loss=0.1889 | Train ACC=0.9627 | Val ACC=0.9535 | Train AUC=0.9910 | Val AUC=0.9805 | time=200.8s\n",
      "Fold 1 | Epoch 088 | Train Loss=0.2230 | Val Loss=0.1907 | Train ACC=0.9254 | Val ACC=0.9535 | Train AUC=0.9801 | Val AUC=0.9805 | time=198.0s\n",
      "Fold 1 | Epoch 089 | Train Loss=0.1804 | Val Loss=0.1914 | Train ACC=0.9593 | Val ACC=0.9535 | Train AUC=0.9921 | Val AUC=0.9784 | time=200.9s\n",
      "Fold 1 | Epoch 090 | Train Loss=0.2117 | Val Loss=0.1948 | Train ACC=0.9254 | Val ACC=0.9535 | Train AUC=0.9818 | Val AUC=0.9784 | time=197.6s\n",
      "Fold 1 | Epoch 091 | Train Loss=0.2235 | Val Loss=0.1943 | Train ACC=0.9356 | Val ACC=0.9535 | Train AUC=0.9758 | Val AUC=0.9784 | time=200.4s\n",
      "Fold 1 | Epoch 092 | Train Loss=0.1837 | Val Loss=0.1925 | Train ACC=0.9525 | Val ACC=0.9535 | Train AUC=0.9883 | Val AUC=0.9784 | time=197.3s\n",
      "Fold 1 | Epoch 093 | Train Loss=0.1998 | Val Loss=0.1882 | Train ACC=0.9492 | Val ACC=0.9535 | Train AUC=0.9871 | Val AUC=0.9805 | time=199.9s\n",
      "Fold 1 | Epoch 094 | Train Loss=0.2160 | Val Loss=0.1944 | Train ACC=0.9186 | Val ACC=0.9535 | Train AUC=0.9788 | Val AUC=0.9784 | time=197.8s\n",
      "Fold 1 | Epoch 095 | Train Loss=0.1856 | Val Loss=0.1927 | Train ACC=0.9424 | Val ACC=0.9535 | Train AUC=0.9890 | Val AUC=0.9762 | time=198.7s\n",
      "Fold 1 | Epoch 096 | Train Loss=0.1571 | Val Loss=0.1917 | Train ACC=0.9695 | Val ACC=0.9535 | Train AUC=0.9961 | Val AUC=0.9784 | time=199.3s\n",
      "Fold 1 | Epoch 097 | Train Loss=0.1945 | Val Loss=0.1902 | Train ACC=0.9525 | Val ACC=0.9535 | Train AUC=0.9872 | Val AUC=0.9805 | time=198.4s\n",
      "Fold 1 | Epoch 098 | Train Loss=0.1890 | Val Loss=0.1927 | Train ACC=0.9559 | Val ACC=0.9535 | Train AUC=0.9855 | Val AUC=0.9762 | time=200.9s\n",
      "Fold 1 | Epoch 099 | Train Loss=0.1719 | Val Loss=0.1910 | Train ACC=0.9492 | Val ACC=0.9535 | Train AUC=0.9925 | Val AUC=0.9784 | time=198.6s\n",
      "Fold 1 | Epoch 100 | Train Loss=0.2175 | Val Loss=0.1909 | Train ACC=0.9322 | Val ACC=0.9535 | Train AUC=0.9785 | Val AUC=0.9784 | time=200.8s\n",
      "=== Fold 1 完成，Best AUC=0.9827 ===\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "--------------------model------------------\n",
      "Total params(M)    : 14,057,602\n",
      "Trainable params(M): 14,057,602\n",
      "Approx. size       : 26.81 MB\n",
      "model type: DualStreamUNet3DClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_24072\\1643430249.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 | Epoch 001 | Train Loss=0.6938 | Val Loss=0.7191 | Train ACC=0.5186 | Val ACC=0.4884 | Train AUC=0.6672 | Val AUC=0.5855 | time=197.5s\n",
      "✅ Fold 2 saved best model (AUC=0.5855)\n",
      "Fold 2 | Epoch 002 | Train Loss=0.6693 | Val Loss=0.6524 | Train ACC=0.5390 | Val ACC=0.5349 | Train AUC=0.7315 | Val AUC=0.7424 | time=200.0s\n",
      "✅ Fold 2 saved best model (AUC=0.7424)\n",
      "Fold 2 | Epoch 003 | Train Loss=0.6477 | Val Loss=0.6402 | Train ACC=0.6068 | Val ACC=0.5814 | Train AUC=0.7410 | Val AUC=0.7262 | time=197.8s\n",
      "Fold 2 | Epoch 004 | Train Loss=0.6277 | Val Loss=0.6206 | Train ACC=0.6712 | Val ACC=0.6512 | Train AUC=0.7440 | Val AUC=0.7338 | time=201.2s\n",
      "Fold 2 | Epoch 005 | Train Loss=0.6073 | Val Loss=0.6128 | Train ACC=0.6508 | Val ACC=0.6512 | Train AUC=0.7583 | Val AUC=0.7305 | time=195.9s\n",
      "Fold 2 | Epoch 006 | Train Loss=0.6136 | Val Loss=0.6096 | Train ACC=0.6678 | Val ACC=0.6744 | Train AUC=0.7300 | Val AUC=0.7338 | time=200.4s\n",
      "Fold 2 | Epoch 007 | Train Loss=0.6018 | Val Loss=0.5976 | Train ACC=0.6542 | Val ACC=0.6744 | Train AUC=0.7390 | Val AUC=0.7424 | time=200.5s\n",
      "Fold 2 | Epoch 008 | Train Loss=0.5967 | Val Loss=0.5898 | Train ACC=0.6814 | Val ACC=0.6977 | Train AUC=0.7496 | Val AUC=0.7468 | time=204.7s\n",
      "✅ Fold 2 saved best model (AUC=0.7468)\n",
      "Fold 2 | Epoch 009 | Train Loss=0.5950 | Val Loss=0.5940 | Train ACC=0.6780 | Val ACC=0.6744 | Train AUC=0.7508 | Val AUC=0.7576 | time=197.1s\n",
      "✅ Fold 2 saved best model (AUC=0.7576)\n",
      "Fold 2 | Epoch 010 | Train Loss=0.5670 | Val Loss=0.5798 | Train ACC=0.7220 | Val ACC=0.7209 | Train AUC=0.7877 | Val AUC=0.7619 | time=197.9s\n",
      "✅ Fold 2 saved best model (AUC=0.7619)\n",
      "Fold 2 | Epoch 011 | Train Loss=0.5750 | Val Loss=0.5752 | Train ACC=0.6983 | Val ACC=0.6977 | Train AUC=0.7776 | Val AUC=0.7641 | time=198.7s\n",
      "✅ Fold 2 saved best model (AUC=0.7641)\n",
      "Fold 2 | Epoch 012 | Train Loss=0.5565 | Val Loss=0.5766 | Train ACC=0.7220 | Val ACC=0.6512 | Train AUC=0.8023 | Val AUC=0.7727 | time=199.0s\n",
      "✅ Fold 2 saved best model (AUC=0.7727)\n",
      "Fold 2 | Epoch 013 | Train Loss=0.5656 | Val Loss=0.5550 | Train ACC=0.7254 | Val ACC=0.7209 | Train AUC=0.7885 | Val AUC=0.7749 | time=201.1s\n",
      "✅ Fold 2 saved best model (AUC=0.7749)\n",
      "Fold 2 | Epoch 014 | Train Loss=0.5384 | Val Loss=0.5481 | Train ACC=0.7220 | Val ACC=0.7209 | Train AUC=0.8166 | Val AUC=0.7922 | time=198.0s\n",
      "✅ Fold 2 saved best model (AUC=0.7922)\n",
      "Fold 2 | Epoch 015 | Train Loss=0.5526 | Val Loss=0.5436 | Train ACC=0.7424 | Val ACC=0.7209 | Train AUC=0.8029 | Val AUC=0.7944 | time=201.0s\n",
      "✅ Fold 2 saved best model (AUC=0.7944)\n",
      "Fold 2 | Epoch 016 | Train Loss=0.5168 | Val Loss=0.5309 | Train ACC=0.7831 | Val ACC=0.7442 | Train AUC=0.8475 | Val AUC=0.8117 | time=196.4s\n",
      "✅ Fold 2 saved best model (AUC=0.8117)\n",
      "Fold 2 | Epoch 017 | Train Loss=0.5021 | Val Loss=0.5316 | Train ACC=0.7729 | Val ACC=0.7209 | Train AUC=0.8534 | Val AUC=0.8247 | time=200.1s\n",
      "✅ Fold 2 saved best model (AUC=0.8247)\n",
      "Fold 2 | Epoch 018 | Train Loss=0.4950 | Val Loss=0.5085 | Train ACC=0.7661 | Val ACC=0.7674 | Train AUC=0.8544 | Val AUC=0.8301 | time=197.2s\n",
      "✅ Fold 2 saved best model (AUC=0.8301)\n",
      "Fold 2 | Epoch 019 | Train Loss=0.5042 | Val Loss=0.4996 | Train ACC=0.7593 | Val ACC=0.7674 | Train AUC=0.8423 | Val AUC=0.8420 | time=200.2s\n",
      "✅ Fold 2 saved best model (AUC=0.8420)\n",
      "Fold 2 | Epoch 020 | Train Loss=0.4682 | Val Loss=0.4955 | Train ACC=0.7864 | Val ACC=0.8140 | Train AUC=0.8792 | Val AUC=0.8463 | time=197.9s\n",
      "✅ Fold 2 saved best model (AUC=0.8463)\n",
      "Fold 2 | Epoch 021 | Train Loss=0.4897 | Val Loss=0.4936 | Train ACC=0.7661 | Val ACC=0.7674 | Train AUC=0.8515 | Val AUC=0.8485 | time=200.2s\n",
      "✅ Fold 2 saved best model (AUC=0.8485)\n",
      "Fold 2 | Epoch 022 | Train Loss=0.4432 | Val Loss=0.4799 | Train ACC=0.8169 | Val ACC=0.7907 | Train AUC=0.8980 | Val AUC=0.8377 | time=197.2s\n",
      "Fold 2 | Epoch 023 | Train Loss=0.4603 | Val Loss=0.4838 | Train ACC=0.8000 | Val ACC=0.7674 | Train AUC=0.8882 | Val AUC=0.8636 | time=199.9s\n",
      "✅ Fold 2 saved best model (AUC=0.8636)\n",
      "Fold 2 | Epoch 024 | Train Loss=0.4270 | Val Loss=0.4620 | Train ACC=0.8441 | Val ACC=0.7907 | Train AUC=0.9099 | Val AUC=0.8680 | time=197.4s\n",
      "✅ Fold 2 saved best model (AUC=0.8680)\n",
      "Fold 2 | Epoch 025 | Train Loss=0.4239 | Val Loss=0.4560 | Train ACC=0.8271 | Val ACC=0.7907 | Train AUC=0.9033 | Val AUC=0.8745 | time=198.1s\n",
      "✅ Fold 2 saved best model (AUC=0.8745)\n",
      "Fold 2 | Epoch 026 | Train Loss=0.4144 | Val Loss=0.4552 | Train ACC=0.8271 | Val ACC=0.7907 | Train AUC=0.9098 | Val AUC=0.8831 | time=200.4s\n",
      "✅ Fold 2 saved best model (AUC=0.8831)\n",
      "Fold 2 | Epoch 027 | Train Loss=0.3798 | Val Loss=0.5312 | Train ACC=0.8644 | Val ACC=0.7442 | Train AUC=0.9333 | Val AUC=0.8874 | time=197.1s\n",
      "✅ Fold 2 saved best model (AUC=0.8874)\n",
      "Fold 2 | Epoch 028 | Train Loss=0.3799 | Val Loss=0.4270 | Train ACC=0.8271 | Val ACC=0.8605 | Train AUC=0.9282 | Val AUC=0.8874 | time=201.3s\n",
      "Fold 2 | Epoch 029 | Train Loss=0.3769 | Val Loss=0.6090 | Train ACC=0.8610 | Val ACC=0.6279 | Train AUC=0.9229 | Val AUC=0.8853 | time=197.8s\n",
      "Fold 2 | Epoch 030 | Train Loss=0.4002 | Val Loss=0.4102 | Train ACC=0.8373 | Val ACC=0.8605 | Train AUC=0.9075 | Val AUC=0.9069 | time=201.0s\n",
      "✅ Fold 2 saved best model (AUC=0.9069)\n",
      "Fold 2 | Epoch 031 | Train Loss=0.3504 | Val Loss=0.4152 | Train ACC=0.8746 | Val ACC=0.8605 | Train AUC=0.9484 | Val AUC=0.9048 | time=198.8s\n",
      "Fold 2 | Epoch 032 | Train Loss=0.3798 | Val Loss=0.4064 | Train ACC=0.8441 | Val ACC=0.8605 | Train AUC=0.9193 | Val AUC=0.9004 | time=200.9s\n",
      "Fold 2 | Epoch 033 | Train Loss=0.3635 | Val Loss=0.4450 | Train ACC=0.8712 | Val ACC=0.7442 | Train AUC=0.9362 | Val AUC=0.9015 | time=197.9s\n",
      "Fold 2 | Epoch 034 | Train Loss=0.3701 | Val Loss=0.4273 | Train ACC=0.8610 | Val ACC=0.7907 | Train AUC=0.9273 | Val AUC=0.8983 | time=201.2s\n",
      "Fold 2 | Epoch 035 | Train Loss=0.3553 | Val Loss=0.5054 | Train ACC=0.8610 | Val ACC=0.7674 | Train AUC=0.9347 | Val AUC=0.9091 | time=197.9s\n",
      "✅ Fold 2 saved best model (AUC=0.9091)\n",
      "Fold 2 | Epoch 036 | Train Loss=0.3494 | Val Loss=0.4145 | Train ACC=0.8644 | Val ACC=0.8140 | Train AUC=0.9385 | Val AUC=0.9048 | time=201.4s\n",
      "Fold 2 | Epoch 037 | Train Loss=0.3341 | Val Loss=0.5322 | Train ACC=0.8678 | Val ACC=0.6744 | Train AUC=0.9394 | Val AUC=0.9113 | time=199.2s\n",
      "✅ Fold 2 saved best model (AUC=0.9113)\n",
      "Fold 2 | Epoch 038 | Train Loss=0.3292 | Val Loss=0.3888 | Train ACC=0.8780 | Val ACC=0.8605 | Train AUC=0.9514 | Val AUC=0.9102 | time=199.6s\n",
      "Fold 2 | Epoch 039 | Train Loss=0.3327 | Val Loss=0.3840 | Train ACC=0.8712 | Val ACC=0.8605 | Train AUC=0.9425 | Val AUC=0.9134 | time=198.3s\n",
      "✅ Fold 2 saved best model (AUC=0.9134)\n",
      "Fold 2 | Epoch 040 | Train Loss=0.3032 | Val Loss=0.3953 | Train ACC=0.8983 | Val ACC=0.8372 | Train AUC=0.9545 | Val AUC=0.9177 | time=199.1s\n",
      "✅ Fold 2 saved best model (AUC=0.9177)\n",
      "Fold 2 | Epoch 041 | Train Loss=0.2904 | Val Loss=0.3724 | Train ACC=0.8814 | Val ACC=0.8605 | Train AUC=0.9621 | Val AUC=0.9199 | time=199.4s\n",
      "✅ Fold 2 saved best model (AUC=0.9199)\n",
      "Fold 2 | Epoch 042 | Train Loss=0.2772 | Val Loss=0.3685 | Train ACC=0.9017 | Val ACC=0.8605 | Train AUC=0.9676 | Val AUC=0.9221 | time=198.3s\n",
      "✅ Fold 2 saved best model (AUC=0.9221)\n",
      "Fold 2 | Epoch 043 | Train Loss=0.3124 | Val Loss=0.3945 | Train ACC=0.8712 | Val ACC=0.8372 | Train AUC=0.9535 | Val AUC=0.9177 | time=201.4s\n",
      "Fold 2 | Epoch 044 | Train Loss=0.2795 | Val Loss=0.3660 | Train ACC=0.8983 | Val ACC=0.8372 | Train AUC=0.9647 | Val AUC=0.9177 | time=198.3s\n",
      "Fold 2 | Epoch 045 | Train Loss=0.2953 | Val Loss=0.3674 | Train ACC=0.8983 | Val ACC=0.8605 | Train AUC=0.9574 | Val AUC=0.9177 | time=201.8s\n",
      "Fold 2 | Epoch 046 | Train Loss=0.2629 | Val Loss=0.4924 | Train ACC=0.9220 | Val ACC=0.8140 | Train AUC=0.9715 | Val AUC=0.9221 | time=197.5s\n",
      "Fold 2 | Epoch 047 | Train Loss=0.2869 | Val Loss=0.3587 | Train ACC=0.9017 | Val ACC=0.8605 | Train AUC=0.9598 | Val AUC=0.9242 | time=201.2s\n",
      "✅ Fold 2 saved best model (AUC=0.9242)\n",
      "Fold 2 | Epoch 048 | Train Loss=0.2412 | Val Loss=0.3689 | Train ACC=0.9153 | Val ACC=0.8605 | Train AUC=0.9777 | Val AUC=0.9221 | time=198.9s\n",
      "Fold 2 | Epoch 049 | Train Loss=0.2328 | Val Loss=0.3777 | Train ACC=0.9186 | Val ACC=0.8837 | Train AUC=0.9801 | Val AUC=0.9177 | time=201.8s\n",
      "Fold 2 | Epoch 050 | Train Loss=0.2440 | Val Loss=0.5175 | Train ACC=0.9085 | Val ACC=0.7674 | Train AUC=0.9772 | Val AUC=0.9264 | time=198.3s\n",
      "✅ Fold 2 saved best model (AUC=0.9264)\n",
      "Fold 2 | Epoch 051 | Train Loss=0.2421 | Val Loss=0.3524 | Train ACC=0.9220 | Val ACC=0.8605 | Train AUC=0.9787 | Val AUC=0.9221 | time=201.8s\n",
      "Fold 2 | Epoch 052 | Train Loss=0.2871 | Val Loss=0.3794 | Train ACC=0.9017 | Val ACC=0.8837 | Train AUC=0.9577 | Val AUC=0.9275 | time=199.0s\n",
      "✅ Fold 2 saved best model (AUC=0.9275)\n",
      "Fold 2 | Epoch 053 | Train Loss=0.2147 | Val Loss=0.3426 | Train ACC=0.9525 | Val ACC=0.8837 | Train AUC=0.9913 | Val AUC=0.9329 | time=200.2s\n",
      "✅ Fold 2 saved best model (AUC=0.9329)\n",
      "Fold 2 | Epoch 054 | Train Loss=0.2311 | Val Loss=0.3530 | Train ACC=0.9288 | Val ACC=0.8372 | Train AUC=0.9812 | Val AUC=0.9264 | time=197.9s\n",
      "Fold 2 | Epoch 055 | Train Loss=0.2643 | Val Loss=0.3650 | Train ACC=0.8915 | Val ACC=0.8605 | Train AUC=0.9702 | Val AUC=0.9221 | time=198.9s\n",
      "Fold 2 | Epoch 056 | Train Loss=0.2262 | Val Loss=0.3613 | Train ACC=0.9390 | Val ACC=0.8837 | Train AUC=0.9829 | Val AUC=0.9264 | time=200.7s\n",
      "Fold 2 | Epoch 057 | Train Loss=0.2136 | Val Loss=0.3320 | Train ACC=0.9525 | Val ACC=0.8837 | Train AUC=0.9859 | Val AUC=0.9329 | time=197.3s\n",
      "Fold 2 | Epoch 058 | Train Loss=0.2427 | Val Loss=0.3273 | Train ACC=0.9153 | Val ACC=0.8837 | Train AUC=0.9749 | Val AUC=0.9286 | time=200.9s\n",
      "Fold 2 | Epoch 059 | Train Loss=0.2230 | Val Loss=0.3380 | Train ACC=0.9424 | Val ACC=0.8605 | Train AUC=0.9820 | Val AUC=0.9242 | time=198.7s\n",
      "Fold 2 | Epoch 060 | Train Loss=0.2271 | Val Loss=0.3651 | Train ACC=0.9356 | Val ACC=0.8837 | Train AUC=0.9841 | Val AUC=0.9264 | time=200.8s\n",
      "Fold 2 | Epoch 061 | Train Loss=0.2092 | Val Loss=0.3427 | Train ACC=0.9390 | Val ACC=0.8605 | Train AUC=0.9855 | Val AUC=0.9253 | time=197.8s\n",
      "Fold 2 | Epoch 062 | Train Loss=0.1939 | Val Loss=0.4183 | Train ACC=0.9390 | Val ACC=0.8140 | Train AUC=0.9893 | Val AUC=0.9286 | time=201.3s\n",
      "Fold 2 | Epoch 063 | Train Loss=0.2026 | Val Loss=0.3282 | Train ACC=0.9288 | Val ACC=0.8605 | Train AUC=0.9851 | Val AUC=0.9264 | time=198.5s\n",
      "Fold 2 | Epoch 064 | Train Loss=0.1797 | Val Loss=0.3153 | Train ACC=0.9559 | Val ACC=0.8605 | Train AUC=0.9908 | Val AUC=0.9372 | time=202.1s\n",
      "✅ Fold 2 saved best model (AUC=0.9372)\n",
      "Fold 2 | Epoch 065 | Train Loss=0.2009 | Val Loss=0.3620 | Train ACC=0.9356 | Val ACC=0.8837 | Train AUC=0.9858 | Val AUC=0.9329 | time=198.7s\n",
      "Fold 2 | Epoch 066 | Train Loss=0.2301 | Val Loss=0.3533 | Train ACC=0.9288 | Val ACC=0.8837 | Train AUC=0.9770 | Val AUC=0.9307 | time=201.1s\n",
      "Fold 2 | Epoch 067 | Train Loss=0.1751 | Val Loss=0.3605 | Train ACC=0.9593 | Val ACC=0.8837 | Train AUC=0.9940 | Val AUC=0.9286 | time=198.6s\n",
      "Fold 2 | Epoch 068 | Train Loss=0.2122 | Val Loss=0.3244 | Train ACC=0.9153 | Val ACC=0.8605 | Train AUC=0.9822 | Val AUC=0.9286 | time=200.5s\n",
      "Fold 2 | Epoch 069 | Train Loss=0.1865 | Val Loss=0.3453 | Train ACC=0.9559 | Val ACC=0.8837 | Train AUC=0.9889 | Val AUC=0.9307 | time=199.1s\n",
      "Fold 2 | Epoch 070 | Train Loss=0.1829 | Val Loss=0.3605 | Train ACC=0.9525 | Val ACC=0.8837 | Train AUC=0.9906 | Val AUC=0.9264 | time=198.3s\n",
      "Fold 2 | Epoch 071 | Train Loss=0.1956 | Val Loss=0.3345 | Train ACC=0.9458 | Val ACC=0.8837 | Train AUC=0.9878 | Val AUC=0.9351 | time=198.9s\n",
      "Fold 2 | Epoch 072 | Train Loss=0.2107 | Val Loss=0.3378 | Train ACC=0.9424 | Val ACC=0.8837 | Train AUC=0.9860 | Val AUC=0.9318 | time=196.9s\n",
      "Fold 2 | Epoch 073 | Train Loss=0.2018 | Val Loss=0.3132 | Train ACC=0.9424 | Val ACC=0.8605 | Train AUC=0.9867 | Val AUC=0.9372 | time=201.8s\n",
      "Fold 2 | Epoch 074 | Train Loss=0.2113 | Val Loss=0.3809 | Train ACC=0.9322 | Val ACC=0.8372 | Train AUC=0.9809 | Val AUC=0.9307 | time=197.9s\n",
      "Fold 2 | Epoch 075 | Train Loss=0.1954 | Val Loss=0.3144 | Train ACC=0.9390 | Val ACC=0.8605 | Train AUC=0.9895 | Val AUC=0.9372 | time=200.5s\n",
      "Fold 2 | Epoch 076 | Train Loss=0.1810 | Val Loss=0.3178 | Train ACC=0.9390 | Val ACC=0.8605 | Train AUC=0.9880 | Val AUC=0.9329 | time=196.8s\n",
      "Fold 2 | Epoch 077 | Train Loss=0.1705 | Val Loss=0.3428 | Train ACC=0.9525 | Val ACC=0.8837 | Train AUC=0.9902 | Val AUC=0.9286 | time=200.5s\n",
      "Fold 2 | Epoch 078 | Train Loss=0.1663 | Val Loss=0.3243 | Train ACC=0.9661 | Val ACC=0.8837 | Train AUC=0.9948 | Val AUC=0.9351 | time=196.1s\n",
      "Fold 2 | Epoch 079 | Train Loss=0.1589 | Val Loss=0.3292 | Train ACC=0.9695 | Val ACC=0.8837 | Train AUC=0.9953 | Val AUC=0.9372 | time=201.4s\n",
      "Fold 2 | Epoch 080 | Train Loss=0.1743 | Val Loss=0.3462 | Train ACC=0.9661 | Val ACC=0.8837 | Train AUC=0.9904 | Val AUC=0.9307 | time=197.5s\n",
      "Fold 2 | Epoch 081 | Train Loss=0.1616 | Val Loss=0.3256 | Train ACC=0.9559 | Val ACC=0.8837 | Train AUC=0.9948 | Val AUC=0.9351 | time=201.6s\n",
      "Fold 2 | Epoch 082 | Train Loss=0.1544 | Val Loss=0.3254 | Train ACC=0.9627 | Val ACC=0.8837 | Train AUC=0.9944 | Val AUC=0.9286 | time=198.1s\n",
      "Fold 2 | Epoch 083 | Train Loss=0.1941 | Val Loss=0.3192 | Train ACC=0.9356 | Val ACC=0.8837 | Train AUC=0.9862 | Val AUC=0.9329 | time=201.1s\n",
      "Fold 2 | Epoch 084 | Train Loss=0.1737 | Val Loss=0.3215 | Train ACC=0.9525 | Val ACC=0.8837 | Train AUC=0.9898 | Val AUC=0.9351 | time=198.8s\n",
      "Fold 2 | Epoch 085 | Train Loss=0.1918 | Val Loss=0.3153 | Train ACC=0.9356 | Val ACC=0.8837 | Train AUC=0.9857 | Val AUC=0.9329 | time=199.5s\n",
      "Fold 2 | Epoch 086 | Train Loss=0.1872 | Val Loss=0.3178 | Train ACC=0.9458 | Val ACC=0.8837 | Train AUC=0.9864 | Val AUC=0.9351 | time=199.5s\n",
      "Fold 2 | Epoch 087 | Train Loss=0.1736 | Val Loss=0.3096 | Train ACC=0.9492 | Val ACC=0.8605 | Train AUC=0.9917 | Val AUC=0.9351 | time=198.4s\n",
      "Fold 2 | Epoch 088 | Train Loss=0.1913 | Val Loss=0.3214 | Train ACC=0.9356 | Val ACC=0.8837 | Train AUC=0.9873 | Val AUC=0.9351 | time=201.7s\n",
      "Fold 2 | Epoch 089 | Train Loss=0.2170 | Val Loss=0.3132 | Train ACC=0.9322 | Val ACC=0.8837 | Train AUC=0.9832 | Val AUC=0.9351 | time=198.0s\n",
      "Fold 2 | Epoch 090 | Train Loss=0.1761 | Val Loss=0.3201 | Train ACC=0.9525 | Val ACC=0.8837 | Train AUC=0.9878 | Val AUC=0.9394 | time=200.6s\n",
      "✅ Fold 2 saved best model (AUC=0.9394)\n",
      "Fold 2 | Epoch 091 | Train Loss=0.1887 | Val Loss=0.3207 | Train ACC=0.9593 | Val ACC=0.8837 | Train AUC=0.9883 | Val AUC=0.9394 | time=198.3s\n",
      "Fold 2 | Epoch 092 | Train Loss=0.1460 | Val Loss=0.3237 | Train ACC=0.9763 | Val ACC=0.8837 | Train AUC=0.9982 | Val AUC=0.9372 | time=200.9s\n",
      "Fold 2 | Epoch 093 | Train Loss=0.1635 | Val Loss=0.3314 | Train ACC=0.9661 | Val ACC=0.8837 | Train AUC=0.9929 | Val AUC=0.9372 | time=197.9s\n",
      "Fold 2 | Epoch 094 | Train Loss=0.1951 | Val Loss=0.3112 | Train ACC=0.9458 | Val ACC=0.8837 | Train AUC=0.9896 | Val AUC=0.9372 | time=200.5s\n",
      "Fold 2 | Epoch 095 | Train Loss=0.2080 | Val Loss=0.3147 | Train ACC=0.9322 | Val ACC=0.8837 | Train AUC=0.9809 | Val AUC=0.9351 | time=198.5s\n",
      "Fold 2 | Epoch 096 | Train Loss=0.1826 | Val Loss=0.3245 | Train ACC=0.9458 | Val ACC=0.8837 | Train AUC=0.9898 | Val AUC=0.9372 | time=201.0s\n",
      "Fold 2 | Epoch 097 | Train Loss=0.1503 | Val Loss=0.3131 | Train ACC=0.9797 | Val ACC=0.8605 | Train AUC=0.9976 | Val AUC=0.9351 | time=198.6s\n",
      "Fold 2 | Epoch 098 | Train Loss=0.1694 | Val Loss=0.3231 | Train ACC=0.9627 | Val ACC=0.8837 | Train AUC=0.9941 | Val AUC=0.9372 | time=201.5s\n",
      "Fold 2 | Epoch 099 | Train Loss=0.2185 | Val Loss=0.3228 | Train ACC=0.9356 | Val ACC=0.8837 | Train AUC=0.9796 | Val AUC=0.9329 | time=197.8s\n",
      "Fold 2 | Epoch 100 | Train Loss=0.1927 | Val Loss=0.3164 | Train ACC=0.9492 | Val ACC=0.8837 | Train AUC=0.9895 | Val AUC=0.9372 | time=199.1s\n",
      "=== Fold 2 完成，Best AUC=0.9394 ===\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "--------------------model------------------\n",
      "Total params(M)    : 14,057,602\n",
      "Trainable params(M): 14,057,602\n",
      "Approx. size       : 26.81 MB\n",
      "model type: DualStreamUNet3DClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_24072\\1643430249.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 | Epoch 001 | Train Loss=0.7121 | Val Loss=0.6900 | Train ACC=0.5186 | Val ACC=0.5116 | Train AUC=0.6026 | Val AUC=0.6093 | time=200.0s\n",
      "✅ Fold 3 saved best model (AUC=0.6093)\n",
      "Fold 3 | Epoch 002 | Train Loss=0.6760 | Val Loss=0.6627 | Train ACC=0.5254 | Val ACC=0.5349 | Train AUC=0.7783 | Val AUC=0.6190 | time=198.1s\n",
      "✅ Fold 3 saved best model (AUC=0.6190)\n",
      "Fold 3 | Epoch 003 | Train Loss=0.6430 | Val Loss=0.6431 | Train ACC=0.5627 | Val ACC=0.5116 | Train AUC=0.7773 | Val AUC=0.6234 | time=201.2s\n",
      "✅ Fold 3 saved best model (AUC=0.6234)\n",
      "Fold 3 | Epoch 004 | Train Loss=0.6221 | Val Loss=0.6330 | Train ACC=0.6576 | Val ACC=0.5349 | Train AUC=0.7553 | Val AUC=0.6310 | time=197.4s\n",
      "✅ Fold 3 saved best model (AUC=0.6310)\n",
      "Fold 3 | Epoch 005 | Train Loss=0.5954 | Val Loss=0.6254 | Train ACC=0.6678 | Val ACC=0.5814 | Train AUC=0.7800 | Val AUC=0.6255 | time=201.8s\n",
      "Fold 3 | Epoch 006 | Train Loss=0.5674 | Val Loss=0.6202 | Train ACC=0.7356 | Val ACC=0.5116 | Train AUC=0.7963 | Val AUC=0.6374 | time=198.7s\n",
      "✅ Fold 3 saved best model (AUC=0.6374)\n",
      "Fold 3 | Epoch 007 | Train Loss=0.5673 | Val Loss=0.6318 | Train ACC=0.7153 | Val ACC=0.5814 | Train AUC=0.7877 | Val AUC=0.6234 | time=200.9s\n",
      "Fold 3 | Epoch 008 | Train Loss=0.5612 | Val Loss=0.6240 | Train ACC=0.7254 | Val ACC=0.5116 | Train AUC=0.7905 | Val AUC=0.6342 | time=198.2s\n",
      "Fold 3 | Epoch 009 | Train Loss=0.5489 | Val Loss=0.6231 | Train ACC=0.7220 | Val ACC=0.5814 | Train AUC=0.8020 | Val AUC=0.6472 | time=201.0s\n",
      "✅ Fold 3 saved best model (AUC=0.6472)\n",
      "Fold 3 | Epoch 010 | Train Loss=0.5502 | Val Loss=0.6102 | Train ACC=0.7322 | Val ACC=0.5349 | Train AUC=0.7960 | Val AUC=0.6515 | time=197.7s\n",
      "✅ Fold 3 saved best model (AUC=0.6515)\n",
      "Fold 3 | Epoch 011 | Train Loss=0.5212 | Val Loss=0.6107 | Train ACC=0.7186 | Val ACC=0.5581 | Train AUC=0.8295 | Val AUC=0.6558 | time=200.7s\n",
      "✅ Fold 3 saved best model (AUC=0.6558)\n",
      "Fold 3 | Epoch 012 | Train Loss=0.5056 | Val Loss=0.6224 | Train ACC=0.7559 | Val ACC=0.6279 | Train AUC=0.8398 | Val AUC=0.6732 | time=198.2s\n",
      "✅ Fold 3 saved best model (AUC=0.6732)\n",
      "Fold 3 | Epoch 013 | Train Loss=0.4903 | Val Loss=0.6039 | Train ACC=0.7763 | Val ACC=0.6279 | Train AUC=0.8505 | Val AUC=0.6797 | time=199.9s\n",
      "✅ Fold 3 saved best model (AUC=0.6797)\n",
      "Fold 3 | Epoch 014 | Train Loss=0.5012 | Val Loss=0.6026 | Train ACC=0.7695 | Val ACC=0.6047 | Train AUC=0.8424 | Val AUC=0.7056 | time=198.8s\n",
      "✅ Fold 3 saved best model (AUC=0.7056)\n",
      "Fold 3 | Epoch 015 | Train Loss=0.4939 | Val Loss=0.5887 | Train ACC=0.7831 | Val ACC=0.6047 | Train AUC=0.8474 | Val AUC=0.7056 | time=199.2s\n",
      "Fold 3 | Epoch 016 | Train Loss=0.4727 | Val Loss=0.5699 | Train ACC=0.8000 | Val ACC=0.6977 | Train AUC=0.8720 | Val AUC=0.7208 | time=200.3s\n",
      "✅ Fold 3 saved best model (AUC=0.7208)\n",
      "Fold 3 | Epoch 017 | Train Loss=0.4613 | Val Loss=0.5708 | Train ACC=0.8034 | Val ACC=0.6744 | Train AUC=0.8770 | Val AUC=0.7294 | time=198.1s\n",
      "✅ Fold 3 saved best model (AUC=0.7294)\n",
      "Fold 3 | Epoch 018 | Train Loss=0.4578 | Val Loss=0.5519 | Train ACC=0.8068 | Val ACC=0.7209 | Train AUC=0.8759 | Val AUC=0.7403 | time=202.0s\n",
      "✅ Fold 3 saved best model (AUC=0.7403)\n",
      "Fold 3 | Epoch 019 | Train Loss=0.4530 | Val Loss=0.5404 | Train ACC=0.7898 | Val ACC=0.6744 | Train AUC=0.8788 | Val AUC=0.7662 | time=198.4s\n",
      "✅ Fold 3 saved best model (AUC=0.7662)\n",
      "Fold 3 | Epoch 020 | Train Loss=0.4273 | Val Loss=0.5440 | Train ACC=0.8271 | Val ACC=0.6512 | Train AUC=0.9044 | Val AUC=0.7619 | time=200.7s\n",
      "Fold 3 | Epoch 021 | Train Loss=0.4376 | Val Loss=0.5895 | Train ACC=0.8237 | Val ACC=0.6744 | Train AUC=0.8914 | Val AUC=0.7771 | time=198.0s\n",
      "✅ Fold 3 saved best model (AUC=0.7771)\n",
      "Fold 3 | Epoch 022 | Train Loss=0.3950 | Val Loss=0.5248 | Train ACC=0.8576 | Val ACC=0.6977 | Train AUC=0.9202 | Val AUC=0.7835 | time=201.5s\n",
      "✅ Fold 3 saved best model (AUC=0.7835)\n",
      "Fold 3 | Epoch 023 | Train Loss=0.4010 | Val Loss=0.5381 | Train ACC=0.8305 | Val ACC=0.6977 | Train AUC=0.9126 | Val AUC=0.8052 | time=198.3s\n",
      "✅ Fold 3 saved best model (AUC=0.8052)\n",
      "Fold 3 | Epoch 024 | Train Loss=0.3989 | Val Loss=0.5115 | Train ACC=0.8339 | Val ACC=0.6977 | Train AUC=0.9085 | Val AUC=0.8009 | time=201.0s\n",
      "Fold 3 | Epoch 025 | Train Loss=0.3543 | Val Loss=0.4968 | Train ACC=0.8644 | Val ACC=0.7209 | Train AUC=0.9383 | Val AUC=0.8268 | time=197.6s\n",
      "✅ Fold 3 saved best model (AUC=0.8268)\n",
      "Fold 3 | Epoch 026 | Train Loss=0.3543 | Val Loss=0.5166 | Train ACC=0.8712 | Val ACC=0.7209 | Train AUC=0.9381 | Val AUC=0.8290 | time=201.3s\n",
      "✅ Fold 3 saved best model (AUC=0.8290)\n",
      "Fold 3 | Epoch 027 | Train Loss=0.3658 | Val Loss=0.4991 | Train ACC=0.8542 | Val ACC=0.7674 | Train AUC=0.9286 | Val AUC=0.8420 | time=197.4s\n",
      "✅ Fold 3 saved best model (AUC=0.8420)\n",
      "Fold 3 | Epoch 028 | Train Loss=0.3428 | Val Loss=0.5001 | Train ACC=0.8610 | Val ACC=0.7442 | Train AUC=0.9394 | Val AUC=0.8247 | time=199.4s\n",
      "Fold 3 | Epoch 029 | Train Loss=0.3644 | Val Loss=0.5105 | Train ACC=0.8576 | Val ACC=0.7674 | Train AUC=0.9266 | Val AUC=0.8442 | time=197.6s\n",
      "✅ Fold 3 saved best model (AUC=0.8442)\n",
      "Fold 3 | Epoch 030 | Train Loss=0.3290 | Val Loss=0.4610 | Train ACC=0.8542 | Val ACC=0.7442 | Train AUC=0.9472 | Val AUC=0.8571 | time=199.4s\n",
      "✅ Fold 3 saved best model (AUC=0.8571)\n",
      "Fold 3 | Epoch 031 | Train Loss=0.3594 | Val Loss=0.4475 | Train ACC=0.8475 | Val ACC=0.7209 | Train AUC=0.9276 | Val AUC=0.8582 | time=200.1s\n",
      "✅ Fold 3 saved best model (AUC=0.8582)\n",
      "Fold 3 | Epoch 032 | Train Loss=0.3316 | Val Loss=0.5963 | Train ACC=0.8814 | Val ACC=0.7442 | Train AUC=0.9429 | Val AUC=0.8528 | time=197.4s\n",
      "Fold 3 | Epoch 033 | Train Loss=0.3107 | Val Loss=0.4546 | Train ACC=0.8881 | Val ACC=0.7442 | Train AUC=0.9505 | Val AUC=0.8636 | time=201.4s\n",
      "✅ Fold 3 saved best model (AUC=0.8636)\n",
      "Fold 3 | Epoch 034 | Train Loss=0.3151 | Val Loss=0.5241 | Train ACC=0.8814 | Val ACC=0.7907 | Train AUC=0.9496 | Val AUC=0.8615 | time=197.4s\n",
      "Fold 3 | Epoch 035 | Train Loss=0.3161 | Val Loss=0.4854 | Train ACC=0.8814 | Val ACC=0.7907 | Train AUC=0.9476 | Val AUC=0.8615 | time=200.9s\n",
      "Fold 3 | Epoch 036 | Train Loss=0.3133 | Val Loss=0.4500 | Train ACC=0.8678 | Val ACC=0.7442 | Train AUC=0.9509 | Val AUC=0.8571 | time=198.7s\n",
      "Fold 3 | Epoch 037 | Train Loss=0.3189 | Val Loss=0.4776 | Train ACC=0.8712 | Val ACC=0.6977 | Train AUC=0.9470 | Val AUC=0.8528 | time=201.1s\n",
      "Fold 3 | Epoch 038 | Train Loss=0.2838 | Val Loss=0.5040 | Train ACC=0.9051 | Val ACC=0.7442 | Train AUC=0.9600 | Val AUC=0.8680 | time=198.1s\n",
      "✅ Fold 3 saved best model (AUC=0.8680)\n",
      "Fold 3 | Epoch 039 | Train Loss=0.3248 | Val Loss=0.4519 | Train ACC=0.8610 | Val ACC=0.7907 | Train AUC=0.9407 | Val AUC=0.8626 | time=201.4s\n",
      "Fold 3 | Epoch 040 | Train Loss=0.2832 | Val Loss=0.4551 | Train ACC=0.8915 | Val ACC=0.8140 | Train AUC=0.9593 | Val AUC=0.8680 | time=197.8s\n",
      "✅ Fold 3 saved best model (AUC=0.8680)\n",
      "Fold 3 | Epoch 041 | Train Loss=0.2715 | Val Loss=0.4641 | Train ACC=0.8881 | Val ACC=0.7674 | Train AUC=0.9623 | Val AUC=0.8788 | time=201.3s\n",
      "✅ Fold 3 saved best model (AUC=0.8788)\n",
      "Fold 3 | Epoch 042 | Train Loss=0.2814 | Val Loss=0.4424 | Train ACC=0.8915 | Val ACC=0.7674 | Train AUC=0.9623 | Val AUC=0.8701 | time=199.1s\n",
      "Fold 3 | Epoch 043 | Train Loss=0.2642 | Val Loss=0.8098 | Train ACC=0.8949 | Val ACC=0.6512 | Train AUC=0.9653 | Val AUC=0.8745 | time=200.1s\n",
      "Fold 3 | Epoch 044 | Train Loss=0.2562 | Val Loss=0.5551 | Train ACC=0.9119 | Val ACC=0.6977 | Train AUC=0.9655 | Val AUC=0.8874 | time=198.4s\n",
      "✅ Fold 3 saved best model (AUC=0.8874)\n",
      "Fold 3 | Epoch 045 | Train Loss=0.2805 | Val Loss=0.4554 | Train ACC=0.9085 | Val ACC=0.7907 | Train AUC=0.9598 | Val AUC=0.8831 | time=198.5s\n",
      "Fold 3 | Epoch 046 | Train Loss=0.2734 | Val Loss=0.4564 | Train ACC=0.9051 | Val ACC=0.7907 | Train AUC=0.9629 | Val AUC=0.8799 | time=200.4s\n",
      "Fold 3 | Epoch 047 | Train Loss=0.2351 | Val Loss=0.4119 | Train ACC=0.9119 | Val ACC=0.7674 | Train AUC=0.9768 | Val AUC=0.8766 | time=198.1s\n",
      "Fold 3 | Epoch 048 | Train Loss=0.2395 | Val Loss=0.4288 | Train ACC=0.9186 | Val ACC=0.7674 | Train AUC=0.9743 | Val AUC=0.8853 | time=200.9s\n",
      "Fold 3 | Epoch 049 | Train Loss=0.2502 | Val Loss=0.4191 | Train ACC=0.9051 | Val ACC=0.7442 | Train AUC=0.9686 | Val AUC=0.8874 | time=197.6s\n",
      "✅ Fold 3 saved best model (AUC=0.8874)\n",
      "Fold 3 | Epoch 050 | Train Loss=0.2534 | Val Loss=0.4046 | Train ACC=0.8983 | Val ACC=0.8140 | Train AUC=0.9674 | Val AUC=0.8939 | time=201.0s\n",
      "✅ Fold 3 saved best model (AUC=0.8939)\n",
      "Fold 3 | Epoch 051 | Train Loss=0.2332 | Val Loss=0.4201 | Train ACC=0.9220 | Val ACC=0.7674 | Train AUC=0.9742 | Val AUC=0.8831 | time=198.2s\n",
      "Fold 3 | Epoch 052 | Train Loss=0.2409 | Val Loss=0.4026 | Train ACC=0.9119 | Val ACC=0.7907 | Train AUC=0.9707 | Val AUC=0.8918 | time=201.4s\n",
      "Fold 3 | Epoch 053 | Train Loss=0.2442 | Val Loss=0.4248 | Train ACC=0.9186 | Val ACC=0.7907 | Train AUC=0.9714 | Val AUC=0.8874 | time=199.1s\n",
      "Fold 3 | Epoch 054 | Train Loss=0.2769 | Val Loss=0.4573 | Train ACC=0.9085 | Val ACC=0.7442 | Train AUC=0.9565 | Val AUC=0.8874 | time=200.6s\n",
      "Fold 3 | Epoch 055 | Train Loss=0.2369 | Val Loss=0.5317 | Train ACC=0.9153 | Val ACC=0.7907 | Train AUC=0.9744 | Val AUC=0.8961 | time=198.0s\n",
      "✅ Fold 3 saved best model (AUC=0.8961)\n",
      "Fold 3 | Epoch 056 | Train Loss=0.2706 | Val Loss=0.4169 | Train ACC=0.8949 | Val ACC=0.8140 | Train AUC=0.9597 | Val AUC=0.8918 | time=200.2s\n",
      "Fold 3 | Epoch 057 | Train Loss=0.2448 | Val Loss=0.4282 | Train ACC=0.9017 | Val ACC=0.8140 | Train AUC=0.9732 | Val AUC=0.8961 | time=197.3s\n",
      "✅ Fold 3 saved best model (AUC=0.8961)\n",
      "Fold 3 | Epoch 058 | Train Loss=0.2651 | Val Loss=0.3947 | Train ACC=0.9153 | Val ACC=0.7674 | Train AUC=0.9636 | Val AUC=0.8939 | time=200.4s\n",
      "Fold 3 | Epoch 059 | Train Loss=0.2567 | Val Loss=0.3926 | Train ACC=0.8983 | Val ACC=0.7907 | Train AUC=0.9644 | Val AUC=0.8961 | time=197.6s\n",
      "Fold 3 | Epoch 060 | Train Loss=0.2456 | Val Loss=0.3847 | Train ACC=0.9017 | Val ACC=0.7907 | Train AUC=0.9707 | Val AUC=0.9004 | time=197.5s\n",
      "✅ Fold 3 saved best model (AUC=0.9004)\n",
      "Fold 3 | Epoch 061 | Train Loss=0.2047 | Val Loss=0.4326 | Train ACC=0.9322 | Val ACC=0.8140 | Train AUC=0.9825 | Val AUC=0.8961 | time=199.2s\n",
      "Fold 3 | Epoch 062 | Train Loss=0.2310 | Val Loss=0.4113 | Train ACC=0.9220 | Val ACC=0.8140 | Train AUC=0.9723 | Val AUC=0.8831 | time=197.0s\n",
      "Fold 3 | Epoch 063 | Train Loss=0.2050 | Val Loss=0.4012 | Train ACC=0.9186 | Val ACC=0.7674 | Train AUC=0.9832 | Val AUC=0.8896 | time=201.1s\n",
      "Fold 3 | Epoch 064 | Train Loss=0.2136 | Val Loss=0.3866 | Train ACC=0.9288 | Val ACC=0.8140 | Train AUC=0.9832 | Val AUC=0.9026 | time=198.0s\n",
      "✅ Fold 3 saved best model (AUC=0.9026)\n",
      "Fold 3 | Epoch 065 | Train Loss=0.2225 | Val Loss=0.3890 | Train ACC=0.9254 | Val ACC=0.7907 | Train AUC=0.9778 | Val AUC=0.8961 | time=201.4s\n",
      "Fold 3 | Epoch 066 | Train Loss=0.2088 | Val Loss=0.3986 | Train ACC=0.9458 | Val ACC=0.7907 | Train AUC=0.9801 | Val AUC=0.8939 | time=197.7s\n",
      "Fold 3 | Epoch 067 | Train Loss=0.2127 | Val Loss=0.3837 | Train ACC=0.9186 | Val ACC=0.7907 | Train AUC=0.9801 | Val AUC=0.8961 | time=202.3s\n",
      "Fold 3 | Epoch 068 | Train Loss=0.1936 | Val Loss=0.3844 | Train ACC=0.9356 | Val ACC=0.7674 | Train AUC=0.9853 | Val AUC=0.9004 | time=197.8s\n",
      "Fold 3 | Epoch 069 | Train Loss=0.2111 | Val Loss=0.3815 | Train ACC=0.9390 | Val ACC=0.7907 | Train AUC=0.9813 | Val AUC=0.9004 | time=199.3s\n",
      "Fold 3 | Epoch 070 | Train Loss=0.1974 | Val Loss=0.3973 | Train ACC=0.9390 | Val ACC=0.7907 | Train AUC=0.9840 | Val AUC=0.8983 | time=196.7s\n",
      "Fold 3 | Epoch 071 | Train Loss=0.1898 | Val Loss=0.3751 | Train ACC=0.9356 | Val ACC=0.7907 | Train AUC=0.9853 | Val AUC=0.9004 | time=200.8s\n",
      "Fold 3 | Epoch 072 | Train Loss=0.1769 | Val Loss=0.3814 | Train ACC=0.9458 | Val ACC=0.7674 | Train AUC=0.9893 | Val AUC=0.9004 | time=198.5s\n",
      "Fold 3 | Epoch 073 | Train Loss=0.2027 | Val Loss=0.3912 | Train ACC=0.9390 | Val ACC=0.7674 | Train AUC=0.9844 | Val AUC=0.9004 | time=201.9s\n",
      "Fold 3 | Epoch 074 | Train Loss=0.1909 | Val Loss=0.3901 | Train ACC=0.9458 | Val ACC=0.7674 | Train AUC=0.9884 | Val AUC=0.8983 | time=198.0s\n",
      "Fold 3 | Epoch 075 | Train Loss=0.1854 | Val Loss=0.3920 | Train ACC=0.9356 | Val ACC=0.7674 | Train AUC=0.9860 | Val AUC=0.8983 | time=200.7s\n",
      "Fold 3 | Epoch 076 | Train Loss=0.2213 | Val Loss=0.3766 | Train ACC=0.9254 | Val ACC=0.8140 | Train AUC=0.9764 | Val AUC=0.9026 | time=201.2s\n",
      "Fold 3 | Epoch 077 | Train Loss=0.1987 | Val Loss=0.3770 | Train ACC=0.9424 | Val ACC=0.7907 | Train AUC=0.9846 | Val AUC=0.9026 | time=199.1s\n",
      "Fold 3 | Epoch 078 | Train Loss=0.1884 | Val Loss=0.3802 | Train ACC=0.9458 | Val ACC=0.7907 | Train AUC=0.9873 | Val AUC=0.8983 | time=182.0s\n",
      "Fold 3 | Epoch 079 | Train Loss=0.2520 | Val Loss=0.3891 | Train ACC=0.9051 | Val ACC=0.7674 | Train AUC=0.9641 | Val AUC=0.8983 | time=165.0s\n",
      "Fold 3 | Epoch 080 | Train Loss=0.1787 | Val Loss=0.3878 | Train ACC=0.9627 | Val ACC=0.7907 | Train AUC=0.9877 | Val AUC=0.8961 | time=166.6s\n",
      "Fold 3 | Epoch 081 | Train Loss=0.2274 | Val Loss=0.3915 | Train ACC=0.9254 | Val ACC=0.7907 | Train AUC=0.9736 | Val AUC=0.9026 | time=155.9s\n",
      "Fold 3 | Epoch 082 | Train Loss=0.2303 | Val Loss=0.3793 | Train ACC=0.9186 | Val ACC=0.7907 | Train AUC=0.9740 | Val AUC=0.8983 | time=153.4s\n",
      "Fold 3 | Epoch 083 | Train Loss=0.1729 | Val Loss=0.3751 | Train ACC=0.9559 | Val ACC=0.7907 | Train AUC=0.9916 | Val AUC=0.9004 | time=153.2s\n",
      "Fold 3 | Epoch 084 | Train Loss=0.1811 | Val Loss=0.3774 | Train ACC=0.9492 | Val ACC=0.7907 | Train AUC=0.9896 | Val AUC=0.9026 | time=153.1s\n",
      "Fold 3 | Epoch 085 | Train Loss=0.2376 | Val Loss=0.3689 | Train ACC=0.9186 | Val ACC=0.7907 | Train AUC=0.9725 | Val AUC=0.9026 | time=154.9s\n",
      "Fold 3 | Epoch 086 | Train Loss=0.2230 | Val Loss=0.3767 | Train ACC=0.9254 | Val ACC=0.7907 | Train AUC=0.9821 | Val AUC=0.9026 | time=153.6s\n",
      "Fold 3 | Epoch 087 | Train Loss=0.2006 | Val Loss=0.3813 | Train ACC=0.9356 | Val ACC=0.7907 | Train AUC=0.9808 | Val AUC=0.9004 | time=155.4s\n",
      "Fold 3 | Epoch 088 | Train Loss=0.1654 | Val Loss=0.3814 | Train ACC=0.9492 | Val ACC=0.7907 | Train AUC=0.9920 | Val AUC=0.9004 | time=154.3s\n",
      "Fold 3 | Epoch 089 | Train Loss=0.1992 | Val Loss=0.3801 | Train ACC=0.9424 | Val ACC=0.7907 | Train AUC=0.9820 | Val AUC=0.9026 | time=154.2s\n",
      "Fold 3 | Epoch 090 | Train Loss=0.1888 | Val Loss=0.3782 | Train ACC=0.9390 | Val ACC=0.7907 | Train AUC=0.9866 | Val AUC=0.9026 | time=153.0s\n",
      "Fold 3 | Epoch 091 | Train Loss=0.1875 | Val Loss=0.3738 | Train ACC=0.9458 | Val ACC=0.7907 | Train AUC=0.9867 | Val AUC=0.9004 | time=152.9s\n",
      "Fold 3 | Epoch 092 | Train Loss=0.2225 | Val Loss=0.3815 | Train ACC=0.9153 | Val ACC=0.7907 | Train AUC=0.9783 | Val AUC=0.9004 | time=153.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m     out  \u001b[38;5;241m=\u001b[39m model(mri,pet)\n\u001b[0;32m     84\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[1;32m---> 86\u001b[0m vl_loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m vl_batches  \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     89\u001b[0m prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\monai\\data\\meta_tensor.py:283\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 283\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:1437\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1437\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------------- 五折交叉验证训练 -----------------\n",
    "os.makedirs(cfg.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for fold_idx in range(cfg.n_splits):              # cfg.n_splits == 5\n",
    "    fold = fold_idx + 1\n",
    "    print(f\"\\n=== Fold {fold}/{cfg.n_splits} ===\")\n",
    "\n",
    "    # —— 每折都重新实例化模型与训练组件 —— #\n",
    "    model     = generate_model(cfg)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.lr,\n",
    "        weight_decay=getattr(cfg, 'weight_decay', 0)\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.num_epochs)\n",
    "    scaler    = GradScaler(enabled=getattr(cfg, 'fp16', False))\n",
    "\n",
    "    # —— 获取该折的 DataLoader —— #\n",
    "    tr_loader = fold_loaders[fold_idx]['train_loader']\n",
    "    vl_loader = fold_loaders[fold_idx]['val_loader']\n",
    "\n",
    "    # —— 换成标准交叉熵 —— #\n",
    "    criterion = nn.CrossEntropyLoss()   # ⭐ 不再使用加权交叉熵 ⭐\n",
    "\n",
    "    # —— 为该折创建专属 CSV —— #\n",
    "    csv_path = os.path.join(cfg.checkpoint_dir, f\"metrics_fold{fold}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_Loss\",\"train_ACC\",\"train_PRE\",\"train_SEN\",\"train_SPE\",\"train_F1\",\"train_AUC\",\"train_MCC\",\n",
    "            \"val_Loss\",\"val_ACC\"  ,\"val_PRE\"  ,\"val_SEN\"  ,\"val_SPE\"  ,\"val_F1\"  ,\"val_AUC\"  ,\"val_MCC\",\n",
    "        ])\n",
    "\n",
    "    best_auc = -np.inf\n",
    "\n",
    "    # —— Epoch 循环 —— #\n",
    "    for epoch in range(1, cfg.num_epochs + 1):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # -------- Train --------\n",
    "        model.train()\n",
    "        tr_loss_sum = 0.0\n",
    "        tr_batches  = 0\n",
    "        yt, yp, ys = [], [], []\n",
    "        for batch in tr_loader:\n",
    "            mri = batch['MRI'].to(cfg.device)      # [B,1,D,H,W]\n",
    "            pet = batch['PET'].to(cfg.device)      # [B,1,D,H,W]\n",
    "            y   = batch['label'].to(cfg.device).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda', enabled=getattr(cfg, 'fp16', False)):\n",
    "                out  = model(mri,pet)\n",
    "                loss = criterion(out, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tr_loss_sum += loss.item()\n",
    "            tr_batches  += 1\n",
    "\n",
    "            prob = torch.softmax(out, dim=1)[:, 1].detach().cpu().numpy()\n",
    "            pred = out.argmax(1).detach().cpu().numpy()\n",
    "            yt.extend(y.cpu().numpy())\n",
    "            yp.extend(pred)\n",
    "            ys.extend(prob)\n",
    "\n",
    "        tr_met  = calculate_metrics(yt, yp, ys)\n",
    "        tr_loss = tr_loss_sum / tr_batches\n",
    "\n",
    "        # -------- Validation --------\n",
    "        model.eval()\n",
    "        vl_loss_sum = 0.0\n",
    "        vl_batches  = 0\n",
    "        yt, yp, ys = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in vl_loader:\n",
    "                mri = batch['MRI'].to(cfg.device)\n",
    "                pet = batch['PET'].to(cfg.device)\n",
    "                y   = batch['label'].to(cfg.device).long()\n",
    "\n",
    "                with autocast(device_type='cuda', enabled=getattr(cfg, 'fp16', False)):\n",
    "                    out  = model(mri,pet)\n",
    "                    loss = criterion(out, y)\n",
    "\n",
    "                vl_loss_sum += loss.item()\n",
    "                vl_batches  += 1\n",
    "\n",
    "                prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "                pred = out.argmax(1).cpu().numpy()\n",
    "                yt.extend(y.cpu().numpy())\n",
    "                yp.extend(pred)\n",
    "                ys.extend(prob)\n",
    "\n",
    "        vl_met  = calculate_metrics(yt, yp, ys)\n",
    "        vl_loss = vl_loss_sum / vl_batches\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Fold {fold} | Epoch {epoch:03d} | \"\n",
    "            f\"Train Loss={tr_loss:.4f} | Val Loss={vl_loss:.4f} | \"\n",
    "            f\"Train ACC={tr_met['ACC']:.4f} | Val ACC={vl_met['ACC']:.4f} | \"\n",
    "            f\"Train AUC={tr_met['AUC']:.4f} | Val AUC={vl_met['AUC']:.4f} | \"\n",
    "            f\"time={time.time()-t0:.1f}s\")\n",
    "\n",
    "        # —— 保存当前折最佳模型 —— #\n",
    "        if vl_met['AUC'] > best_auc:\n",
    "            best_auc = vl_met['AUC']\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(cfg.checkpoint_dir, f\"best_model_fold{fold}.pth\")\n",
    "            )\n",
    "            print(\"✅ Fold\", fold, \"saved best model (AUC={:.4f})\".format(best_auc))\n",
    "\n",
    "        # —— 追加写入 CSV —— #\n",
    "        with open(csv_path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                f\"{tr_loss:.4f}\", f\"{tr_met['ACC']:.4f}\", f\"{tr_met['PRE']:.4f}\",\n",
    "                f\"{tr_met['SEN']:.4f}\", f\"{tr_met['SPE']:.4f}\", f\"{tr_met['F1']:.4f}\", f\"{tr_met['AUC']:.4f}\", f\"{tr_met['MCC']:.4f}\",\n",
    "                f\"{vl_loss:.4f}\", f\"{vl_met['ACC']:.4f}\", f\"{vl_met['PRE']:.4f}\",\n",
    "                f\"{vl_met['SEN']:.4f}\", f\"{vl_met['SPE']:.4f}\", f\"{vl_met['F1']:.4f}\", f\"{vl_met['AUC']:.4f}\", f\"{vl_met['MCC']:.4f}\",\n",
    "            ])\n",
    "\n",
    "    print(f\"=== Fold {fold} 完成，Best AUC={best_auc:.4f} ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------测试-----------------------\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def load_test_data(cfg, fold):\n",
    "    full_ds = ADNI(\n",
    "        cfg.label_file,\n",
    "        cfg.mri_dir,\n",
    "        cfg.pet_dir,\n",
    "        cfg.task,\n",
    "        cfg.augment\n",
    "    ).data_dict\n",
    "\n",
    "    idx_path = os.path.join(cfg.checkpoint_dir, \"fold_indices.json\")\n",
    "    with open(idx_path, \"r\") as f:\n",
    "        all_indices = json.load(f)\n",
    "\n",
    "    test_idx = all_indices[str(fold)][\"test_idx\"]\n",
    "    test_data = [full_ds[i] for i in test_idx]\n",
    "    return test_data\n",
    "\n",
    "def test_models(checkpoint_dir, test_data, fold):\n",
    "    \"\"\"返回 metrics, y_prob, y_true, y_pred （新增 y_pred）\"\"\"\n",
    "    device = cfg.device\n",
    "\n",
    "    _, test_tf = ADNI_transform(augment=False)\n",
    "    ds = Dataset(data=test_data, transform=test_tf)\n",
    "    loader = DataLoader(ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "                        num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = generate_model(cfg)\n",
    "    ckpt = os.path.join(checkpoint_dir, f\"best_model_fold{fold}.pth\")\n",
    "    \n",
    "    # ---- 安全加载 state_dict ----\n",
    "    try:\n",
    "        state_dict = torch.load(ckpt, map_location=device, weights_only=True)\n",
    "    except TypeError:  # 兼容旧版 PyTorch\n",
    "        state_dict = torch.load(ckpt, map_location=device)\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device).eval()\n",
    "    print(f\"✅ Loaded {ckpt}\")\n",
    "\n",
    "    y_true, y_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            mri = batch['MRI'].to(cfg.device)\n",
    "            pet = batch['PET'].to(cfg.device)\n",
    "            y   = batch['label'].to(cfg.device).long()\n",
    "\n",
    "            out = model(mri,pet)\n",
    "            \n",
    "            probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "            labels = batch['label'].long().view(-1).cpu().numpy()\n",
    "            y_prob.extend(probs)\n",
    "            y_true.extend(labels)\n",
    "\n",
    "    y_pred  = (np.array(y_prob) > 0.5).astype(int)\n",
    "    metrics = calculate_metrics(y_true, y_pred, y_prob)\n",
    "\n",
    "    # --- ROC ---\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, lw=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title(f'ROC Fold {fold} (AUC={metrics[\"AUC\"]:.2f})')\n",
    "    roc_path = os.path.join(checkpoint_dir, f\"roc_fold{fold}.png\")\n",
    "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ ROC curve for fold {fold} saved to {roc_path}\")\n",
    "\n",
    "    return metrics, y_prob, y_true, y_pred   # <── 新增 y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------model------------------\n",
      "Total params(M)    : 14,057,602\n",
      "Trainable params(M): 14,057,602\n",
      "Approx. size       : 26.81 MB\n",
      "model type: DualStreamUNet3DClassifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 统计一次模型参数\n",
    "temp_model = generate_model(cfg)\n",
    "total_params     = sum(p.numel() for p in temp_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in temp_model.parameters() if p.requires_grad)\n",
    "bytes_per_param  = 2 if getattr(cfg, 'fp16', False) else 4\n",
    "approx_size_mb   = total_params * bytes_per_param / 1024 ** 2\n",
    "del temp_model\n",
    "\n",
    "#------------- 文件准备 -------------\n",
    "all_metrics = []\n",
    "all_probs   = []\n",
    "all_labels  = []\n",
    "\n",
    "ckpt_dir = cfg.checkpoint_dir\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "results_txt  = os.path.join(ckpt_dir, \"test_results.txt\")\n",
    "result_csv   = os.path.join(ckpt_dir, \"result.csv\")  # 新增\n",
    "\n",
    "# TXT：模型参数 + 表头\n",
    "with open(results_txt, \"w\") as f:\n",
    "    f.write(\"===== MODEL PARAMETERS =====\\n\")\n",
    "    f.write(f\"Total params       : {total_params}\\n\")\n",
    "    f.write(f\"Trainable params   : {trainable_params}\\n\")\n",
    "    f.write(f\"Approx. size (MB)  : {approx_size_mb:.2f}\\n\\n\")\n",
    "    f.write(\"===== FOLD RESULTS =====\\n\")\n",
    "    f.write(\"Fold\\tACC\\tPRE\\tSEN\\tSPE\\tF1\\tAUC\\tMCC\\n\")\n",
    "\n",
    "# CSV：表头\n",
    "with open(result_csv, \"w\", newline=\"\") as csv_f:\n",
    "    writer = csv.writer(csv_f)\n",
    "    writer.writerow([\n",
    "        \"fold\", \"idx_in_fold\", \"sample_id\",\n",
    "        \"true_label\", \"pred_label\", \"correct\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Fold 1/5 ===\n",
      "\n",
      "[ADNI Dataset: ADCN] 样本分布：\n",
      "  CN (0): 204\n",
      "  AD (1): 219\n",
      "\n",
      "--------------------model------------------\n",
      "Total params(M)    : 14,057,602\n",
      "Trainable params(M): 14,057,602\n",
      "Approx. size       : 26.81 MB\n",
      "model type: DualStreamUNet3DClassifier\n",
      "✅ Loaded C:/Users/dongzj/Desktop/ex_result/Ablation_unet3d_2stream/checkpoints_two_encoder-adcn\\best_model_fold1.pth\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DualStreamUNet3DClassifier.forward() missing 1 required positional argument: 'pet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m test_data \u001b[38;5;241m=\u001b[39m load_test_data(cfg, fold)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# metrics, probs, labels, preds\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m metrics, probs, labels, preds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Console 输出\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACC=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, PRE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCC=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMCC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "Cell \u001b[1;32mIn[10], line 51\u001b[0m, in \u001b[0;36mtest_models\u001b[1;34m(checkpoint_dir, test_data, fold)\u001b[0m\n\u001b[0;32m     48\u001b[0m pet \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPET\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)    \u001b[38;5;66;03m# [B,1,D,H,W]\u001b[39;00m\n\u001b[0;32m     49\u001b[0m x   \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([mri, pet], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)   \u001b[38;5;66;03m# [B,2,D,H,W]\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     54\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\dongzj\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dongzj\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: DualStreamUNet3DClassifier.forward() missing 1 required positional argument: 'pet'"
     ]
    }
   ],
   "source": [
    "#------------- 逐折测试 -------------\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "for fold in range(1, cfg.n_splits + 1):\n",
    "    print(f\"\\n=== Testing Fold {fold}/{cfg.n_splits} ===\")\n",
    "    test_data = load_test_data(cfg, fold)\n",
    "\n",
    "    # metrics, probs, labels, preds\n",
    "    metrics, probs, labels, preds = test_models(\n",
    "        ckpt_dir, test_data, fold\n",
    "    )\n",
    "\n",
    "    # Console 输出\n",
    "    print(\n",
    "        f\"Fold {fold} - \"\n",
    "        f\"ACC={metrics['ACC']:.4f}, PRE={metrics['PRE']:.4f}, \"\n",
    "        f\"SEN={metrics['SEN']:.4f}, SPE={metrics['SPE']:.4f}, \"\n",
    "        f\"F1={metrics['F1']:.4f}, AUC={metrics['AUC']:.4f}, \"\n",
    "        f\"MCC={metrics['MCC']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # TXT 写入\n",
    "    with open(results_txt, \"a\") as f:\n",
    "        f.write(\n",
    "            f\"{fold}\\t\"\n",
    "            f\"{metrics['ACC']:.4f}\\t{metrics['PRE']:.4f}\\t\"\n",
    "            f\"{metrics['SEN']:.4f}\\t{metrics['SPE']:.4f}\\t\"\n",
    "            f\"{metrics['F1']:.4f}\\t{metrics['AUC']:.4f}\\t\"\n",
    "            f\"{metrics['MCC']:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "    # CSV：样本级结果\n",
    "    with open(result_csv, \"a\", newline=\"\") as csv_f:\n",
    "        writer = csv.writer(csv_f)\n",
    "        for idx, (sample_dict, y_t, y_p) in enumerate(\n",
    "                zip(test_data, labels, preds)):\n",
    "            # 尝试从样本 dict 中抓 ID；若无则用文件名或序号\n",
    "            sample_id = (\n",
    "                sample_dict.get(\"subject\")\n",
    "                or os.path.basename(sample_dict.get(\"MRI\", f\"s{idx}\"))\n",
    "            )\n",
    "            writer.writerow([\n",
    "                fold, idx, sample_id,\n",
    "                int(y_t), int(y_p), int(y_t == y_p)\n",
    "            ])\n",
    "\n",
    "    # 汇总\n",
    "    all_metrics.append(metrics)\n",
    "    all_probs.extend(probs)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "#------------- 平均 ROC -------------\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "plt.plot(mean_fpr, interp_tpr, 'b-', lw=2,\n",
    "         label=f'Mean ROC (AUC={roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(ckpt_dir, 'mean_test_roc.png'),\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "#------------- 汇总指标 -------------\n",
    "print(\"\\n=== Final Test Results (mean ± std) ===\")\n",
    "summary_lines = []\n",
    "for k in ['ACC', 'PRE', 'SEN', 'SPE', 'F1', 'AUC', 'MCC']:\n",
    "    vals = [m[k] for m in all_metrics]\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val  = np.std(vals)\n",
    "    line = f\"{k}: {mean_val:.4f} ± {std_val:.4f}\"\n",
    "    print(line)\n",
    "    summary_lines.append(line)\n",
    "\n",
    "with open(results_txt, \"a\") as f:\n",
    "    f.write(\"\\n===== SUMMARY =====\\n\")\n",
    "    for line in summary_lines:\n",
    "        f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
