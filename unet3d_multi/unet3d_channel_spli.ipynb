{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, csv, numpy as np\n",
    "from collections import Counter\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datasets.ADNI import ADNI, ADNI_transform\n",
    "from monai.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, matthews_corrcoef,\n",
    "                             confusion_matrix, roc_curve, auc)\n",
    "from models.unet3d import UNet3DClassifier,UNet3D\n",
    "from utils.metrics import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device         : cuda:0\n",
      "label_file     : adni_dataset/ADNI_902.csv\n",
      "mri_dir        : adni_dataset/MRI\n",
      "pet_dir        : adni_dataset/PET\n",
      "task           : ADCN\n",
      "augment        : False\n",
      "split_ratio_test: 0.2\n",
      "seed           : 42\n",
      "num_epochs     : 100\n",
      "batch_size     : 8\n",
      "lr             : 1e-06\n",
      "weight_decay   : 1e-05\n",
      "fp16           : True\n",
      "checkpoint_dir : checkpoints\n",
      "nb_class       : 2\n",
      "n_splits       : 1\n",
      "dropout_rate   : 0.5\n",
      "in_channels    : 2\n",
      "seg_task       : False\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 配置 --------------------\n",
    "def load_cfg(path):\n",
    "    with open(path) as f: return json.load(f)\n",
    "\n",
    "class Cfg:\n",
    "    def __init__(self, d):\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        for k, v in d.items(): \n",
    "            setattr(self, k, v)\n",
    "\n",
    "# # ----------------- 指标函数 -------------------\n",
    "# def calculate_metrics(y_true, y_pred, y_score):\n",
    "#     if len(y_true) == 0:\n",
    "#         raise ValueError(\"No samples to evaluate. Please check your test_loader / data split.\")\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "#     spe = tn / (tn + fp + 1e-8)\n",
    "#     return {\n",
    "#         'ACC': accuracy_score(y_true, y_pred),\n",
    "#         'PRE': precision_score(y_true, y_pred, zero_division=0),\n",
    "#         'SEN': recall_score(y_true, y_pred, zero_division=0),\n",
    "#         'SPE': spe,\n",
    "#         'F1' : f1_score(y_true, y_pred, zero_division=0),\n",
    "#         'AUC': roc_auc_score(y_true, y_score),\n",
    "#         'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "#         'cm' : np.array([[tn, fp], [fn, tp]])\n",
    "#     }\n",
    "\n",
    "config_path = \"config/config.json\"\n",
    "cfg = Cfg(load_cfg(config_path))\n",
    "for name, val in vars(cfg).items():\n",
    "    print(f\"{name:15s}: {val}\")\n",
    "writer = SummaryWriter(cfg.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ADNI Dataset: ADCN] 样本分布：\n",
      "  CN (0): 204\n",
      "  AD (1): 219\n",
      "\n",
      "=== raw data_dict 前 5 条样本 ===\n",
      "[{'MRI': 'adni_dataset/MRI\\\\002_S_4213.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\002_S_4213.nii',\n",
      "  'Subject': '002_S_4213',\n",
      "  'label': 0},\n",
      " {'MRI': 'adni_dataset/MRI\\\\002_S_5018.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\002_S_5018.nii',\n",
      "  'Subject': '002_S_5018',\n",
      "  'label': 1},\n",
      " {'MRI': 'adni_dataset/MRI\\\\003_S_4081.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\003_S_4081.nii',\n",
      "  'Subject': '003_S_4081',\n",
      "  'label': 0},\n",
      " {'MRI': 'adni_dataset/MRI\\\\003_S_4119.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\003_S_4119.nii',\n",
      "  'Subject': '003_S_4119',\n",
      "  'label': 0},\n",
      " {'MRI': 'adni_dataset/MRI\\\\003_S_4136.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\003_S_4136.nii',\n",
      "  'Subject': '003_S_4136',\n",
      "  'label': 1}]\n"
     ]
    }
   ],
   "source": [
    "# 数据划分\n",
    "full_ds = ADNI(cfg.label_file, cfg.mri_dir, cfg.pet_dir, cfg.task, cfg.augment).data_dict\n",
    "train_val, test_ds = train_test_split(\n",
    "    full_ds, test_size=0.2, random_state=42,\n",
    "    stratify=[d['label'] for d in full_ds])\n",
    "\n",
    "# 再划分验证集\n",
    "train_ds, val_ds = train_test_split(\n",
    "    train_val, test_size=0.2, random_state=42,\n",
    "    stratify=[d['label'] for d in train_val])\n",
    "\n",
    "# 数据加载\n",
    "tr_tf, vl_tf = ADNI_transform(augment=cfg.augment)\n",
    "tr_loader = DataLoader(Dataset(train_ds, tr_tf),\n",
    "                       batch_size=cfg.batch_size, shuffle=True,\n",
    "                       num_workers=4, pin_memory=True)\n",
    "vl_loader = DataLoader(Dataset(val_ds, vl_tf),\n",
    "                       batch_size=cfg.batch_size, shuffle=False,\n",
    "                       num_workers=2, pin_memory=True)\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"=== raw data_dict 前 5 条样本 ===\")\n",
    "pprint(full_ds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------model------------------\n",
      "Total params(M)    : 19,073,698\n",
      "Trainable params(M): 19,073,698\n",
      "Approx. size    : 36.38 MB\n",
      "model type: UNet3D\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 32, 96, 112, 96]           1,760\n",
      "       BatchNorm3d-2      [-1, 32, 96, 112, 96]              64\n",
      "              ReLU-3      [-1, 32, 96, 112, 96]               0\n",
      "            Conv3d-4      [-1, 64, 96, 112, 96]          55,360\n",
      "       BatchNorm3d-5      [-1, 64, 96, 112, 96]             128\n",
      "              ReLU-6      [-1, 64, 96, 112, 96]               0\n",
      "         MaxPool3d-7       [-1, 64, 48, 56, 48]               0\n",
      "       Conv3DBlock-8  [[-1, 64, 48, 56, 48], [-1, 64, 96, 112, 96]]               0\n",
      "            Conv3d-9       [-1, 64, 48, 56, 48]         110,656\n",
      "      BatchNorm3d-10       [-1, 64, 48, 56, 48]             128\n",
      "             ReLU-11       [-1, 64, 48, 56, 48]               0\n",
      "           Conv3d-12      [-1, 128, 48, 56, 48]         221,312\n",
      "      BatchNorm3d-13      [-1, 128, 48, 56, 48]             256\n",
      "             ReLU-14      [-1, 128, 48, 56, 48]               0\n",
      "        MaxPool3d-15      [-1, 128, 24, 28, 24]               0\n",
      "      Conv3DBlock-16  [[-1, 128, 24, 28, 24], [-1, 128, 48, 56, 48]]               0\n",
      "           Conv3d-17      [-1, 128, 24, 28, 24]         442,496\n",
      "      BatchNorm3d-18      [-1, 128, 24, 28, 24]             256\n",
      "             ReLU-19      [-1, 128, 24, 28, 24]               0\n",
      "           Conv3d-20      [-1, 256, 24, 28, 24]         884,992\n",
      "      BatchNorm3d-21      [-1, 256, 24, 28, 24]             512\n",
      "             ReLU-22      [-1, 256, 24, 28, 24]               0\n",
      "        MaxPool3d-23      [-1, 256, 12, 14, 12]               0\n",
      "      Conv3DBlock-24  [[-1, 256, 12, 14, 12], [-1, 256, 24, 28, 24]]               0\n",
      "           Conv3d-25      [-1, 256, 12, 14, 12]       1,769,728\n",
      "      BatchNorm3d-26      [-1, 256, 12, 14, 12]             512\n",
      "             ReLU-27      [-1, 256, 12, 14, 12]               0\n",
      "           Conv3d-28      [-1, 512, 12, 14, 12]       3,539,456\n",
      "      BatchNorm3d-29      [-1, 512, 12, 14, 12]           1,024\n",
      "             ReLU-30      [-1, 512, 12, 14, 12]               0\n",
      "      Conv3DBlock-31  [[-1, 512, 12, 14, 12], [-1, 512, 12, 14, 12]]               0\n",
      "  ConvTranspose3d-32      [-1, 512, 24, 28, 24]       2,097,664\n",
      "           Conv3d-33      [-1, 256, 24, 28, 24]       5,308,672\n",
      "      BatchNorm3d-34      [-1, 256, 24, 28, 24]             512\n",
      "             ReLU-35      [-1, 256, 24, 28, 24]               0\n",
      "           Conv3d-36      [-1, 256, 24, 28, 24]       1,769,728\n",
      "      BatchNorm3d-37      [-1, 256, 24, 28, 24]             512\n",
      "             ReLU-38      [-1, 256, 24, 28, 24]               0\n",
      "    UpConv3DBlock-39      [-1, 256, 24, 28, 24]               0\n",
      "  ConvTranspose3d-40      [-1, 256, 48, 56, 48]         524,544\n",
      "           Conv3d-41      [-1, 128, 48, 56, 48]       1,327,232\n",
      "      BatchNorm3d-42      [-1, 128, 48, 56, 48]             256\n",
      "             ReLU-43      [-1, 128, 48, 56, 48]               0\n",
      "           Conv3d-44      [-1, 128, 48, 56, 48]         442,496\n",
      "      BatchNorm3d-45      [-1, 128, 48, 56, 48]             256\n",
      "             ReLU-46      [-1, 128, 48, 56, 48]               0\n",
      "    UpConv3DBlock-47      [-1, 128, 48, 56, 48]               0\n",
      "  ConvTranspose3d-48     [-1, 128, 96, 112, 96]         131,200\n",
      "           Conv3d-49      [-1, 64, 96, 112, 96]         331,840\n",
      "      BatchNorm3d-50      [-1, 64, 96, 112, 96]             128\n",
      "             ReLU-51      [-1, 64, 96, 112, 96]               0\n",
      "           Conv3d-52      [-1, 64, 96, 112, 96]         110,656\n",
      "      BatchNorm3d-53      [-1, 64, 96, 112, 96]             128\n",
      "             ReLU-54      [-1, 64, 96, 112, 96]               0\n",
      "           Conv3d-55       [-1, 2, 96, 112, 96]             130\n",
      "    UpConv3DBlock-56       [-1, 2, 96, 112, 96]               0\n",
      "================================================================\n",
      "Total params: 19,074,594\n",
      "Trainable params: 19,074,594\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.88\n",
      "Forward/backward pass size (MB): 4446287488.12\n",
      "Params size (MB): 72.76\n",
      "Estimated Total Size (MB): 4446287568.76\n",
      "----------------------------------------------------------------\n",
      "--- 10.71 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 创建模型 -------------------\n",
    "model = UNet3D(in_channels=cfg.in_channels, num_classes=cfg.nb_class)\n",
    "\n",
    "# 参数统计\n",
    "total_params     = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "bytes_per_param  = 2 if cfg.fp16 else 4\n",
    "print(\"--------------------model------------------\")\n",
    "print(f\"Total params(M)    : {total_params:,}\")\n",
    "print(f\"Trainable params(M): {trainable_params:,}\")\n",
    "print(f\"Approx. size    : {total_params*bytes_per_param/1024**2:.2f} MB\")\n",
    "print(\"model type:\", type(model).__name__)\n",
    "\n",
    "\n",
    "# ----------------- 测试创建模型 -------------------\n",
    "from torchsummary import summary\n",
    "start_time = time.time()\n",
    "summary(\n",
    "    model=model,\n",
    "    input_size=(2, 96, 112, 96),    # (C, D, H, W)\n",
    "    batch_size=-1,\n",
    "    device=\"cpu\"                                  # 若想在 GPU 上汇总，可填 \"cuda\"\n",
    ")\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_8140\\3362600758.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=cfg.fp16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train ACC=0.5185 F1=0.6829 AUC=0.5449 | Val   ACC=0.4853 F1=0.0000 AUC=0.6048 | time=136.3s\n",
      "✅ Saved best model.\n",
      "Epoch 002 | Train ACC=0.5185 F1=0.6829 AUC=0.6681 | Val   ACC=0.5441 F1=0.6804 AUC=0.6316 | time=131.3s\n",
      "✅ Saved best model.\n",
      "Epoch 003 | Train ACC=0.5370 F1=0.6898 AUC=0.6954 | Val   ACC=0.5441 F1=0.6804 AUC=0.6952 | time=132.3s\n",
      "✅ Saved best model.\n",
      "Epoch 004 | Train ACC=0.5741 F1=0.7028 AUC=0.7468 | Val   ACC=0.5735 F1=0.7010 AUC=0.7485 | time=131.2s\n",
      "✅ Saved best model.\n",
      "Epoch 005 | Train ACC=0.6556 F1=0.7240 AUC=0.7492 | Val   ACC=0.6471 F1=0.7143 AUC=0.7117 | time=130.2s\n",
      "Epoch 006 | Train ACC=0.6889 F1=0.7358 AUC=0.7572 | Val   ACC=0.6618 F1=0.7294 AUC=0.7675 | time=130.1s\n",
      "✅ Saved best model.\n",
      "Epoch 007 | Train ACC=0.6741 F1=0.7086 AUC=0.7448 | Val   ACC=0.6765 F1=0.6071 AUC=0.7848 | time=140.7s\n",
      "✅ Saved best model.\n",
      "Epoch 008 | Train ACC=0.7000 F1=0.7197 AUC=0.7546 | Val   ACC=0.7647 F1=0.7838 AUC=0.8065 | time=132.5s\n",
      "✅ Saved best model.\n",
      "Epoch 009 | Train ACC=0.7185 F1=0.7379 AUC=0.7929 | Val   ACC=0.8088 F1=0.8267 AUC=0.8303 | time=128.2s\n",
      "✅ Saved best model.\n",
      "Epoch 010 | Train ACC=0.6963 F1=0.7192 AUC=0.7648 | Val   ACC=0.7647 F1=0.7576 AUC=0.8216 | time=136.1s\n",
      "Epoch 011 | Train ACC=0.7185 F1=0.7361 AUC=0.7987 | Val   ACC=0.7206 F1=0.6885 AUC=0.8329 | time=136.1s\n",
      "✅ Saved best model.\n",
      "Epoch 012 | Train ACC=0.7370 F1=0.7526 AUC=0.7940 | Val   ACC=0.8088 F1=0.8060 AUC=0.8338 | time=140.6s\n",
      "✅ Saved best model.\n",
      "Epoch 013 | Train ACC=0.7407 F1=0.7552 AUC=0.8194 | Val   ACC=0.8088 F1=0.8169 AUC=0.8299 | time=136.9s\n",
      "Epoch 014 | Train ACC=0.7407 F1=0.7464 AUC=0.8103 | Val   ACC=0.8088 F1=0.8060 AUC=0.8359 | time=143.5s\n",
      "✅ Saved best model.\n",
      "Epoch 015 | Train ACC=0.7000 F1=0.7076 AUC=0.8001 | Val   ACC=0.7941 F1=0.7879 AUC=0.8394 | time=147.3s\n",
      "✅ Saved best model.\n",
      "Epoch 016 | Train ACC=0.7370 F1=0.7526 AUC=0.8284 | Val   ACC=0.8235 F1=0.8235 AUC=0.8446 | time=149.5s\n",
      "✅ Saved best model.\n",
      "Epoch 017 | Train ACC=0.7593 F1=0.7670 AUC=0.8362 | Val   ACC=0.8235 F1=0.8235 AUC=0.8442 | time=131.0s\n",
      "Epoch 018 | Train ACC=0.7333 F1=0.7429 AUC=0.8187 | Val   ACC=0.7500 F1=0.7302 AUC=0.8511 | time=125.6s\n",
      "✅ Saved best model.\n",
      "Epoch 019 | Train ACC=0.7778 F1=0.7794 AUC=0.8522 | Val   ACC=0.7647 F1=0.7500 AUC=0.8485 | time=124.0s\n",
      "Epoch 020 | Train ACC=0.7444 F1=0.7473 AUC=0.8098 | Val   ACC=0.8382 F1=0.8406 AUC=0.8537 | time=127.7s\n",
      "✅ Saved best model.\n",
      "Epoch 021 | Train ACC=0.7667 F1=0.7742 AUC=0.8581 | Val   ACC=0.8382 F1=0.8406 AUC=0.8494 | time=127.1s\n",
      "Epoch 022 | Train ACC=0.7556 F1=0.7609 AUC=0.8489 | Val   ACC=0.8088 F1=0.8060 AUC=0.8545 | time=127.7s\n",
      "✅ Saved best model.\n",
      "Epoch 023 | Train ACC=0.8000 F1=0.8015 AUC=0.8604 | Val   ACC=0.7941 F1=0.8158 AUC=0.8489 | time=124.2s\n",
      "Epoch 024 | Train ACC=0.7889 F1=0.7897 AUC=0.8667 | Val   ACC=0.7647 F1=0.7419 AUC=0.8537 | time=124.9s\n",
      "Epoch 025 | Train ACC=0.7815 F1=0.7823 AUC=0.8623 | Val   ACC=0.8529 F1=0.8571 AUC=0.8554 | time=128.7s\n",
      "✅ Saved best model.\n",
      "Epoch 026 | Train ACC=0.7778 F1=0.7794 AUC=0.8480 | Val   ACC=0.8676 F1=0.8732 AUC=0.8554 | time=131.3s\n",
      "Epoch 027 | Train ACC=0.7963 F1=0.7985 AUC=0.8787 | Val   ACC=0.8235 F1=0.8378 AUC=0.8597 | time=127.1s\n",
      "✅ Saved best model.\n",
      "Epoch 028 | Train ACC=0.8259 F1=0.8278 AUC=0.8906 | Val   ACC=0.8235 F1=0.8333 AUC=0.8558 | time=124.1s\n",
      "Epoch 029 | Train ACC=0.8185 F1=0.8231 AUC=0.8911 | Val   ACC=0.8235 F1=0.8235 AUC=0.8576 | time=123.9s\n",
      "Epoch 030 | Train ACC=0.7963 F1=0.8043 AUC=0.8807 | Val   ACC=0.7941 F1=0.7879 AUC=0.8606 | time=125.9s\n",
      "✅ Saved best model.\n",
      "Epoch 031 | Train ACC=0.8148 F1=0.8188 AUC=0.8996 | Val   ACC=0.8382 F1=0.8493 AUC=0.8615 | time=126.2s\n",
      "✅ Saved best model.\n",
      "Epoch 032 | Train ACC=0.7889 F1=0.7912 AUC=0.9040 | Val   ACC=0.7647 F1=0.7949 AUC=0.8623 | time=127.4s\n",
      "✅ Saved best model.\n",
      "Epoch 033 | Train ACC=0.8222 F1=0.8235 AUC=0.9023 | Val   ACC=0.7794 F1=0.7692 AUC=0.8658 | time=124.9s\n",
      "✅ Saved best model.\n",
      "Epoch 034 | Train ACC=0.8296 F1=0.8271 AUC=0.8970 | Val   ACC=0.7794 F1=0.7692 AUC=0.8606 | time=125.2s\n",
      "Epoch 035 | Train ACC=0.7963 F1=0.8043 AUC=0.8878 | Val   ACC=0.8088 F1=0.8060 AUC=0.8632 | time=126.2s\n",
      "Epoch 036 | Train ACC=0.8519 F1=0.8540 AUC=0.9111 | Val   ACC=0.7941 F1=0.7879 AUC=0.8641 | time=126.6s\n",
      "Epoch 037 | Train ACC=0.8519 F1=0.8507 AUC=0.9139 | Val   ACC=0.8529 F1=0.8649 AUC=0.8597 | time=124.6s\n",
      "Epoch 038 | Train ACC=0.8259 F1=0.8253 AUC=0.9147 | Val   ACC=0.8382 F1=0.8493 AUC=0.8636 | time=122.2s\n",
      "Epoch 039 | Train ACC=0.8519 F1=0.8540 AUC=0.9352 | Val   ACC=0.8088 F1=0.8060 AUC=0.8632 | time=125.2s\n",
      "Epoch 040 | Train ACC=0.8259 F1=0.8315 AUC=0.9093 | Val   ACC=0.7794 F1=0.8101 AUC=0.8597 | time=127.4s\n",
      "Epoch 041 | Train ACC=0.8481 F1=0.8429 AUC=0.9308 | Val   ACC=0.7794 F1=0.7619 AUC=0.8701 | time=127.4s\n",
      "✅ Saved best model.\n",
      "Epoch 042 | Train ACC=0.8593 F1=0.8652 AUC=0.9429 | Val   ACC=0.8235 F1=0.8235 AUC=0.8693 | time=126.0s\n",
      "Epoch 043 | Train ACC=0.8444 F1=0.8444 AUC=0.9282 | Val   ACC=0.7941 F1=0.8000 AUC=0.8727 | time=124.8s\n",
      "✅ Saved best model.\n",
      "Epoch 044 | Train ACC=0.8407 F1=0.8481 AUC=0.9173 | Val   ACC=0.7794 F1=0.8000 AUC=0.8693 | time=127.7s\n",
      "Epoch 045 | Train ACC=0.8259 F1=0.8240 AUC=0.9158 | Val   ACC=0.7941 F1=0.8000 AUC=0.8745 | time=130.4s\n",
      "✅ Saved best model.\n",
      "Epoch 046 | Train ACC=0.8407 F1=0.8401 AUC=0.9216 | Val   ACC=0.8088 F1=0.8169 AUC=0.8745 | time=126.2s\n",
      "Epoch 047 | Train ACC=0.8593 F1=0.8571 AUC=0.9384 | Val   ACC=0.7647 F1=0.7895 AUC=0.8649 | time=125.2s\n",
      "Epoch 048 | Train ACC=0.8704 F1=0.8718 AUC=0.9367 | Val   ACC=0.8235 F1=0.8286 AUC=0.8771 | time=125.0s\n",
      "✅ Saved best model.\n",
      "Epoch 049 | Train ACC=0.8815 F1=0.8806 AUC=0.9383 | Val   ACC=0.8088 F1=0.8000 AUC=0.8762 | time=125.3s\n",
      "Epoch 050 | Train ACC=0.8815 F1=0.8841 AUC=0.9392 | Val   ACC=0.8235 F1=0.8333 AUC=0.8771 | time=128.4s\n",
      "Epoch 051 | Train ACC=0.8481 F1=0.8509 AUC=0.9260 | Val   ACC=0.8382 F1=0.8406 AUC=0.8749 | time=123.9s\n",
      "Epoch 052 | Train ACC=0.8889 F1=0.8905 AUC=0.9457 | Val   ACC=0.8382 F1=0.8406 AUC=0.8732 | time=122.8s\n",
      "Epoch 053 | Train ACC=0.8741 F1=0.8741 AUC=0.9550 | Val   ACC=0.8235 F1=0.8286 AUC=0.8753 | time=123.4s\n",
      "Epoch 054 | Train ACC=0.9000 F1=0.9004 AUC=0.9553 | Val   ACC=0.7941 F1=0.8108 AUC=0.8779 | time=126.2s\n",
      "✅ Saved best model.\n",
      "Epoch 055 | Train ACC=0.8815 F1=0.8873 AUC=0.9482 | Val   ACC=0.8088 F1=0.8169 AUC=0.8810 | time=129.7s\n",
      "✅ Saved best model.\n",
      "Epoch 056 | Train ACC=0.8741 F1=0.8768 AUC=0.9424 | Val   ACC=0.8382 F1=0.8406 AUC=0.8779 | time=124.8s\n",
      "Epoch 057 | Train ACC=0.8741 F1=0.8759 AUC=0.9453 | Val   ACC=0.8088 F1=0.8219 AUC=0.8784 | time=122.1s\n",
      "Epoch 058 | Train ACC=0.8630 F1=0.8635 AUC=0.9435 | Val   ACC=0.8235 F1=0.8333 AUC=0.8762 | time=124.8s\n",
      "Epoch 059 | Train ACC=0.8926 F1=0.8961 AUC=0.9527 | Val   ACC=0.8088 F1=0.8219 AUC=0.8727 | time=125.3s\n",
      "Epoch 060 | Train ACC=0.8852 F1=0.8881 AUC=0.9499 | Val   ACC=0.8235 F1=0.8333 AUC=0.8762 | time=125.1s\n",
      "Epoch 061 | Train ACC=0.8889 F1=0.8881 AUC=0.9610 | Val   ACC=0.8235 F1=0.8235 AUC=0.8771 | time=130.2s\n",
      "Epoch 062 | Train ACC=0.8815 F1=0.8841 AUC=0.9391 | Val   ACC=0.8088 F1=0.8169 AUC=0.8805 | time=117.6s\n",
      "Epoch 063 | Train ACC=0.8778 F1=0.8764 AUC=0.9476 | Val   ACC=0.8088 F1=0.8060 AUC=0.8805 | time=115.7s\n",
      "Epoch 064 | Train ACC=0.8630 F1=0.8645 AUC=0.9416 | Val   ACC=0.8088 F1=0.8219 AUC=0.8788 | time=114.7s\n",
      "Epoch 065 | Train ACC=0.8889 F1=0.8889 AUC=0.9529 | Val   ACC=0.7941 F1=0.8108 AUC=0.8753 | time=115.9s\n",
      "Epoch 066 | Train ACC=0.8370 F1=0.8440 AUC=0.9268 | Val   ACC=0.8088 F1=0.8169 AUC=0.8840 | time=115.2s\n",
      "✅ Saved best model.\n",
      "Epoch 067 | Train ACC=0.8963 F1=0.8986 AUC=0.9602 | Val   ACC=0.8235 F1=0.8286 AUC=0.8840 | time=114.5s\n",
      "Epoch 068 | Train ACC=0.8963 F1=0.8971 AUC=0.9613 | Val   ACC=0.8088 F1=0.8169 AUC=0.8779 | time=113.4s\n",
      "Epoch 069 | Train ACC=0.8667 F1=0.8705 AUC=0.9316 | Val   ACC=0.8382 F1=0.8406 AUC=0.8831 | time=133.1s\n",
      "Epoch 070 | Train ACC=0.8704 F1=0.8708 AUC=0.9404 | Val   ACC=0.7941 F1=0.8108 AUC=0.8753 | time=161.2s\n",
      "Epoch 071 | Train ACC=0.8778 F1=0.8817 AUC=0.9438 | Val   ACC=0.8088 F1=0.8169 AUC=0.8831 | time=157.2s\n",
      "Epoch 072 | Train ACC=0.8852 F1=0.8856 AUC=0.9555 | Val   ACC=0.8088 F1=0.8169 AUC=0.8801 | time=152.9s\n",
      "Epoch 073 | Train ACC=0.8630 F1=0.8645 AUC=0.9423 | Val   ACC=0.8235 F1=0.8286 AUC=0.8762 | time=153.3s\n",
      "Epoch 074 | Train ACC=0.8778 F1=0.8800 AUC=0.9485 | Val   ACC=0.8382 F1=0.8406 AUC=0.8762 | time=155.5s\n",
      "Epoch 075 | Train ACC=0.8593 F1=0.8603 AUC=0.9285 | Val   ACC=0.8088 F1=0.8169 AUC=0.8827 | time=154.5s\n",
      "Epoch 076 | Train ACC=0.9000 F1=0.9011 AUC=0.9686 | Val   ACC=0.8382 F1=0.8406 AUC=0.8844 | time=151.4s\n",
      "✅ Saved best model.\n",
      "Epoch 077 | Train ACC=0.8407 F1=0.8425 AUC=0.9389 | Val   ACC=0.7941 F1=0.8108 AUC=0.8818 | time=153.0s\n",
      "Epoch 078 | Train ACC=0.8889 F1=0.8913 AUC=0.9507 | Val   ACC=0.8382 F1=0.8406 AUC=0.8805 | time=154.9s\n",
      "Epoch 079 | Train ACC=0.9000 F1=0.9018 AUC=0.9577 | Val   ACC=0.8235 F1=0.8235 AUC=0.8831 | time=145.4s\n",
      "Epoch 080 | Train ACC=0.8593 F1=0.8633 AUC=0.9401 | Val   ACC=0.8088 F1=0.8169 AUC=0.8909 | time=154.6s\n",
      "✅ Saved best model.\n",
      "Epoch 081 | Train ACC=0.9074 F1=0.9110 AUC=0.9524 | Val   ACC=0.8088 F1=0.8169 AUC=0.8887 | time=131.5s\n",
      "Epoch 082 | Train ACC=0.8926 F1=0.8922 AUC=0.9558 | Val   ACC=0.8235 F1=0.8286 AUC=0.8861 | time=137.9s\n",
      "Epoch 083 | Train ACC=0.9037 F1=0.9051 AUC=0.9637 | Val   ACC=0.7941 F1=0.8108 AUC=0.8779 | time=147.0s\n",
      "Epoch 084 | Train ACC=0.9074 F1=0.9077 AUC=0.9681 | Val   ACC=0.8235 F1=0.8286 AUC=0.8797 | time=158.3s\n",
      "Epoch 085 | Train ACC=0.8704 F1=0.8718 AUC=0.9540 | Val   ACC=0.8382 F1=0.8406 AUC=0.8762 | time=155.0s\n",
      "Epoch 086 | Train ACC=0.8630 F1=0.8655 AUC=0.9415 | Val   ACC=0.7941 F1=0.8056 AUC=0.8797 | time=154.0s\n",
      "Epoch 087 | Train ACC=0.8815 F1=0.8824 AUC=0.9592 | Val   ACC=0.8088 F1=0.8169 AUC=0.8874 | time=154.8s\n",
      "Epoch 088 | Train ACC=0.8741 F1=0.8741 AUC=0.9470 | Val   ACC=0.7941 F1=0.8108 AUC=0.8805 | time=153.9s\n",
      "Epoch 089 | Train ACC=0.8704 F1=0.8736 AUC=0.9511 | Val   ACC=0.8235 F1=0.8286 AUC=0.8874 | time=156.6s\n",
      "Epoch 090 | Train ACC=0.8630 F1=0.8645 AUC=0.9420 | Val   ACC=0.8235 F1=0.8286 AUC=0.8874 | time=153.8s\n",
      "Epoch 091 | Train ACC=0.9185 F1=0.9191 AUC=0.9665 | Val   ACC=0.8382 F1=0.8406 AUC=0.8857 | time=148.2s\n",
      "Epoch 092 | Train ACC=0.8815 F1=0.8865 AUC=0.9493 | Val   ACC=0.8235 F1=0.8286 AUC=0.8861 | time=139.7s\n",
      "Epoch 093 | Train ACC=0.9074 F1=0.9097 AUC=0.9604 | Val   ACC=0.8088 F1=0.8169 AUC=0.8874 | time=151.4s\n",
      "Epoch 094 | Train ACC=0.9111 F1=0.9111 AUC=0.9778 | Val   ACC=0.8382 F1=0.8406 AUC=0.8857 | time=140.1s\n",
      "Epoch 095 | Train ACC=0.8741 F1=0.8741 AUC=0.9586 | Val   ACC=0.8382 F1=0.8406 AUC=0.8814 | time=151.4s\n",
      "Epoch 096 | Train ACC=0.9037 F1=0.9037 AUC=0.9633 | Val   ACC=0.8382 F1=0.8406 AUC=0.8771 | time=121.1s\n",
      "Epoch 097 | Train ACC=0.8852 F1=0.8889 AUC=0.9599 | Val   ACC=0.8235 F1=0.8235 AUC=0.8870 | time=121.0s\n",
      "Epoch 098 | Train ACC=0.8963 F1=0.8971 AUC=0.9686 | Val   ACC=0.8382 F1=0.8406 AUC=0.8857 | time=122.1s\n",
      "Epoch 099 | Train ACC=0.9074 F1=0.9091 AUC=0.9736 | Val   ACC=0.8088 F1=0.8219 AUC=0.8866 | time=139.1s\n",
      "Epoch 100 | Train ACC=0.8926 F1=0.8953 AUC=0.9579 | Val   ACC=0.8088 F1=0.8169 AUC=0.8874 | time=151.3s\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 训练 ---------------------\n",
    "model = UNet3DClassifier(in_channels=cfg.in_channels, num_classes=cfg.nb_class).to(cfg.device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.num_epochs)\n",
    "scaler = GradScaler(enabled=cfg.fp16)\n",
    "\n",
    "best_auc = -np.inf\n",
    "for epoch in range(1, cfg.num_epochs + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # -------- Train --------\n",
    "    model.train(); yt, yp, ys = [], [], []\n",
    "    for batch in tr_loader:\n",
    "        # ❶ 从 batch 里取出两模态，并拼通道\n",
    "        mri = batch['MRI'].to(cfg.device)    # [B,1,D,H,W]\n",
    "        pet = batch['PET'].to(cfg.device)    # [B,1,D,H,W]\n",
    "        x   = torch.cat([mri, pet], dim=1)   # [B,2,D,H,W]\n",
    "        y   = batch['label'].to(cfg.device).long().view(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type='cuda', enabled=cfg.fp16):\n",
    "            out  = model(x)\n",
    "            loss = criterion(out, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        prob = torch.softmax(out, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        pred = out.argmax(1).detach().cpu().numpy()\n",
    "        yt.extend(y.cpu().numpy())\n",
    "        yp.extend(pred)\n",
    "        ys.extend(prob)\n",
    "\n",
    "    tr_met = calculate_metrics(yt, yp, ys)\n",
    "\n",
    "    # -------- Validation --------\n",
    "    model.eval(); yt, yp, ys = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in vl_loader:\n",
    "            mri = batch['MRI'].to(cfg.device)\n",
    "            pet = batch['PET'].to(cfg.device)\n",
    "            x   = torch.cat([mri, pet], dim=1)\n",
    "            y   = batch['label'].to(cfg.device).long().view(-1)\n",
    "\n",
    "            with autocast(device_type='cuda', enabled=cfg.fp16):\n",
    "                out  = model(x)\n",
    "                loss = criterion(out, y)\n",
    "\n",
    "            prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "            pred = out.argmax(1).cpu().numpy()\n",
    "            yt.extend(y.cpu().numpy())\n",
    "            yp.extend(pred)\n",
    "            ys.extend(prob)\n",
    "\n",
    "    vl_met = calculate_metrics(yt, yp, ys)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | \"\n",
    "          f\"Train ACC={tr_met['ACC']:.4f} F1={tr_met['F1']:.4f} AUC={tr_met['AUC']:.4f} | \"\n",
    "          f\"Val   ACC={vl_met['ACC']:.4f} F1={vl_met['F1']:.4f} AUC={vl_met['AUC']:.4f} | \"\n",
    "          f\"time={time.time()-t0:.1f}s\")\n",
    "\n",
    "    if vl_met['AUC'] > best_auc:\n",
    "        best_auc = vl_met['AUC']\n",
    "        torch.save(model.state_dict(), os.path.join(cfg.checkpoint_dir, \"best_model.pth\"))\n",
    "        print(\"✅ Saved best model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== raw test_ds 前 5 条样本 ===\n",
      "[{'MRI': 'adni_dataset/MRI\\\\941_S_4376.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\941_S_4376.nii',\n",
      "  'Subject': '941_S_4376',\n",
      "  'label': 0},\n",
      " {'MRI': 'adni_dataset/MRI\\\\031_S_4024.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\031_S_4024.nii',\n",
      "  'Subject': '031_S_4024',\n",
      "  'label': 1},\n",
      " {'MRI': 'adni_dataset/MRI\\\\032_S_4348.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\032_S_4348.nii',\n",
      "  'Subject': '032_S_4348',\n",
      "  'label': 0},\n",
      " {'MRI': 'adni_dataset/MRI\\\\094_S_1090.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\094_S_1090.nii',\n",
      "  'Subject': '094_S_1090',\n",
      "  'label': 1},\n",
      " {'MRI': 'adni_dataset/MRI\\\\016_S_4887.nii',\n",
      "  'PET': 'adni_dataset/PET\\\\016_S_4887.nii',\n",
      "  'Subject': '016_S_4887',\n",
      "  'label': 1}]\n",
      "MRI batch shape: torch.Size([8, 1, 91, 109, 91])\n",
      "PET batch shape: torch.Size([8, 1, 91, 109, 91])\n",
      "Label batch shape: torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_15724\\2653020706.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\n",
      "C:\\Users\\dongzj\\AppData\\Local\\Temp\\ipykernel_15724\\2653020706.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=cfg.fp16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Results ===\n",
      "ACC: 0.8824\n",
      "PRE: 0.9250\n",
      "SEN: 0.8409\n",
      "SPE: 0.9268\n",
      "F1 : 0.8810\n",
      "AUC: 0.9454\n",
      "MCC: 0.7686\n",
      "Confusion Matrix:\n",
      "[[38  3]\n",
      " [ 7 37]]\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 测试 --------------------\n",
    "def calculate_metrics(y_true, y_pred, y_score):\n",
    "    if len(y_true) == 0:\n",
    "        raise ValueError(\"No samples to evaluate. Please check your test_loader / data split.\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sen = recall_score(y_true, y_pred, zero_division=0)\n",
    "    spe = tn / (tn + fp + 1e-8)\n",
    "\n",
    "    # 近似 AUC = (Sensitivity + Specificity) / 2\n",
    "    auc_val = (sen + spe) / 2\n",
    "\n",
    "    return {\n",
    "        'ACC': accuracy_score(y_true, y_pred),\n",
    "        'PRE': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'SEN': sen,\n",
    "        'SPE': spe,\n",
    "        'F1' : f1_score(y_true, y_pred, zero_division=0),\n",
    "        'AUC': auc_val,\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "        'cm' : np.array([[tn, fp], [fn, tp]])\n",
    "    }\n",
    "\n",
    "# ❶ 用同样的 transform（无增强）处理测试集\n",
    "_, test_tf = ADNI_transform(augment=False)\n",
    "\n",
    "# ❷ 构造 MONAI Dataset → DataLoader\n",
    "test_loader = DataLoader(\n",
    "    Dataset(test_ds, test_tf),\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,    # 测试一般不打乱\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ❸ （可选）打印 test_ds 的前几条，确认路径/标签无误\n",
    "from pprint import pprint\n",
    "print(\"=== raw test_ds 前 5 条样本 ===\")\n",
    "pprint(test_ds[:5])\n",
    "\n",
    "# ❹ （可选）迭代一个 batch，确认形状\n",
    "batch = next(iter(test_loader))\n",
    "print(\"MRI batch shape:\", batch['MRI'].shape)   # → [B,1,D,H,W]\n",
    "print(\"PET batch shape:\", batch['PET'].shape)   # → [B,1,D,H,W]\n",
    "print(\"Label batch shape:\", batch['label'].shape)  # → [B]\n",
    "\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from utils.metrics import calculate_metrics\n",
    "from models.unet3d import UNet3DClassifier\n",
    "\n",
    "# 1) 构建模型并加载权重\n",
    "model = UNet3DClassifier(\n",
    "    in_channels=cfg.in_channels, \n",
    "    num_classes=cfg.nb_class\n",
    ").to(cfg.device)\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(cfg.checkpoint_dir, \"best_model.pth\"),\n",
    "    map_location=cfg.device\n",
    "))\n",
    "model.eval()\n",
    "\n",
    "# 2) 遍历 test_loader\n",
    "yt, yp, ys = [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        mri = batch['MRI'].to(cfg.device)    # [B,1,D,H,W]\n",
    "        pet = batch['PET'].to(cfg.device)    # [B,1,D,H,W]\n",
    "        x   = torch.cat([mri, pet], dim=1)   # [B,2,D,H,W]\n",
    "        y   = batch['label'].to(cfg.device).long().view(-1)\n",
    "\n",
    "        with autocast(enabled=cfg.fp16):\n",
    "            out = model(x)                   # [B, num_classes]\n",
    "\n",
    "        prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # 正例概率\n",
    "        pred = out.argmax(1).cpu().numpy()\n",
    "\n",
    "        yt.extend(y.cpu().numpy())\n",
    "        yp.extend(pred)\n",
    "        ys.extend(prob)\n",
    "\n",
    "# 3) 计算并打印指标\n",
    "metrics = calculate_metrics(yt, yp, ys)\n",
    "print(\"\\n=== Test Results ===\")\n",
    "print(f\"ACC: {metrics['ACC']:.4f}\")\n",
    "print(f\"PRE: {metrics['PRE']:.4f}\")\n",
    "print(f\"SEN: {metrics['SEN']:.4f}\")\n",
    "print(f\"SPE: {metrics['SPE']:.4f}\")\n",
    "print(f\"F1 : {metrics['F1']:.4f}\")\n",
    "print(f\"AUC: {metrics['AUC']:.4f}\")\n",
    "print(f\"MCC: {metrics['MCC']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(metrics['cm'])  # [[tn, fp], [fn, tp]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
